{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 对于2018年CIC2rd的反馈数据进行文本分类"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## install dependency and initial session and S3 bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arn:aws-cn:iam::876820548815:role/Sagemaker-Bootcamp-SageMakerExecutionRole-Z3VF78G260T1\n",
      "ray-ai-ml-bjs\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "import json\n",
    "import boto3\n",
    "from random import shuffle\n",
    "\n",
    "sess = sagemaker.Session()\n",
    "\n",
    "role = get_execution_role()\n",
    "print(role) # This is the role that SageMaker would use to leverage AWS resources (S3, CloudWatch) on your behalf\n",
    "\n",
    "bucket = 'ray-ai-ml-bjs' #sess.default_bucket() # Replace with your own bucket name if needed\n",
    "print(bucket)\n",
    "prefix = 'classification/blazingtext/bmwticket' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Requirement already up-to-date: jieba in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (0.42.1)\n",
      "\u001b[33mWARNING: You are using pip version 20.2.3; however, version 20.2.4 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/python3/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Requirement already satisfied: paddlepaddle-tiny in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (1.6.1)\n",
      "Requirement already satisfied: graphviz in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from paddlepaddle-tiny) (0.14.1)\n",
      "Requirement already satisfied: numpy<=1.16.4,>=1.12 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from paddlepaddle-tiny) (1.16.4)\n",
      "Requirement already satisfied: decorator in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from paddlepaddle-tiny) (4.4.2)\n",
      "Requirement already satisfied: six in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from paddlepaddle-tiny) (1.14.0)\n",
      "Requirement already satisfied: objgraph in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from paddlepaddle-tiny) (3.4.1)\n",
      "Requirement already satisfied: protobuf>=3.1.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from paddlepaddle-tiny) (3.12.2)\n",
      "Requirement already satisfied: requests>=2.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from paddlepaddle-tiny) (2.23.0)\n",
      "Requirement already satisfied: setuptools in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from protobuf>=3.1.0->paddlepaddle-tiny) (46.1.3.post20200330)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from requests>=2.0.0->paddlepaddle-tiny) (1.25.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from requests>=2.0.0->paddlepaddle-tiny) (2020.4.5.2)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from requests>=2.0.0->paddlepaddle-tiny) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from requests>=2.0.0->paddlepaddle-tiny) (2.9)\n",
      "\u001b[33mWARNING: You are using pip version 20.2.3; however, version 20.2.4 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/python3/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -i https://pypi.tuna.tsinghua.edu.cn/simple jieba --upgrade\n",
    "!pip install -i https://pypi.tuna.tsinghua.edu.cn/simple paddlepaddle-tiny"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare classification category\n",
    "- All return '\\n' convert to `_` for example `LSC\\n远程指令` convert to `LSC_远程指令`\n",
    "- Convert alphabet to Uppercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba\n",
    "import re\n",
    "import pandas as pd\n",
    "import os\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 读入原始Excel文件，并通过参数 usecols 提取相关列，保存为csv文件，作为算法Raw data输入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "excel_data_df = pd.read_excel('20201026_customer feedback_with comments.xlsx', sheet_name='Sheet1', usecols=['channel', 'Rating', 'Customer Comment', 'Positive or Negative', 'Coding level 1', 'Coding level 2'], index_col=None)\n",
    "#print(excel_data_df[0:5])\n",
    "\n",
    "raw_app_comments_file = 'raw-app-comments-1030.csv'\n",
    "excel_data_df.to_csv(raw_app_comments_file, index=False)\n",
    "sentiment_input_with_def = []\n",
    "sentiment_input_without_def = []\n",
    "sentiment_def= []\n",
    "input_with_category = []\n",
    "input_without_category = []\n",
    "data_offset_counts = {}\n",
    "category_def = []\n",
    "\n",
    "csv_data_df = pd.read_csv(raw_app_comments_file, delimiter=',', index_col=None)\n",
    "#print(csv_data_df[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 处理分类, 如果分类有更新，需要重新运行文件 取消注释 modify_label_file，重新运行\n",
    " - 分类标签处理会去掉换行回车键\n",
    " - 多分类标签，标签之间通过'__'拼接为一条\n",
    " - 字母转换为大写字母\n",
    " - 标签格式：数字,标签字符串，例如1154,互联驾驶使用年限__USABILITY/DIFFICULT TO USE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'APP显示问题': '1001', 'APP版本问题': '1002', 'APP登陆问题': '1003', 'APP车辆信息显示问题': '1004', 'BON': '1005', 'CARLIFE': '1006', 'CARPLAY': '1007', 'ETC': '1008', 'GPS': '1009', 'IBA用户手册': '1010', 'LSC': '1011', 'LSC_远程指令': '1012', 'PIN码': '1013', 'POI': '1014', 'QQ音乐': '1015', 'RSU': '1016', 'RTTI': '1017', 'SIM卡相关': '1019', 'WIFI': '1020', '个性化设置': '1021', '二手车预激活问题': '1022', '会员': '1072', '其他': '1024', '即时充电': '1025', '喜马拉雅': '1026', '地图自动更新服务': '1027', '天猫精灵': '1028', '实时路况功能': '1029', '意见建议': '1030', '数字钥匙': '1031', '智慧停车': '1032', '更新BMW服务': '1033', '满意': '1034', '节日祝福': '1035', '行程摘要': '1036', '行车摘要': '1037', '车机端登录': '1038', '远程3D视图': '1039', '远程指令': '1040', '远程指令_LSC': '1041', '远程服务': '1042', '远程软件升级': '1043', '违章代缴': '1044', '预开通激活': '1045', '预激活开通': '1046', '其他/APP__OTHER': '1047', 'APP/社群__USABILITY/DIFFICULT TO USE': '1048', '车机端BMW CONNECTED/BMW云端互联__LOGINFAULT': '1049', '其他/蓝牙__CONNECTION FAULT': '1050', '其他/APP__USABILITY/DIFFICULT TO USE': '1051', '车机端BMW CONNECTED/BMW云端互联__USABILITY/DIFFICULT TO USE': '1052', '其他__LOGINFAULT': '1053', '价格-PRICE__OTHER': '1054', 'CARPLAY__USABILITY/DIFFICULT TO USE': '1055', '其他-WIFI__USABILITY/DIFFICULT TO USE': '1056', 'APP登录问题__LOGINFAULT': '1057', '车机端BMW CONNECTED/BMW云端互联__OTHER': '1058', '地图自动更新服务__UPDATE NOT POSSIBLE': '1059', '自然语言识别__USABILITY/DIFFICULT TO USE': '1060', '喜马拉雅__USABILITY/DIFFICULT TO USE': '1061', '地图自动更新服务__USABILITY/DIFFICULT TO USE': '1062', '客户改信息__USABILITY/DIFFICULT TO USE': '1063', '互联应用__USABILITY/DIFFICULT TO USE': '1064', '远程3D视图__USABILITY/DIFFICULT TO USE': '1065', '是否配备互联驾驶__USABILITY/DIFFICULT TO USE': '1066', 'APP功能显示__CONNECTION FAULT': '1067', '车机系统升级__OTHER': '1068', '电商__USABILITY/DIFFICULT TO USE': '1069', '社区__OTHER': '1070', '预开通激活__USABILITY/DIFFICULT TO USE': '1071', 'QQ音乐__UPDATE NOT POSSIBLE': '1073', '天猫精灵__CONNECTION FAULT': '1074', '定位__USABILITY/DIFFICULT TO USE': '1075', '车机端BMW CONNECTED/BMW云端互联__CONNECTION FAULT': '1076', '远程指令__USABILITY/DIFFICULT TO USE': '1077', 'NAN': '1078', '价格-PRICE__PRICING': '1079', 'OTHER__UPDATE NOT POSSIBLE': '1080', '远程软件升级__UPDATE NOT POSSIBLE': '1081', '互联驾驶信息更改__USABILITY/DIFFICULT TO USE': '1082', '远程软件升级__USABILITY/DIFFICULT TO USE': '1083', '升级宝马服务__USABILITY/DIFFICULT TO USE': '1084', '目的地__USABILITY/DIFFICULT TO USE': '1085', '意见建议-CONCERN&ADVICE__DESIGN / VISUALS (WEB)': '1086', '车机端BMW CONNECTED/BMW云端互联__UPDATE NOT POSSIBLE': '1087', '其他/APP个性化设置__USABILITY/DIFFICULT TO USE': '1088', '定位__UPDATE NOT POSSIBLE': '1089', '验证码__USABILITY/DIFFICULT TO USE': '1090', 'TCB__TCB': '1091', '账号解绑__USABILITY/DIFFICULT TO USE': '1092', '实时路况功能__USABILITY/DIFFICULT TO USE': '1093', '其他__CONNECTION FAULT': '1094', '其他/APP__CONCERN&ADVICE': '1095', '其他-蓝牙__USABILITY/DIFFICULT TO USE': '1096', 'APP车辆信息显示__CONNECTION FAULT': '1097', '车机端BMW CONNECTED/BMW云端互联__LOADING TIME / INTERACTION SPEED': '1098', '意见建议-CONCERN&ADVICE__TRIP SUMMARY': '1099', '数字钥匙功能__USABILITY/DIFFICULT TO USE': '1100', '行程摘要__USABILITY/DIFFICULT TO USE': '1101', 'APP登录问题__NOT COMPATIBLE': '1102', '远程软件升级__CONNECTION FAULT': '1103', '其他__USABILITY/DIFFICULT TO USE': '1104', '导航__USABILITY/DIFFICULT TO USE': '1105', '远程软件升级__OTHER': '1106', '上门取送车服务__USABILITY/DIFFICULT TO USE': '1107', 'APP车辆配置__USABILITY/DIFFICULT TO USE': '1108', 'WIFI__CONNECTION FAULT': '1109', '见建议-CONCERN&ADVICE__CONCERN&ADVICE': '1110', '充电墙盒__USABILITY/DIFFICULT TO USE': '1111', 'APP功能显示__USABILITY/DIFFICULT TO USE': '1112', '360行车记录仪__USABILITY/DIFFICULT TO USE': '1113', '其他/APP__LOADING TIME / INTERACTION SPEED': '1114', '其他__DESIGN / VISUALS (WEB)': '1115', '社群__USABILITY/DIFFICULT TO USE': '1116', 'DRIVE RECORDER__USABILITY/DIFFICULT TO USE': '1117', '登陆问题__LOGINFAULT': '1118', '互联驾驶信息更改__TBD': '1119', '即时充电__USABILITY/DIFFICULT TO USE': '1120', '意见建议-CONCERN&ADVICE__USABILITY/DIFFICULT TO USE': '1121', '数字钥匙功能__OTHER': '1122', 'APP车辆信息显示__CONVENIENCE': '1123', '其他/APP个性化设置__OTHER': '1124', '验证码__CONNECTION FAULT': '1125', '其他/APP__DESIGN / VISUALS (WEB)': '1126', '其他/APP__CONVENIENCE': '1127', '互联驾驶在线商店__USABILITY/DIFFICULT TO USE': '1128', '紧急救援中心__USABILITY/DIFFICULT TO USE': '1129', '远程指令__DESIGN / VISUALS (WEB)': '1130', '预激活开通__USABILITY/DIFFICULT TO USE': '1131', 'APP功能显示__UPDATE NOT POSSIBLE': '1132', 'APP车辆信息显示__DESIGN / VISUALS (WEB)': '1133', '其他-WIFI__UPDATE NOT POSSIBLE': '1134', 'CARPLAY__CONNECTION FAULT': '1135', '预约保养经销商__UPDATE NOT POSSIBLE': '1136', '兴趣点__USABILITY/DIFFICULT TO USE': '1137', '远程售后服务__USABILITY/DIFFICULT TO USE': '1138', '违章代缴__USABILITY/DIFFICULT TO USE': '1139', '其他/APP__UPDATE NOT POSSIBLE': '1140', '远程指令__UPDATE NOT POSSIBLE': '1141', '节日祝福__USABILITY/DIFFICULT TO USE': '1142', 'WIFI__USABILITY/DIFFICULT TO USE': '1143', '其他__CONVENIENCE': '1144', '其他/APP__CONNECTION FAULT': '1145', 'CARLIFE__USABILITY/DIFFICULT TO USE': '1146', 'APP功能显示__DESIGN / VISUALS (WEB)': '1147', 'QQ音乐__USABILITY/DIFFICULT TO USE': '1148', '会员/优惠券__OTHER': '1149', '其他__UPDATE NOT POSSIBLE': '1150', '远程通风__USABILITY/DIFFICULT TO USE': '1151', '车辆信息显示__USABILITY/DIFFICULT TO USE': '1152', '所有功能无法使用__USABILITY/DIFFICULT TO USE': '1153', '互联驾驶使用年限__USABILITY/DIFFICULT TO USE': '1154', '其他__BRAND POWER': '1155', '远程指令__CONNECTION FAULT': '1156', '其他/APP__LOG OUT': '1157', '步行导航__USABILITY/DIFFICULT TO USE': '1158', '实名认证__USABILITY/DIFFICULT TO USE': '1159', '天气__USABILITY/DIFFICULT TO USE': '1160', '意见建议-CONCERN&ADVICE__OTHER': '1161', '会员__OTHER': '1162', '欢迎词__USABILITY/DIFFICULT TO USE': '1163', '其他/APP__NOT COMPATIBLE': '1164', 'APP车辆信息显示__USABILITY/DIFFICULT TO USE': '1165', '意见建议-CONCERN&ADVICE__CONCERN&ADVICE': '1166', '更新BMW服务__USABILITY/DIFFICULT TO USE': '1167', 'APP登录问题__POPUP': '1168', '预激活__USABILITY/DIFFICULT TO USE': '1169', 'WIFI__PRICING': '1170', '天猫精灵__USABILITY/DIFFICULT TO USE': '1171', 'APP车辆信息显示__UPDATE NOT POSSIBLE': '1172', '其他__OTHER': '1173', '互联驾驶信息更改__OTHER': '1174', 'APP登录问题__USABILITY/DIFFICULT TO USE': '1175', '远程指令__没有远程启动的功能': '1176', 'APP功能显示__OTHER': '1177', '预约保养经销商__USABILITY/DIFFICULT TO USE': '1178', '客户信息更改__USABILITY/DIFFICULT TO USE': '1179', '预激活__OTHER': '1180', '其他/APP__POPUP': '1181'}\n"
     ]
    }
   ],
   "source": [
    "def handle_category_str(coding_level1, coding_level2):\n",
    "    if (coding_level1!='' and pd.notnull(coding_level1)) and (coding_level2!='' and pd.notnull(coding_level2)):\n",
    "        category_str = str(coding_level1).split('\\n', 1)[0] + \"__\" + str(coding_level2).split('\\n', 1)[0]\n",
    "        category_str = category_str.upper()\n",
    "    elif (coding_level1=='' or pd.isnull(coding_level1)):\n",
    "        category_str = str(coding_level2).split('\\n', 1)[0]\n",
    "    elif (coding_level2=='' or pd.isnull(coding_level2)):\n",
    "        category_str = str(coding_level1).split('\\n', 1)[0]\n",
    "    else:\n",
    "        category_str = 'No_Category'\n",
    "    return category_str\n",
    "\n",
    "\n",
    "def modify_label_file(csv_data_df):\n",
    "    for index, data in csv_data_df.iterrows():\n",
    "        coding_level1 = data['Coding level 1']\n",
    "        coding_level2 = data['Coding level 2']\n",
    "        category_str = handle_category_str(coding_level1, coding_level2)\n",
    "        category_def.append(category_str)\n",
    "\n",
    "    category_def_unique = list(set(category_def))\n",
    "    print(category_def_unique)\n",
    "    temp_category_id = 1047\n",
    "    for x in category_def_unique:\n",
    "        category_id = temp_category_id\n",
    "        print(category_id,\",\",x)\n",
    "        temp_category_id +=1\n",
    "\n",
    "#modify_label_file(csv_data_df)\n",
    "        \n",
    "index_to_label = {} #1001:APP显示问题\n",
    "label_to_index = {} #APP显示问题:1001\n",
    "with open(\"app-comments-multiple-label.txt\") as f:\n",
    "    for i,label in enumerate(f.readlines()):\n",
    "        ll = label.strip().split(',')\n",
    "        index_to_label[ll[0]] = ll[1].upper()\n",
    "        label_to_index[ll[1].upper()] = ll[0]\n",
    "print(label_to_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 处理情感数据\n",
    "- Rule of NPS,\n",
    "    - Positive: 10-9\n",
    "    - Neutral: 8-7\n",
    "    - Negative: 6-1\n",
    " \n",
    "- Rule of App store:\n",
    "    - Positive Reviews: 5-4\n",
    "    - Negative Reviews: 3-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NPS\n",
      "Positive\n",
      "Positive\n",
      "Neutral\n",
      "Neutral\n",
      "Negative\n",
      "Negative\n",
      "Negative\n",
      "App Store\n",
      "Positive\n",
      "Positive\n",
      "Negative\n",
      "Negative\n",
      "Negative\n",
      "feedback\n",
      "Positive\n",
      "Neutral\n",
      "Negative\n"
     ]
    }
   ],
   "source": [
    "def get_sentiment(channel, rating, sentiment):\n",
    "    sentiment_switcher = { \n",
    "        \"正向\": \"Positive\", \n",
    "        \"中性\": \"Neutral\", \n",
    "        \"负向\": \"Negative\", \n",
    "    } \n",
    "    return_sentiment = sentiment_switcher.get(sentiment, None) \n",
    "    if channel == 'NPS':\n",
    "        if rating >=9:\n",
    "            return_sentiment = 'Positive'\n",
    "        elif rating >=7:\n",
    "            return_sentiment = 'Neutral'\n",
    "        else:\n",
    "            return_sentiment = 'Negative'\n",
    "    elif channel.endswith(\"App Store\"):\n",
    "        if rating >=4:\n",
    "            return_sentiment = 'Positive'\n",
    "        else:\n",
    "            return_sentiment = 'Negative'\n",
    "    return return_sentiment\n",
    "\n",
    "def unit_test_get_sentiment():\n",
    "    # Unit Test for get_sentiment\n",
    "    print(\"NPS\")\n",
    "    print(get_sentiment(\"NPS\", 9, \"Neutral\"))\n",
    "    print(get_sentiment(\"NPS\", 9, \"Negative\"))\n",
    "    print(get_sentiment(\"NPS\", 7, \"Positive\"))\n",
    "    print(get_sentiment(\"NPS\", 8, \"Negative\"))\n",
    "    print(get_sentiment(\"NPS\", 6, \"Positive\"))\n",
    "    print(get_sentiment(\"NPS\", 5, \"Negative\"))\n",
    "    print(get_sentiment(\"NPS\", 4, \"Neutral\"))\n",
    "    print(\"App Store\")\n",
    "    print(get_sentiment(\"IOS App Store\", 4, \"Neutral\"))\n",
    "    print(get_sentiment(\"Andior App Store\", 5, \"Negative\"))\n",
    "    print(get_sentiment(\"HuaWeiApp Store\", 3, \"Positive\"))\n",
    "    print(get_sentiment(\"Oppp App Store\", 2, \"Negative\"))\n",
    "    print(get_sentiment(\"Xiao Mi App Store\", 1, \"Positive\"))\n",
    "    print(\"feedback\")\n",
    "    print(get_sentiment(\"feedback\", 0, \"正向\"))\n",
    "    print(get_sentiment(\"feedback\", 0, \"中性\"))\n",
    "    print(get_sentiment(\"feedback\", 0, \"负向\"))\n",
    "\n",
    "# Unit Test\n",
    "#unit_test_get_sentiment()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 将原始数据进行预处理\n",
    "- 提取出分类，情感，评论，渠道，评分等\n",
    "- 分为有分类和无分类\n",
    "- 分为有情感类比和无情感类比\n",
    "- 将分类标签格式转换为：index_!_分类标签_!_评论，例如 1011_!_LSC_!_定位不准，乱定位"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_def.clear()\n",
    "input_without_category.clear()\n",
    "input_with_category.clear()\n",
    "sentiment_input_without_def.clear()\n",
    "sentiment_input_with_def.clear()\n",
    "sentiment_def.clear()\n",
    "data_offset_counts.clear()\n",
    "\n",
    "for index, data in csv_data_df.iterrows():\n",
    "    channel_str = data['channel']\n",
    "    rating_num = data.get('Rating',0)\n",
    "    comment_str = data['Customer Comment']\n",
    "    sentiment_str = data['Positive or Negative']\n",
    "    coding_level1 = data['Coding level 1']\n",
    "    coding_level2 = data['Coding level 2']\n",
    "    category_str = handle_category_str(coding_level1, coding_level2)\n",
    "    if (category_str == 'No_Category' or category_str =='nan'):\n",
    "        input_without_category.append(str(comment_str))\n",
    "        #print(channel_str, rating_num, comment_str, sentiment_str, coding_level1, coding_level2)\n",
    "    else:\n",
    "        category_def.append(category_str)\n",
    "        category_index = label_to_index.get(category_str, None)\n",
    "        input_with_category.append(str(category_index) + '_!_' + str(category_str) + '_!_' + str(comment_str))\n",
    "        data_offset_counts[category_str] = data_offset_counts.get(category_str, 0) + 1\n",
    "    \n",
    "    sentiment_result = get_sentiment(channel_str, rating_num, sentiment_str)\n",
    "    if sentiment_str==None or pd.isnull(sentiment_result):\n",
    "        sentiment_input_without_def.append(str(comment_str))\n",
    "    else:\n",
    "        sentiment_input_with_def.append(str(comment_str))\n",
    "        sentiment_def.append(str(sentiment_str))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 预览原始数据预处理结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1173_!_其他__OTHER_!_新的APP', '1173_!_其他__OTHER_!_good job', '1173_!_其他__OTHER_!_145666'] \n",
      "\n",
      "['v', '10', '2'] \n",
      "\n",
      "Excel Sheet to CSV done - csv_data_df:  7578  , input_with_category:  6941  , input_without_category:  637 \n",
      "\n",
      "data offset counts: \n",
      "其他__OTHER    3329\n",
      "其他/APP__USABILITY/DIFFICULT TO USE    897\n",
      "APP车辆信息显示__USABILITY/DIFFICULT TO USE    294\n",
      "远程指令__USABILITY/DIFFICULT TO USE    228\n",
      "其他/APP__CONVENIENCE    206\n",
      "其他__USABILITY/DIFFICULT TO USE    163\n",
      "其他/APP__OTHER    163\n",
      "预激活__USABILITY/DIFFICULT TO USE    154\n",
      "其他/APP__DESIGN / VISUALS (WEB)    152\n",
      "APP车辆信息显示__UPDATE NOT POSSIBLE    142\n",
      "远程3D视图__USABILITY/DIFFICULT TO USE    117\n",
      "会员__OTHER     100\n",
      "预开通激活__USABILITY/DIFFICULT TO USE     88\n",
      "意见建议-CONCERN&ADVICE__CONCERN&ADVICE     51\n",
      "其他/APP__CONNECTION FAULT     49\n",
      "其他__DESIGN / VISUALS (WEB)     48\n",
      "定位__USABILITY/DIFFICULT TO USE     46\n",
      "数字钥匙功能__USABILITY/DIFFICULT TO USE     46\n",
      "其他/APP__UPDATE NOT POSSIBLE     44\n",
      "互联驾驶信息更改__USABILITY/DIFFICULT TO USE     42\n",
      "APP功能显示__USABILITY/DIFFICULT TO USE     38\n",
      "其他__BRAND POWER     38\n",
      "其他/APP个性化设置__USABILITY/DIFFICULT TO USE     32\n",
      "天猫精灵__USABILITY/DIFFICULT TO USE     31\n",
      "其他__CONVENIENCE     30\n",
      "地图自动更新服务__USABILITY/DIFFICULT TO USE     27\n",
      "意见建议-CONCERN&ADVICE__USABILITY/DIFFICULT TO USE     26\n",
      "CARPLAY__USABILITY/DIFFICULT TO USE     25\n",
      "远程软件升级__USABILITY/DIFFICULT TO USE     25\n",
      "QQ音乐__USABILITY/DIFFICULT TO USE     20\n",
      "sentiment:  7578  , sentiment_input_with_def:  7578  , sentiment_input_without_def:  0 \n",
      "\n",
      "\n",
      " sentiment_input with definition:  7578 preview 10 items\n",
      "['新的APP', 'good job', '145666', '测试', '已经成功推荐了', '开通一个月了，什么也用不了，我有脸推荐给谁？', '更新了还可以，但是希望功能强大，车的信号加强。', '功能不全(不能远程启动) 好歹也是M车型', '新颖', '界面不友好，老版直观，']\n"
     ]
    }
   ],
   "source": [
    "print(input_with_category[0:3],'\\n')\n",
    "print(input_without_category[0:3],'\\n')\n",
    "print('Excel Sheet to CSV done - csv_data_df: ',len(csv_data_df), ' , input_with_category: ', len(input_with_category), ' , input_without_category: ', len(input_without_category), '\\n')\n",
    "\n",
    "print('data offset counts: ')\n",
    "items = list(data_offset_counts.items())\n",
    "items.sort(key=lambda x: x[1], reverse=True)\n",
    "for i in range(30):\n",
    "    word, count = items[i]\n",
    "    print(\"{:<10}{:>7}\".format(word, count))\n",
    "\n",
    "print('sentiment: ',len(csv_data_df), ' , sentiment_input_with_def: ', len(sentiment_input_with_def), ' , sentiment_input_without_def: ', len(sentiment_input_without_def), '\\n')\n",
    "print('\\n','sentiment_input with definition: ', len(sentiment_input_with_def), 'preview 10 items')\n",
    "print(sentiment_input_with_def[0:10])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 调用AWS comprehend API 进行情感分析\n",
    "1. 示例检查API是否工作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "喜马拉雅FM可以像QQ音乐一样直接在车上应用么？还是只能在CARPLAY上使用 - sentiment: NEUTRAL - sentiment_score: {\"Positive\": 0.010348141193389893, \"Negative\": 0.09099732339382172, \"Neutral\": 0.8986498713493347, \"Mixed\": 4.764513505506329e-06}\n",
      "\n",
      "你好，为什么在互联驾驶这个功能中定位不了我车了，显示说我在车上的GPS关闭了，但是我检查过了，也开着啊什么问题呢 - sentiment: NEGATIVE - sentiment_score: {\"Positive\": 0.0004973442992195487, \"Negative\": 0.9937689900398254, \"Neutral\": 0.005685589741915464, \"Mixed\": 4.8103760491358116e-05}\n",
      "\n",
      "我喜欢使用互联驾驶这个功能中路线规划 - sentiment: POSITIVE - sentiment_score: {\"Positive\": 0.9950544834136963, \"Negative\": 5.20801440870855e-05, \"Neutral\": 0.004892551805824041, \"Mixed\": 8.196818157557573e-07}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "session = boto3.Session(profile_name='global', region_name='us-east-1')\n",
    "comprehend_client = session.client('comprehend')\n",
    "sample_list = ['喜马拉雅FM可以像QQ音乐一样直接在车上应用么？还是只能在CARPLAY上使用', '你好，为什么在互联驾驶这个功能中定位不了我车了，显示说我在车上的GPS关闭了，但是我检查过了，也开着啊什么问题呢', '我喜欢使用互联驾驶这个功能中路线规划']\n",
    "for s_input in sample_list:\n",
    "    sentiment_response = comprehend_client.detect_sentiment(Text=s_input, LanguageCode='zh')\n",
    "    sentiment_str = sentiment_response['Sentiment']\n",
    "    sentiment_score = json.dumps(sentiment_response['SentimentScore'])\n",
    "    print(s_input + ' - sentiment: ' + sentiment_str + ' - sentiment_score: ' + sentiment_score + '\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 按照25条评论为一组，批量调用batch_detect_sentiment API，并把结果按照如下格式保存\n",
    "\n",
    "```评论 | 情感分析结果 | 置信度```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function TextIOWrapper.close()>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# batch_detect_sentiment \n",
    "sentiment_result_file = 'sentiment_result.csv'\n",
    "\n",
    "if os.path.isfile(sentiment_result_file):\n",
    "    os.remove(sentiment_result_file)\n",
    "\n",
    "with open(sentiment_result_file, 'a+') as sentiment_f:\n",
    "    sentiment_f.write('comment' + '|' + 'sentiment' + '|' + 'sentiment_score' + '\\n')\n",
    "\n",
    "sentiment_chunks = [sentiment_input_with_def[x:x+25] for x in range(0, len(sentiment_input_with_def), 25)]\n",
    "for chunk in sentiment_chunks:\n",
    "    sentiment_response = comprehend_client.batch_detect_sentiment(TextList=chunk, LanguageCode='zh')\n",
    "    #print(sentiment_response['ResultList'])\n",
    "    with open(sentiment_result_file, 'a+') as sentiment_f:\n",
    "        s_input_index = 0\n",
    "        for s_input in chunk:\n",
    "          sentiment_str = sentiment_response['ResultList'][s_input_index]['Sentiment']\n",
    "          sentiment_score = json.dumps(sentiment_response['ResultList'][s_input_index]['SentimentScore'])\n",
    "          sentiment_f.write(s_input + '|' + sentiment_str + '|' + sentiment_score + '\\n')\n",
    "          s_input_index +=1\n",
    "sentiment_f.close"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. 预览情感分析结果前5行，给出总体分析数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    comment sentiment                                    sentiment_score\n",
      "0     新的APP   NEUTRAL  {\"Positive\": 0.0007595693459734321, \"Negative\"...\n",
      "1  good job  POSITIVE  {\"Positive\": 0.9861030578613281, \"Negative\": 0...\n",
      "2    145666   NEUTRAL  {\"Positive\": 0.00029819051269441843, \"Negative...\n",
      "3        测试   NEUTRAL  {\"Positive\": 0.00022875443391967565, \"Negative...\n",
      "4   已经成功推荐了  POSITIVE  {\"Positive\": 0.9979491829872131, \"Negative\": 3...\n",
      "Analysis sentiment done for total item:  7636\n"
     ]
    }
   ],
   "source": [
    "sentiment_data_df = pd.read_csv(sentiment_result_file, delimiter='|', index_col=None)\n",
    "print(sentiment_data_df.head())\n",
    "\n",
    "print('Analysis sentiment done for total item: ', len(sentiment_data_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 中文分词处理\n",
    "1. 利用jieba分词进行处理\n",
    "2. 准备常用的停用词表 - 用于过滤对于推理无关的代词，电话号码，邮箱，时间戳等，用于提高精度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1005_!_RS_!_客户罗先生（车主黄先生的家人）致电，表示其i豪华型车辆，之前已经接到互联驾驶通知协议手机号更改成功的通知，但目前使用新协议手机号登陆云端互联APP后，首页不显示远程控制选项了（更改协议手机号之前可以正常使用），针对此问题，烦请互联驾驶部门跟进处理。 签订互联驾驶协议时登记的车主姓名：黄先生 协议手机号码：（原协议手机号） VIN：LBV5S3104HSN87123 登陆云端互联密码：990308ljq 手机型号&版本：IOS 最新 云端互联APP版本：最新 联系人：罗先生 联系电话：\n",
      "1002_!_Carplay_!_ya_gao 2018-11-01 09:35: 客户杨先生通过在线客户平台反馈，表示在2018/9/1在淮安润宝行店内购买的 530Li 尊享型 豪华套装车辆，客户表示互联驾驶已经开通但是还是没有Apple Carplay的选项，已建议客户发送邮件，针对客户问题烦请互联驾驶人员跟进处理。 联系人/协议手机号码： 车主/联系人：杨先生 车架号：LBVKY5109JSP87501\n",
      "1002_!_Carplay_!_ya_gao 2018-11-01 10:36:2018/11/1 7:53:14客户李先生（车主刘力先生的朋友）致电，表示其（2018.09.29）在（唐山中宝）购买了（525LI M），（10.09）登陆BMW云端互联APP，遇到（CARPLAY无显示、无法使用）问题，已建议客户发送截图至互联驾驶邮箱，针对此问题烦请跟进处理。未转接。协议手机号码：+86\n"
     ]
    }
   ],
   "source": [
    "import logging,os,jieba\n",
    "#!wget https://cdc-code.s3.cn-north-1.amazonaws.com.cn/chineseStopWords.txt\n",
    "def get_stopwords(StopWordFileName):\n",
    "    logging.basicConfig(format='%(asctime)s:%(levelname)s:%(message)s',level=logging.INFO)  \n",
    "      #加载停用词表 \n",
    "    stopword_set = set()\n",
    "    with open(StopWordFileName,'r',encoding=\"utf-8\") as stopwords:\n",
    "        for stopword in stopwords: \n",
    "            stopword_set.add(stopword.strip(\"\\n\"))  \n",
    "    return stopword_set\n",
    "    \n",
    "def clear_timestamp(mystr):\n",
    "    patterns = [r\"\\w{3} \\w{3} \\d{2} \\d{1,2}:\\d{1,2}:\\d{1,2} \\d{4}\\s*\",    #sun aug 19 13:02:10 2018\n",
    "        r\"\\w{3}, \\d{2} \\w{3} \\d{4} \\d{1,2}:\\d{1,2}:\\d{1,2} \\w{2}\\s*\",     #Sun, 19 Aug 2018 13:02:08 ET\n",
    "        r\"\\d{4}-\\d{1,2}-\\d{1,2} \\d{1,2}:\\d{1,2}:\\s*\",                       #2018-11-01 09:35:\n",
    "        r\"\\d{4}/\\d{1,2}/\\d{1,2}\\s*\",                                    #2018/9/1\n",
    "        r\"\\d{1,2}/\\d{1,2}/\\d{4}\\s*\",                                    #9/1/2018\n",
    "        r\"\\d{4}.\\d{1,2}.\\d{0,2}\\s*\",                                    #2018.9.1\n",
    "        r\"\\d{1,2}.\\d{1,2}.\\d{4}\\s*\",                                    #9.1.2018\n",
    "        r\"\\d{4}-\\d{1,2}-\\d{1,2} \\d{1,2}:\\d{1,2}:\\d{4}/\\d{1,2}/\\d{1,2}\\s*\",      #2018-11-01 11:18:2018/10/31\n",
    "        r\"\\d{1,2}:\\d{1,2}:\\d{4}/\\d{1,2}/\\d{1,2}\\s*\",      #2018-11-01 11:18:2018/10/31 21:09:08\n",
    "        r\"\\d{1,2}:\\d{1,2}:\\d{1,2}\\s*(AM|PM|am|pm)\\s*\",        #4:00:58 PM\n",
    "        r\"\\d{1,2}:\\d{1,2}:\\d{1,2}\\s*\",                                     #21:09:08\n",
    "        r\"\\d{1,2}:\\d{1,2}\\s*\",                                     #21:09:08\n",
    "        r\"(\\d{4})年(\\d{1,2})月(\\d{1,2})日\\s*\",                 #2018年10月5日\n",
    "        r\"(\\d{2,4})年\\s*\",                 #2018年\n",
    "        r\"(\\d{4})年(\\d{1,2})月\\s*\",                 #2018年10月\n",
    "        r\":\\s*([\\da-zA_Z]+\\/)+([a-zA-Z0-9\\.]+)\"                     #URL\n",
    "        ]\n",
    "\n",
    "    s = mystr\n",
    "\n",
    "    for p in patterns:\n",
    "        s = re.sub(p,'', s)\n",
    "\n",
    "    s = s.strip()\n",
    "    return s\n",
    "\n",
    "def clear_email_phone_colon(mystr):\n",
    "    patterns = [r\"1[0-9]{10}\", #mobile\n",
    "        r\"(\\(0\\d{2}\\) \\d{8})|(\\(0\\d{3}\\) \\d{7})|(\\(0\\d{3}\\)-\\d{8}$)|(\\(0\\d{2}\\)\\d{8})|(\\(0\\d{3}\\)\\d{7})|(\\(0\\d{3}\\)\\d{8}$)\",                       #phone\n",
    "        r\"(0\\d{2}-\\d{8})|(0\\d{3}-\\d{7})|(0\\d{3}-\\d{8}$)|(\\d{8})\",                       #phone\n",
    "        r\"\\w+([-+.]\\w+)*@\\w+([-.]\\w+)*\\.\\w+([-.]\\w+)*\"    #email\n",
    "        ]\n",
    "\n",
    "    s = mystr\n",
    "\n",
    "    for p in patterns:\n",
    "        s = re.sub(p,'', s)\n",
    "\n",
    "    s = s.strip()\n",
    "    return s\n",
    "\n",
    "# Debug code\n",
    "file  = 'stop-words-test.txt'\n",
    "with open(file) as f:\n",
    "    lines = f.readlines()\n",
    "    \n",
    "labels = []\n",
    "for line in lines:\n",
    "    s = clear_email_phone_colon(line)\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用分词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pip\n",
      "  Downloading pip-20.2.4-py2.py3-none-any.whl (1.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.5 MB 616 kB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: pip\n",
      "  Attempting uninstall: pip\n",
      "    Found existing installation: pip 20.2.3\n",
      "    Uninstalling pip-20.2.3:\n",
      "      Successfully uninstalled pip-20.2.3\n",
      "Successfully installed pip-20.2.4\n",
      "Requirement already satisfied: datetime in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (4.3)\n",
      "Requirement already satisfied: pytz in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from datetime) (2019.3)\n",
      "Requirement already satisfied: zope.interface in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from datetime) (5.1.0)\n",
      "Requirement already satisfied: setuptools in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from zope.interface->datetime) (46.1.3.post20200330)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pip\n",
    "!pip install datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 不同调用jieba的模式，用于迭代数据，找出最佳结果\n",
    "\n",
    "jieba不同模式参考 https://github.com/fxsjy/jieba\n",
    "    \n",
    "当前最佳结果采用了第六种模式\n",
    "    \n",
    "1. with_stop_words_paddle_pseg - 使用停用词，并且启用paddle + pseg模式\n",
    "2. without_stop_words_paddle_pseg - 不使用停用词，并且启用paddle + pseg模式\n",
    "3. without_stop_words_cut - 不使用停用词，并且启用精确模式\n",
    "4. with_stop_words_cut - 使用停用词，并且启用精确模式\n",
    "5. without_stop_words_cut_paddle - 不使用停用词，并且启用paddle + 精确模式\n",
    "6. with_stop_words_cut_paddle - 使用停用词，并且启用paddle + 精确模式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba.posseg as pseg\n",
    "\n",
    "def with_stop_words_paddle_pseg(mystr, word_counts):\n",
    "    #get stopwords\n",
    "    stopwords = get_stopwords('chinesestopwords_test.txt')\n",
    "    #启用停用词过滤\n",
    "    no_phone = clear_email_phone_colon(mystr)\n",
    "    no_timestamp = clear_timestamp(no_phone)\n",
    "    fenci = re.sub(r\"[\\s+\\.\\!\\/_,$%^*()?;；:-【】+\\\"\\']+|[+——一！，;:：。？、~@#￥%……&*（）]+\", \"\", no_timestamp)\n",
    "    words = pseg.cut(fenci,use_paddle=True) #paddle模式+posseg\n",
    "    filled_words = set()\n",
    "    for word, flag in words:\n",
    "        #print('raw %s %s' % (word, flag))\n",
    "        # 人名, 地名，机构，方位名词, 量词, 代词, 时间, 副词\n",
    "        if (flag == 'nr' or flag == 'ns' or flag == 'PER' \n",
    "            or flag == 'LOC' or flag == 'ORG' or flag == 'f' or flag == 'r' or flag == 'q'\n",
    "            or flag == 't' or flag == 'TIME' or flag == 'd'):\n",
    "            #print('%s %s' % (word, flag))\n",
    "            continue\n",
    "        else:\n",
    "            if word not in stopwords:          #不在停用词表中\n",
    "                if len(word) == 1:\n",
    "                    continue\n",
    "                else:\n",
    "                    word_counts[word] = word_counts.get(word, 0) + 1\n",
    "                filled_words.add(word)\n",
    "    return filled_words\n",
    "\n",
    "\n",
    "def without_stop_words_paddle_pseg(mystr, word_counts):\n",
    "    #get stopwords\n",
    "    stopwords = get_stopwords('chinesestopwords_test.txt')\n",
    "    #启用停用词过滤\n",
    "    no_phone = clear_email_phone_colon(mystr)\n",
    "    no_timestamp = clear_timestamp(no_phone)\n",
    "    fenci = re.sub(r\"[\\s+\\.\\!\\/_,$%^*()?;；:-【】+\\\"\\']+|[+——一！，;:：。？、~@#￥%……&*（）]+\", \"\", no_timestamp)\n",
    "    words = pseg.cut(fenci,use_paddle=True) #paddle模式+posseg\n",
    "    filled_words = set()\n",
    "    for word, flag in words:\n",
    "        #print('raw %s %s' % (word, flag))\n",
    "        # 人名, 地名，机构，方位名词, 量词, 代词, 时间, 副词\n",
    "        if (flag == 'nr' or flag == 'ns' or flag == 'PER' \n",
    "            or flag == 'LOC' or flag == 'ORG' or flag == 'f' or flag == 'r' or flag == 'q'\n",
    "            or flag == 't' or flag == 'TIME' or flag == 'd'):\n",
    "            #print('%s %s' % (word, flag))\n",
    "            continue\n",
    "        else:\n",
    "            if len(word) == 1:\n",
    "                continue\n",
    "            else:\n",
    "                word_counts[word] = word_counts.get(word, 0) + 1\n",
    "        filled_words.add(word)\n",
    "    return filled_words\n",
    "\n",
    "def without_stop_words_cut(mystr, word_counts): \n",
    "    #get stopwords\n",
    "    stopwords = get_stopwords('chinesestopwords_test.txt')\n",
    "    #启用停用词过滤\n",
    "    no_phone = clear_email_phone_colon(mystr)\n",
    "    no_timestamp = clear_timestamp(no_phone)\n",
    "    fenci = re.sub(r\"[\\s+\\.\\!\\/_,$%^*()?;；:-【】+\\\"\\']+|[+——一！，;:：。？、~@#￥%……&*（）]+\", \"\", no_timestamp)\n",
    "    words = jieba.cut(fenci,cut_all=False)\n",
    "    filled_words = set()\n",
    "    for word in words:\n",
    "        #print('raw %s %s' % (word, flag))\n",
    "        if len(word) == 1:\n",
    "            continue\n",
    "        else:\n",
    "            word_counts[word] = word_counts.get(word, 0) + 1\n",
    "        filled_words.add(word)\n",
    "    return filled_words\n",
    "\n",
    "\n",
    "def with_stop_words_cut(mystr, word_counts): \n",
    "    #get stopwords\n",
    "    stopwords = get_stopwords('chinesestopwords_test.txt')\n",
    "    #启用停用词过滤\n",
    "    no_phone = clear_email_phone_colon(mystr)\n",
    "    no_timestamp = clear_timestamp(no_phone)\n",
    "    fenci = re.sub(r\"[\\s+\\.\\!\\/_,$%^*()?;；:-【】+\\\"\\']+|[+——一！，;:：。？、~@#￥%……&*（）]+\", \"\", no_timestamp)\n",
    "    words = jieba.cut(fenci,cut_all=False)\n",
    "    filled_words = set()\n",
    "    for word in words:\n",
    "        #print('raw %s %s' % (word, flag))\n",
    "        # 人名, 地名，机构，方位名词, 量词, 代词, 时间, 副词\n",
    "        if word not in stopwords:          #不在停用词表中\n",
    "            if len(word) == 1:\n",
    "                continue\n",
    "            else:\n",
    "                word_counts[word] = word_counts.get(word, 0) + 1\n",
    "            filled_words.add(word)\n",
    "    return filled_words\n",
    "\n",
    "\n",
    "def without_stop_words_cut_paddle(mystr, word_counts): \n",
    "    #get stopwords\n",
    "    stopwords = get_stopwords('chinesestopwords_test.txt')\n",
    "    #启用停用词过滤\n",
    "    no_phone = clear_email_phone_colon(mystr)\n",
    "    no_timestamp = clear_timestamp(no_phone)\n",
    "    fenci = re.sub(r\"[\\s+\\.\\!\\/_,$%^*()?;；:-【】+\\\"\\']+|[+——一！，;:：。？、~@#￥%……&*（）]+\", \"\", no_timestamp)\n",
    "    words = jieba.cut(fenci,use_paddle=True) #paddle模式\n",
    "    filled_words = set()\n",
    "    for word in words:\n",
    "        #print('raw %s %s' % (word, flag))\n",
    "        if len(word) == 1:\n",
    "            continue\n",
    "        else:\n",
    "            word_counts[word] = word_counts.get(word, 0) + 1\n",
    "        filled_words.add(word)\n",
    "    return filled_words\n",
    "\n",
    "\n",
    "def with_stop_words_cut_paddle(mystr, word_counts):   \n",
    "    #get stopwords\n",
    "    stopwords = get_stopwords('chinesestopwords_test.txt')\n",
    "    #启用停用词过滤\n",
    "    no_phone = clear_email_phone_colon(mystr)\n",
    "    no_timestamp = clear_timestamp(no_phone)\n",
    "    fenci = re.sub(r\"[\\s+\\.\\!\\/_,$%^*()?;；:-【】+\\\"\\']+|[+——一！，;:：。？、~@#￥%……&*（）]+\", \"\", no_timestamp)\n",
    "    words = jieba.cut(fenci,cut_all=False,use_paddle=True) #paddle模式\n",
    "    filled_words = set()\n",
    "    for word in words:\n",
    "        #print('raw %s %s' % (word, flag))\n",
    "        # 人名, 地名，机构，方位名词, 量词, 代词, 时间, 副词\n",
    "        if word not in stopwords:          #不在停用词表中\n",
    "            if len(word) == 1:\n",
    "                continue\n",
    "            else:\n",
    "                word_counts[word] = word_counts.get(word, 0) + 1\n",
    "            filled_words.add(word)\n",
    "    return filled_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 执行分词解析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Paddle enabled successfully......\n",
      "2020-11-05 11:19:10,677:DEBUG:Paddle enabled successfully......\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data processing time 24\n",
      "[['__label__意见建议-CONCERN&ADVICE__OTHER', '有待', '软件', '改进', '功能'], ['__label__其他/APP__OTHER'], ['__label__其他/APP__USABILITY/DIFFICULT TO USE', '实用'], ['__label__其他__OTHER', '还行'], ['__label__其他/APP__USABILITY/DIFFICULT TO USE', '很好']]\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "\n",
    "#单机并行分词\n",
    "#jieba.enable_parallel(8)\n",
    "#paddle模式，精确匹配需要关闭parallel\n",
    "jieba.disable_parallel()\n",
    "#启动paddle模式\n",
    "jieba.enable_paddle()\n",
    "\n",
    "begin = datetime.datetime.now()\n",
    "    \n",
    "labels = []\n",
    "counts = {}                 #计数{word，frequency}\n",
    "for line in input_with_category:\n",
    "    label = []\n",
    "    line = line.split('_!_')\n",
    "    if line[0].strip('\"').isdigit() and index_to_label[line[0].strip('\"')]:\n",
    "        label_code = index_to_label[line[0].strip('\"')]\n",
    "        label.append('__label__' + label_code)\n",
    "        \n",
    "        words_after_jieba = with_stop_words_cut_paddle(line[2], counts)\n",
    "        \n",
    "        label.extend(words_after_jieba)\n",
    "        #print(label)\n",
    "        labels.append(label)\n",
    "\n",
    "shuffle(labels)\n",
    "\n",
    "end = datetime.datetime.now()\n",
    "print('data processing time %d' %(end - begin).seconds)\n",
    "print(labels[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 检查常见词词频"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "功能            618\n",
      "车辆            599\n",
      "宝马            431\n",
      "互联            425\n",
      "更新            363\n",
      "远程            290\n",
      "驾驶            287\n",
      "信息            268\n",
      "喜欢            240\n",
      "很好            237\n",
      "服务            234\n",
      "显示            225\n",
      "定位            176\n",
      "不错            166\n",
      "激活            163\n",
      "云端            152\n",
      "状态            147\n",
      "界面            142\n",
      "开通            134\n",
      "推荐            131\n",
      "体验            125\n",
      "手机            122\n",
      "实用            120\n",
      "操控            116\n",
      "软件            115\n",
      "系统            112\n",
      "会员            108\n",
      "希望            104\n",
      "朋友             99\n",
      "品牌             97\n"
     ]
    }
   ],
   "source": [
    "items = list(counts.items())\n",
    "items.sort(key=lambda x: x[1], reverse=True)\n",
    "for i in range(30):\n",
    "    word, count = items[i]\n",
    "    print(\"{:<10}{:>7}\".format(word, count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 切分训练集和验证集数据\n",
    "1. 按照80：20比例进行切分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = 'classification/blazingtext/bmwticket'\n",
    "t_train_data = labels[0:int(len(labels)*0.8)]\n",
    "t_validation_data = labels[int(len(labels)*0.8):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#t_train_data[0:13]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 保存切分好的训练集和验证集数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "t_train_file = 'tt.train'\n",
    "t_validation_file = 'tt.validation'\n",
    "\n",
    "with open(t_train_file, 'w') as csvoutfile:\n",
    "    csv_writer = csv.writer(csvoutfile, delimiter=' ', lineterminator='\\n')\n",
    "    csv_writer.writerows(t_train_data)\n",
    "    \n",
    "with open(t_validation_file, 'w') as csvoutfile:\n",
    "    csv_writer = csv.writer(csvoutfile, delimiter=' ', lineterminator='\\n')\n",
    "    csv_writer.writerows(t_validation_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. 上传到S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 63.1 ms, sys: 8.26 ms, total: 71.4 ms\n",
      "Wall time: 401 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "t_train_channel = prefix + '/train'\n",
    "t_validation_channel = prefix + '/validation'\n",
    "\n",
    "sess.upload_data(path='tt.train', bucket=bucket, key_prefix=t_train_channel)\n",
    "sess.upload_data(path='tt.validation', bucket=bucket, key_prefix=t_validation_channel)\n",
    "\n",
    "s3_train_data = 's3://{}/{}'.format(bucket, t_train_channel)\n",
    "s3_validation_data = 's3://{}/{}'.format(bucket, t_validation_channel)\n",
    "\n",
    "s3_output_location = 's3://{}/{}/output'.format(bucket, prefix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用BlazingText算法进行评论分类\n",
    "\n",
    "1. 加载SageMaker BlazingText container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-11-05 09:03:17,293:WARNING:'get_image_uri' method will be deprecated in favor of 'ImageURIProvider' class in SageMaker Python SDK v2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using SageMaker BlazingText container: 390948362332.dkr.ecr.cn-north-1.amazonaws.com.cn/blazingtext:latest (cn-north-1)\n"
     ]
    }
   ],
   "source": [
    "region_name = boto3.Session().region_name\n",
    "container = sagemaker.amazon.amazon_estimator.get_image_uri(region_name, \"blazingtext\", \"latest\")\n",
    "print('Using SageMaker BlazingText container: {} ({})'.format(container, region_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 配置BlazingText预测模型和超参调优"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-11-05 09:29:20,306:WARNING:Parameter image_name will be renamed to image_uri in SageMaker Python SDK v2.\n"
     ]
    }
   ],
   "source": [
    "t_bt_model = sagemaker.estimator.Estimator(container,\n",
    "                                         role, \n",
    "                                         train_instance_count=1, \n",
    "                                         train_instance_type='ml.c4.4xlarge',\n",
    "                                         train_volume_size = 120,\n",
    "                                         train_max_run = 360000,\n",
    "                                         input_mode= 'File',\n",
    "                                         output_path=s3_output_location,\n",
    "                                         sagemaker_session=sess)\n",
    "t_bt_model.set_hyperparameters(\n",
    "    mode=\"supervised\",\n",
    "    epochs=20,\n",
    "    min_count=2,\n",
    "    learning_rate=0.1,\n",
    "    vector_dim=10,\n",
    "    early_stopping=True,\n",
    "    patience=4,\n",
    "    min_epochs=5,\n",
    "    word_ngrams=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. 准备模型输入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-11-05 09:29:23,078:WARNING:'s3_input' class will be renamed to 'TrainingInput' in SageMaker Python SDK v2.\n",
      "2020-11-05 09:29:23,079:WARNING:'s3_input' class will be renamed to 'TrainingInput' in SageMaker Python SDK v2.\n"
     ]
    }
   ],
   "source": [
    "t_train_data = sagemaker.inputs.s3_input(s3_train_data, distribution='FullyReplicated', \n",
    "                        content_type='text/plain', s3_data_type='S3Prefix')\n",
    "t_validation_data = sagemaker.inputs.s3_input(s3_validation_data, distribution='FullyReplicated', \n",
    "                             content_type='text/plain', s3_data_type='S3Prefix')\n",
    "t_data_channels = {'train': t_train_data, 'validation': t_validation_data}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. 模型训练执行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-11-05 09:46:32,206:INFO:Creating training-job with name: blazingtext-2020-11-05-09-46-32-206\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-11-05 09:46:32 Starting - Starting the training job...\n",
      "2020-11-05 09:46:34 Starting - Launching requested ML instances......\n",
      "2020-11-05 09:48:03 Starting - Preparing the instances for training.........\n",
      "2020-11-05 09:49:33 Downloading - Downloading input data\n",
      "2020-11-05 09:49:33 Training - Downloading the training image...\n",
      "2020-11-05 09:49:57 Uploading - Uploading generated training model\u001b[34mArguments: train\u001b[0m\n",
      "\u001b[34m[11/05/2020 09:49:47 WARNING 140437587171136] Loggers have already been setup.\u001b[0m\n",
      "\u001b[34m[11/05/2020 09:49:47 WARNING 140437587171136] Loggers have already been setup.\u001b[0m\n",
      "\u001b[34m[11/05/2020 09:49:47 INFO 140437587171136] nvidia-smi took: 0.0252230167389 secs to identify 0 gpus\u001b[0m\n",
      "\u001b[34m[11/05/2020 09:49:47 INFO 140437587171136] Running single machine CPU BlazingText training using supervised mode.\u001b[0m\n",
      "\u001b[34m[11/05/2020 09:49:47 INFO 140437587171136] Processing /opt/ml/input/data/train/tt.train . File size: 0 MB\u001b[0m\n",
      "\u001b[34m[11/05/2020 09:49:47 INFO 140437587171136] Processing /opt/ml/input/data/validation/tt.validation . File size: 0 MB\u001b[0m\n",
      "\u001b[34mRead 0M words\u001b[0m\n",
      "\u001b[34mNumber of words:  1207\u001b[0m\n",
      "\u001b[34mLoading validation data from /opt/ml/input/data/validation/tt.validation\u001b[0m\n",
      "\u001b[34mLoaded validation data.\u001b[0m\n",
      "\u001b[34m-------------- End of epoch: 2\u001b[0m\n",
      "\u001b[34m##### Alpha: -0.0000  Progress: 100.02%  Million Words/sec: 5.63 #####\u001b[0m\n",
      "\u001b[34m-------------- End of epoch: 20\u001b[0m\n",
      "\u001b[34mUsing 16 threads for prediction!\u001b[0m\n",
      "\u001b[34mValidation accuracy: 0.869785\u001b[0m\n",
      "\u001b[34mValidation accuracy improved! Storing best weights...\u001b[0m\n",
      "\u001b[34m##### Alpha: 0.0000  Progress: 100.00%  Million Words/sec: 5.12 #####\n",
      "\u001b[0m\n",
      "\u001b[34mTraining finished.\u001b[0m\n",
      "\u001b[34mAverage throughput in Million words/sec: 5.12\u001b[0m\n",
      "\u001b[34mTotal training time in seconds: 0.12\n",
      "\u001b[0m\n",
      "\u001b[34m#train_accuracy: 0.8964\u001b[0m\n",
      "\u001b[34mNumber of train examples: 3146\n",
      "\u001b[0m\n",
      "\u001b[34m#validation_accuracy: 0.8698\u001b[0m\n",
      "\u001b[34mNumber of validation examples: 1389\u001b[0m\n",
      "\n",
      "2020-11-05 09:50:04 Completed - Training job completed\n",
      "Training seconds: 48\n",
      "Billable seconds: 48\n"
     ]
    }
   ],
   "source": [
    "t_bt_model.fit(inputs=t_data_channels, logs=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 执行推理\n",
    "\n",
    "***注意在模型训练和调优达到需要的精度前，请勿执行模型推理的端点的部署***\n",
    "\n",
    "1. 部署模型端点"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-11-05 10:33:33,894:WARNING:Parameter image will be renamed to image_uri in SageMaker Python SDK v2.\n",
      "2020-11-05 10:33:33,897:INFO:Creating model with name: blazingtext-2020-11-05-09-46-32-206\n",
      "2020-11-05 10:33:35,005:WARNING:Using already existing model: blazingtext-2020-11-05-09-46-32-206\n",
      "2020-11-05 10:33:35,057:INFO:Creating endpoint with name blazingtext-2020-11-05-09-46-32-206\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------!"
     ]
    }
   ],
   "source": [
    "t_text_classifier = t_bt_model.deploy(initial_instance_count = 1,instance_type = 'ml.c5.large')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 执行推理，利用输入数据中无分类的数据进行推理，精度要求85%以上"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total predict:  637  , >  0.85  confidence:  637\n"
     ]
    }
   ],
   "source": [
    "predict_category_result_file = 'predict_category_result.csv'\n",
    "low_confidence = [] # confidence<confidence_thredhold\n",
    "confidence_thredhold = 0.85\n",
    "\n",
    "if os.path.isfile(predict_category_result_file):\n",
    "    os.remove(predict_category_result_file)\n",
    "\n",
    "with open(predict_category_result_file, 'a+') as predict_f:\n",
    "    predict_f.write('category' + '|' + 'comment' + '|' + 'confidence' + '\\n')\n",
    "\n",
    "# #单机并行分词\n",
    "# jieba.enable_parallel(8)\n",
    "# #paddle模式，精确匹配需要关闭parallel\n",
    "# #jieba.disable_parallel()\n",
    "# #启动paddle模式\n",
    "# jieba.enable_paddle()\n",
    "\n",
    "for sentences in input_without_category:\n",
    "    counts = {} \n",
    "    # using the same nltk tokenizer that we used during data preparation for training\n",
    "    tokenized_sentences = [' '.join(with_stop_words_cut(sentences, counts))]\n",
    "    #print('sentences: ', sentences, ' , jieba: ', tokenized_sentences)\n",
    "\n",
    "    #payload = {\"instances\" : tokenized_sentences, \"configuration\": {\"k\": 2}}\n",
    "    payload = {\"instances\" : tokenized_sentences}\n",
    "\n",
    "    t_response = t_text_classifier.predict(json.dumps(payload))\n",
    "\n",
    "    t_predictions = json.loads(t_response)\n",
    "    #print(json.dumps(t_predictions, indent=2))\n",
    "    predict_prob = t_predictions[0]['prob'][0]\n",
    "    predict_category = t_predictions[0]['label'][0]\n",
    "    if predict_prob < confidence_thredhold:\n",
    "        low_confidence.append(sentences + '|' + predict_category + '|' + str(predict_prob) + '\\n')\n",
    "    \n",
    "    with open(predict_category_result_file, 'a+') as predict_f:\n",
    "        predict_f.write(sentences + '|' + predict_category + '|' + str(predict_prob) + '\\n')\n",
    "\n",
    "predict_f.close\n",
    "print('total predict: ', len(input_without_category), ' , > ', confidence_thredhold, ' confidence: ', len(input_without_category) - len(low_confidence))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. 预测完毕，删除推理端点，节省费用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-11-05 11:20:17,441:INFO:Deleting endpoint configuration with name: blazingtext-2020-11-05-09-46-32-206\n",
      "2020-11-05 11:20:17,537:INFO:Deleting endpoint with name: blazingtext-2020-11-05-09-46-32-206\n"
     ]
    }
   ],
   "source": [
    "t_text_classifier.delete_endpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
