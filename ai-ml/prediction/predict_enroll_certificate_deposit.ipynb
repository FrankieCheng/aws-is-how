{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict whether a customer will enroll for a certificate of deposit (CD)\n",
    "\n",
    "This demo predict whether a customer will enroll for a certificate of deposit (CD)\n",
    "\n",
    "The data has been labeled for your convenience and a column in the dataset identifies whether the customer is enrolled for a product offered by the bank. A version of this dataset is publicly available from the ML repository curated by the University of California, Irvine. This tutorial implements a supervised machine learning model since the data is labeled."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success - the MySageMakerInstance is in the us-east-1 region. You will use the 811284229777.dkr.ecr.us-east-1.amazonaws.com/xgboost:latest container for your SageMaker endpoint.\n"
     ]
    }
   ],
   "source": [
    "# import libraries\n",
    "import boto3, re, sys, math, json, os, sagemaker, urllib.request\n",
    "from sagemaker import get_execution_role\n",
    "import numpy as np                                \n",
    "import pandas as pd                               \n",
    "import matplotlib.pyplot as plt                   \n",
    "from IPython.display import Image                 \n",
    "from IPython.display import display               \n",
    "from time import gmtime, strftime                 \n",
    "from sagemaker.predictor import csv_serializer   \n",
    "\n",
    "# Define IAM role\n",
    "role = get_execution_role()\n",
    "prefix = 'sagemaker/DEMO-xgboost-dm'\n",
    "containers = {'us-west-2': '433757028032.dkr.ecr.us-west-2.amazonaws.com/xgboost:latest',\n",
    "              'us-east-1': '811284229777.dkr.ecr.us-east-1.amazonaws.com/xgboost:latest',\n",
    "              'us-east-2': '825641698319.dkr.ecr.us-east-2.amazonaws.com/xgboost:latest',\n",
    "              'eu-west-1': '685385470294.dkr.ecr.eu-west-1.amazonaws.com/xgboost:latest'} # each region has its XGBoost container\n",
    "my_region = boto3.session.Session().region_name # set the region of the instance\n",
    "print(\"Success - the MySageMakerInstance is in the \" + my_region + \" region. You will use the \" + containers[my_region] + \" container for your SageMaker endpoint.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket_name = 'sagemaker-us-east-1-710299592439' # <--- CHANGE THIS VARIABLE TO A UNIQUE NAME FOR YOUR BUCKET\n",
    "s3 = boto3.resource('s3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success: downloaded bank_clean.csv.\n",
      "Success: Data loaded into dataframe.\n",
      "   age  campaign  pdays  previous  no_previous_contact  not_working  \\\n",
      "0   56         1    999         0                    1            0   \n",
      "1   57         1    999         0                    1            0   \n",
      "2   37         1    999         0                    1            0   \n",
      "3   40         1    999         0                    1            0   \n",
      "4   56         1    999         0                    1            0   \n",
      "5   45         1    999         0                    1            0   \n",
      "6   59         1    999         0                    1            0   \n",
      "7   41         1    999         0                    1            0   \n",
      "8   24         1    999         0                    1            0   \n",
      "9   25         1    999         0                    1            0   \n",
      "\n",
      "   job_admin.  job_blue-collar  job_entrepreneur  job_housemaid  ...  \\\n",
      "0           0                0                 0              1  ...   \n",
      "1           0                0                 0              0  ...   \n",
      "2           0                0                 0              0  ...   \n",
      "3           1                0                 0              0  ...   \n",
      "4           0                0                 0              0  ...   \n",
      "5           0                0                 0              0  ...   \n",
      "6           1                0                 0              0  ...   \n",
      "7           0                1                 0              0  ...   \n",
      "8           0                0                 0              0  ...   \n",
      "9           0                0                 0              0  ...   \n",
      "\n",
      "   day_of_week_fri  day_of_week_mon  day_of_week_thu  day_of_week_tue  \\\n",
      "0                0                1                0                0   \n",
      "1                0                1                0                0   \n",
      "2                0                1                0                0   \n",
      "3                0                1                0                0   \n",
      "4                0                1                0                0   \n",
      "5                0                1                0                0   \n",
      "6                0                1                0                0   \n",
      "7                0                1                0                0   \n",
      "8                0                1                0                0   \n",
      "9                0                1                0                0   \n",
      "\n",
      "   day_of_week_wed  poutcome_failure  poutcome_nonexistent  poutcome_success  \\\n",
      "0                0                 0                     1                 0   \n",
      "1                0                 0                     1                 0   \n",
      "2                0                 0                     1                 0   \n",
      "3                0                 0                     1                 0   \n",
      "4                0                 0                     1                 0   \n",
      "5                0                 0                     1                 0   \n",
      "6                0                 0                     1                 0   \n",
      "7                0                 0                     1                 0   \n",
      "8                0                 0                     1                 0   \n",
      "9                0                 0                     1                 0   \n",
      "\n",
      "   y_no  y_yes  \n",
      "0     1      0  \n",
      "1     1      0  \n",
      "2     1      0  \n",
      "3     1      0  \n",
      "4     1      0  \n",
      "5     1      0  \n",
      "6     1      0  \n",
      "7     1      0  \n",
      "8     1      0  \n",
      "9     1      0  \n",
      "\n",
      "[10 rows x 61 columns]\n"
     ]
    }
   ],
   "source": [
    "# Download dataset\n",
    "try:\n",
    "  urllib.request.urlretrieve (\"https://d1.awsstatic.com/tmt/build-train-deploy-machine-learning-model-sagemaker/bank_clean.27f01fbbdf43271788427f3682996ae29ceca05d.csv\", \"bank_clean.csv\")\n",
    "  print('Success: downloaded bank_clean.csv.')\n",
    "except Exception as e:\n",
    "  print('Data load error: ',e)\n",
    "\n",
    "try:\n",
    "  model_data = pd.read_csv('./bank_clean.csv',index_col=0)\n",
    "  print('Success: Data loaded into dataframe.')\n",
    "  print(model_data[:10])\n",
    "except Exception as e:\n",
    "    print('Data load error: ',e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shuffle the data and split into training and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28831, 61) (12357, 61)\n"
     ]
    }
   ],
   "source": [
    "train_data, test_data = np.split(model_data.sample(frac=1, random_state=1729), [int(0.7 * len(model_data))])\n",
    "print(train_data.shape, test_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model\n",
    "\n",
    "To use an Amazon SageMaker pre-built XGBoost model, you will need to reformat the header and first column of the training data and load the data from the S3 bucket. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:sagemaker:'s3_input' class will be renamed to 'TrainingInput' in SageMaker Python SDK v2.\n"
     ]
    }
   ],
   "source": [
    "pd.concat([train_data['y_yes'], train_data.drop(['y_no', 'y_yes'], axis=1)], axis=1).to_csv('train.csv', index=False, header=False)\n",
    "boto3.Session().resource('s3').Bucket(bucket_name).Object(os.path.join(prefix, 'train/train.csv')).upload_file('train.csv')\n",
    "s3_input_train = sagemaker.s3_input(s3_data='s3://{}/{}/train'.format(bucket_name, prefix), content_type='csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Parameter image_name will be renamed to image_uri in SageMaker Python SDK v2.\n"
     ]
    }
   ],
   "source": [
    "# create the XGboost model\n",
    "sess = sagemaker.Session()\n",
    "xgb = sagemaker.estimator.Estimator(containers[my_region],\n",
    "                                    role, train_instance_count=1, \n",
    "                                    train_instance_type='ml.m4.xlarge',\n",
    "                                    output_path='s3://{}/{}/output'.format(bucket_name, prefix),\n",
    "                                    sagemaker_session=sess)\n",
    "xgb.set_hyperparameters(max_depth=5,\n",
    "                        eta=0.2,\n",
    "                        gamma=4,\n",
    "                        min_child_weight=6,\n",
    "                        subsample=0.8,\n",
    "                        silent=0,\n",
    "                        objective='binary:logistic',\n",
    "                        num_round=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-07-01 10:30:10 Starting - Starting the training job...\n",
      "2020-07-01 10:30:13 Starting - Launching requested ML instances.........\n",
      "2020-07-01 10:31:57 Starting - Preparing the instances for training......\n",
      "2020-07-01 10:33:04 Downloading - Downloading input data...\n",
      "2020-07-01 10:33:27 Training - Downloading the training image..\u001b[34mArguments: train\u001b[0m\n",
      "\u001b[34m[2020-07-01:10:33:48:INFO] Running standalone xgboost training.\u001b[0m\n",
      "\u001b[34m[2020-07-01:10:33:48:INFO] Path /opt/ml/input/data/validation does not exist!\u001b[0m\n",
      "\u001b[34m[2020-07-01:10:33:48:INFO] File size need to be processed in the node: 3.38mb. Available memory size in the node: 8506.04mb\u001b[0m\n",
      "\u001b[34m[2020-07-01:10:33:48:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[10:33:48] S3DistributionType set as FullyReplicated\u001b[0m\n",
      "\u001b[34m[10:33:48] 28831x59 matrix with 1701029 entries loaded from /opt/ml/input/data/train?format=csv&label_column=0&delimiter=,\u001b[0m\n",
      "\u001b[34m[10:33:48] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 14 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[0]#011train-error:0.100482\u001b[0m\n",
      "\u001b[34m[10:33:48] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 28 extra nodes, 16 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[1]#011train-error:0.099858\u001b[0m\n",
      "\u001b[34m[10:33:48] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 32 extra nodes, 18 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[2]#011train-error:0.099476\u001b[0m\n",
      "\u001b[34m[10:33:48] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 32 extra nodes, 14 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[3]#011train-error:0.099025\u001b[0m\n",
      "\u001b[34m[10:33:48] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 18 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[4]#011train-error:0.099476\u001b[0m\n",
      "\u001b[34m[10:33:48] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 32 extra nodes, 8 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[5]#011train-error:0.099372\u001b[0m\n",
      "\u001b[34m[10:33:49] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 28 extra nodes, 12 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[6]#011train-error:0.09906\u001b[0m\n",
      "\u001b[34m[10:33:49] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 20 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[7]#011train-error:0.099025\u001b[0m\n",
      "\u001b[34m[10:33:49] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 26 extra nodes, 24 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[8]#011train-error:0.099164\u001b[0m\n",
      "\u001b[34m[10:33:49] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 12 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[9]#011train-error:0.098817\u001b[0m\n",
      "\u001b[34m[10:33:49] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 30 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[10]#011train-error:0.098817\u001b[0m\n",
      "\u001b[34m[10:33:49] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 26 extra nodes, 22 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[11]#011train-error:0.098817\u001b[0m\n",
      "\u001b[34m[10:33:49] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 26 extra nodes, 22 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[12]#011train-error:0.098852\u001b[0m\n",
      "\u001b[34m[10:33:49] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 28 extra nodes, 16 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[13]#011train-error:0.098574\u001b[0m\n",
      "\u001b[34m[10:33:49] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 28 extra nodes, 18 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[14]#011train-error:0.098609\u001b[0m\n",
      "\u001b[34m[10:33:49] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 32 extra nodes, 8 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[15]#011train-error:0.098401\u001b[0m\n",
      "\u001b[34m[10:33:49] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 26 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[16]#011train-error:0.098401\u001b[0m\n",
      "\u001b[34m[10:33:49] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 22 extra nodes, 20 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[17]#011train-error:0.098297\u001b[0m\n",
      "\u001b[34m[10:33:49] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 26 extra nodes, 18 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[18]#011train-error:0.098054\u001b[0m\n",
      "\u001b[34m[10:33:49] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 20 extra nodes, 14 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[19]#011train-error:0.098158\u001b[0m\n",
      "\u001b[34m[10:33:49] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 22 extra nodes, 8 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[20]#011train-error:0.098193\u001b[0m\n",
      "\u001b[34m[10:33:49] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 36 extra nodes, 8 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[21]#011train-error:0.098193\u001b[0m\n",
      "\u001b[34m[10:33:49] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 28 extra nodes, 22 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[22]#011train-error:0.098124\u001b[0m\n",
      "\u001b[34m[10:33:49] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 16 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[23]#011train-error:0.098124\u001b[0m\n",
      "\u001b[34m[10:33:49] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 20 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[24]#011train-error:0.097881\u001b[0m\n",
      "\u001b[34m[10:33:49] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 34 extra nodes, 4 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[25]#011train-error:0.097777\u001b[0m\n",
      "\u001b[34m[10:33:49] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 22 extra nodes, 14 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[26]#011train-error:0.097742\u001b[0m\n",
      "\u001b[34m[10:33:49] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 26 extra nodes, 20 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[27]#011train-error:0.097707\u001b[0m\n",
      "\u001b[34m[10:33:49] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 22 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[28]#011train-error:0.097291\u001b[0m\n",
      "\u001b[34m[10:33:49] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 32 extra nodes, 4 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[29]#011train-error:0.097152\u001b[0m\n",
      "\u001b[34m[10:33:49] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 6 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[30]#011train-error:0.097256\u001b[0m\n",
      "\u001b[34m[10:33:49] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 26 extra nodes, 24 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[31]#011train-error:0.097083\u001b[0m\n",
      "\u001b[34m[10:33:49] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 16 extra nodes, 10 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[32]#011train-error:0.097083\u001b[0m\n",
      "\u001b[34m[10:33:49] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 16 extra nodes, 24 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[33]#011train-error:0.097083\u001b[0m\n",
      "\u001b[34m[10:33:49] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 8 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[34]#011train-error:0.097152\u001b[0m\n",
      "\u001b[34m[10:33:49] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 20 extra nodes, 28 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[35]#011train-error:0.097256\u001b[0m\n",
      "\u001b[34m[10:33:49] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 22 extra nodes, 22 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[36]#011train-error:0.097187\u001b[0m\n",
      "\u001b[34m[10:33:50] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 26 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[37]#011train-error:0.097118\u001b[0m\n",
      "\u001b[34m[10:33:50] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 20 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[38]#011train-error:0.097152\u001b[0m\n",
      "\u001b[34m[10:33:50] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 20 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[39]#011train-error:0.096736\u001b[0m\n",
      "\u001b[34m[10:33:50] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 4 extra nodes, 14 pruned nodes, max_depth=2\u001b[0m\n",
      "\u001b[34m[40]#011train-error:0.09691\u001b[0m\n",
      "\u001b[34m[10:33:50] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 14 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[41]#011train-error:0.096736\u001b[0m\n",
      "\u001b[34m[10:33:50] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 20 extra nodes, 16 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[42]#011train-error:0.096771\u001b[0m\n",
      "\u001b[34m[10:33:50] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 12 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[43]#011train-error:0.096806\u001b[0m\n",
      "\u001b[34m[10:33:50] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 16 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[44]#011train-error:0.096736\u001b[0m\n",
      "\u001b[34m[10:33:50] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 4 extra nodes, 14 pruned nodes, max_depth=2\u001b[0m\n",
      "\u001b[34m[45]#011train-error:0.096806\u001b[0m\n",
      "\u001b[34m[10:33:50] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 22 extra nodes, 24 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[46]#011train-error:0.096459\u001b[0m\n",
      "\u001b[34m[10:33:50] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 26 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[47]#011train-error:0.096424\u001b[0m\n",
      "\u001b[34m[10:33:50] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 12 extra nodes, 16 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[48]#011train-error:0.096528\u001b[0m\n",
      "\u001b[34m[10:33:50] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 20 extra nodes, 14 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[49]#011train-error:0.096563\u001b[0m\n",
      "\u001b[34m[10:33:50] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 20 extra nodes, 38 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[50]#011train-error:0.096597\u001b[0m\n",
      "\u001b[34m[10:33:50] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 14 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[51]#011train-error:0.096528\u001b[0m\n",
      "\u001b[34m[10:33:50] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 16 extra nodes, 30 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[52]#011train-error:0.096112\u001b[0m\n",
      "\u001b[34m[10:33:50] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 16 extra nodes, 14 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[53]#011train-error:0.096077\u001b[0m\n",
      "\u001b[34m[10:33:50] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 16 extra nodes, 16 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[54]#011train-error:0.09632\u001b[0m\n",
      "\u001b[34m[10:33:50] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 8 extra nodes, 16 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[34m[55]#011train-error:0.09632\u001b[0m\n",
      "\u001b[34m[10:33:50] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 12 extra nodes, 30 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[56]#011train-error:0.096147\u001b[0m\n",
      "\u001b[34m[10:33:50] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 16 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[57]#011train-error:0.09632\u001b[0m\n",
      "\u001b[34m[10:33:50] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 22 extra nodes, 24 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[58]#011train-error:0.096112\u001b[0m\n",
      "\u001b[34m[10:33:50] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 12 extra nodes, 34 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[59]#011train-error:0.096042\u001b[0m\n",
      "\u001b[34m[10:33:50] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 28 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[60]#011train-error:0.096008\u001b[0m\n",
      "\u001b[34m[10:33:50] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 26 extra nodes, 14 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[61]#011train-error:0.096042\u001b[0m\n",
      "\u001b[34m[10:33:50] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 20 extra nodes, 30 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[62]#011train-error:0.096077\u001b[0m\n",
      "\u001b[34m[10:33:50] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 6 extra nodes, 30 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[34m[63]#011train-error:0.096147\u001b[0m\n",
      "\u001b[34m[10:33:50] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 18 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[64]#011train-error:0.096216\u001b[0m\n",
      "\u001b[34m[10:33:50] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 20 extra nodes, 12 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[65]#011train-error:0.09632\u001b[0m\n",
      "\u001b[34m[10:33:50] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 10 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[66]#011train-error:0.096181\u001b[0m\n",
      "\u001b[34m[10:33:50] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 20 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[67]#011train-error:0.095904\u001b[0m\n",
      "\u001b[34m[10:33:51] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 16 extra nodes, 24 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[68]#011train-error:0.096008\u001b[0m\n",
      "\u001b[34m[10:33:51] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[69]#011train-error:0.096042\u001b[0m\n",
      "\u001b[34m[10:33:51] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 22 extra nodes, 12 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[70]#011train-error:0.096077\u001b[0m\n",
      "\u001b[34m[10:33:51] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 8 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[71]#011train-error:0.095938\u001b[0m\n",
      "\u001b[34m[10:33:51] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 30 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[72]#011train-error:0.095938\u001b[0m\n",
      "\u001b[34m[10:33:51] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 4 extra nodes, 28 pruned nodes, max_depth=2\u001b[0m\n",
      "\u001b[34m[73]#011train-error:0.096008\u001b[0m\n",
      "\u001b[34m[10:33:51] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 12 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[74]#011train-error:0.095869\u001b[0m\n",
      "\u001b[34m[10:33:51] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 34 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[75]#011train-error:0.095938\u001b[0m\n",
      "\u001b[34m[10:33:51] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 24 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[76]#011train-error:0.095904\u001b[0m\n",
      "\u001b[34m[10:33:51] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 12 extra nodes, 14 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[77]#011train-error:0.0958\u001b[0m\n",
      "\u001b[34m[10:33:51] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 6 extra nodes, 14 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[34m[78]#011train-error:0.09573\u001b[0m\n",
      "\u001b[34m[10:33:51] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 18 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[79]#011train-error:0.095765\u001b[0m\n",
      "\u001b[34m[10:33:51] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 12 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[80]#011train-error:0.095834\u001b[0m\n",
      "\u001b[34m[10:33:51] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 20 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[81]#011train-error:0.095592\u001b[0m\n",
      "\u001b[34m[10:33:51] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 22 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[82]#011train-error:0.095557\u001b[0m\n",
      "\u001b[34m[10:33:51] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 6 extra nodes, 26 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[34m[83]#011train-error:0.095557\u001b[0m\n",
      "\u001b[34m[10:33:51] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 32 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[84]#011train-error:0.095453\u001b[0m\n",
      "\u001b[34m[10:33:51] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 8 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[85]#011train-error:0.095453\u001b[0m\n",
      "\u001b[34m[10:33:51] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 24 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[86]#011train-error:0.095453\u001b[0m\n",
      "\u001b[34m[10:33:51] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 24 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[87]#011train-error:0.095453\u001b[0m\n",
      "\u001b[34m[10:33:51] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 20 extra nodes, 16 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[88]#011train-error:0.095349\u001b[0m\n",
      "\u001b[34m[10:33:51] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 4 extra nodes, 30 pruned nodes, max_depth=2\u001b[0m\n",
      "\u001b[34m[89]#011train-error:0.095037\u001b[0m\n",
      "\u001b[34m[10:33:51] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 14 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[90]#011train-error:0.095106\u001b[0m\n",
      "\u001b[34m[10:33:51] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 42 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[91]#011train-error:0.095037\u001b[0m\n",
      "\u001b[34m[10:33:51] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 30 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[92]#011train-error:0.095106\u001b[0m\n",
      "\u001b[34m[10:33:51] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 14 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[93]#011train-error:0.095314\u001b[0m\n",
      "\u001b[34m[10:33:51] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 30 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[94]#011train-error:0.095314\u001b[0m\n",
      "\u001b[34m[10:33:51] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 6 extra nodes, 24 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[34m[95]#011train-error:0.095314\u001b[0m\n",
      "\u001b[34m[10:33:52] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 12 extra nodes, 30 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[96]#011train-error:0.095279\u001b[0m\n",
      "\u001b[34m[10:33:52] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 12 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[97]#011train-error:0.094828\u001b[0m\n",
      "\u001b[34m[10:33:52] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 4 extra nodes, 22 pruned nodes, max_depth=2\u001b[0m\n",
      "\u001b[34m[98]#011train-error:0.094863\u001b[0m\n",
      "\u001b[34m[10:33:52] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 12 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[99]#011train-error:0.094759\u001b[0m\n",
      "\n",
      "2020-07-01 10:34:00 Uploading - Uploading generated training model\n",
      "2020-07-01 10:34:00 Completed - Training job completed\n",
      "Training seconds: 56\n",
      "Billable seconds: 56\n"
     ]
    }
   ],
   "source": [
    "# With the data loaded and the XGBoost estimator set up, \n",
    "# train the model using gradient optimization \n",
    "\n",
    "xgb.fit({'train': s3_input_train})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploy the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:sagemaker:Parameter image will be renamed to image_uri in SageMaker Python SDK v2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------!"
     ]
    }
   ],
   "source": [
    "xgb_predictor = xgb.deploy(initial_instance_count=1,\n",
    "                           instance_type='ml.m4.xlarge')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## predict whether customers in the test data enrolled for the bank product or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12357,)\n"
     ]
    }
   ],
   "source": [
    "test_data_array = test_data.drop(['y_no', 'y_yes'], axis=1).values #load the data into an array\n",
    "xgb_predictor.content_type = 'text/csv' # set the data type for an inference\n",
    "xgb_predictor.serializer = csv_serializer # set the serializer type\n",
    "predictions = xgb_predictor.predict(test_data_array).decode('utf-8') # predict!\n",
    "predictions_array = np.fromstring(predictions[1:], sep=',') # and turn the prediction into an array\n",
    "print(predictions_array.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Overall Classification Rate: 89.5%\n",
      "\n",
      "Predicted      No Purchase    Purchase\n",
      "Observed\n",
      "No Purchase    90% (10785)    35% (151)\n",
      "Purchase        10% (1143)     65% (278) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "cm = pd.crosstab(index=test_data['y_yes'], columns=np.round(predictions_array), rownames=['Observed'], colnames=['Predicted'])\n",
    "tn = cm.iloc[0,0]; fn = cm.iloc[1,0]; tp = cm.iloc[1,1]; fp = cm.iloc[0,1]; p = (tp+tn)/(tp+tn+fp+fn)*100\n",
    "print(\"\\n{0:<20}{1:<4.1f}%\\n\".format(\"Overall Classification Rate: \", p))\n",
    "print(\"{0:<15}{1:<15}{2:>8}\".format(\"Predicted\", \"No Purchase\", \"Purchase\"))\n",
    "print(\"Observed\")\n",
    "print(\"{0:<15}{1:<2.0f}% ({2:<}){3:>6.0f}% ({4:<})\".format(\"No Purchase\", \n",
    "        tn/(tn+fn)*100,tn, fp/(tp+fp)*100, fp))\n",
    "print(\"{0:<16}{1:<1.0f}% ({2:<}){3:>7.0f}% ({4:<}) \\n\".format(\"Purchase\", \n",
    "        fn/(tn+fn)*100,fn, tp/(tp+fp)*100, tp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'ResponseMetadata': {'RequestId': 'E38F526EA9F1E76E',\n",
       "   'HostId': '/apeQC7odug04b0Kl7k9js+RWdiIUl3ENlIXbaFh26gNxI3V5Ho/uwT1/Ya6/cgXLfR2orJUago=',\n",
       "   'HTTPStatusCode': 200,\n",
       "   'HTTPHeaders': {'x-amz-id-2': '/apeQC7odug04b0Kl7k9js+RWdiIUl3ENlIXbaFh26gNxI3V5Ho/uwT1/Ya6/cgXLfR2orJUago=',\n",
       "    'x-amz-request-id': 'E38F526EA9F1E76E',\n",
       "    'date': 'Wed, 01 Jul 2020 11:00:41 GMT',\n",
       "    'connection': 'close',\n",
       "    'content-type': 'application/xml',\n",
       "    'transfer-encoding': 'chunked',\n",
       "    'server': 'AmazonS3'},\n",
       "   'RetryAttempts': 0},\n",
       "  'Deleted': [{'Key': 'tko-ts-workshop-new-features/output/deepar-stores-sales-demo-2020-01-13-16-51-42-459/output/model.tar.gz'},\n",
       "   {'Key': 'tko-ts-workshop-new-features/data/train/train_new_features.json'},\n",
       "   {'Key': 'sagemaker/DEMO-xgboost-dm/output/xgboost-2020-07-01-10-30-10-450/output/model.tar.gz'},\n",
       "   {'Key': 'tko-ts-workshop/output/deepar-stores-sales-demo-2020-01-13-16-28-03-375/output/model.tar.gz'},\n",
       "   {'Key': 'tko-ts-workshop/data/train/train.json'},\n",
       "   {'Key': 'sagemaker/DEMO-xgboost-dm/predit_enroll_certificate_deposit/train/train.csv'},\n",
       "   {'Key': 'sagemaker/DEMO-xgboost-dm/train/train.csv'},\n",
       "   {'Key': 'tko-ts-workshop/output/deepar-stores-sales-demo-2020-01-13-16-12-08-678/output/model.tar.gz'},\n",
       "   {'Key': 'tko-ts-workshop-new-features/data/test/test_new_features.json'},\n",
       "   {'Key': 'tko-ts-workshop/data/test/test.json'}]}]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sagemaker.Session().delete_endpoint(xgb_predictor.endpoint)\n",
    "bucket_to_delete = boto3.resource('s3').Bucket(bucket_name)\n",
    "bucket_to_delete.objects.all().delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
