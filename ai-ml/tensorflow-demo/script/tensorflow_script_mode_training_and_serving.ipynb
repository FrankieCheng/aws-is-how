{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow script mode training and serving\n",
    "\n",
    "Script mode is a training script format for TensorFlow that lets you execute any TensorFlow training script in SageMaker with minimal modification. The [SageMaker Python SDK](https://github.com/aws/sagemaker-python-sdk) handles transferring your script to a SageMaker training instance. On the training instance, SageMaker's native TensorFlow support sets up training-related environment variables and executes your training script. In this tutorial, we use the SageMaker Python SDK to launch a training job and deploy the trained model.\n",
    "\n",
    "Script mode supports training with a Python script, a Python module, or a shell script. In this example, we use a Python script to train a classification model on the [MNIST dataset](http://yann.lecun.com/exdb/mnist/). In this example, we will show how easily you can train a SageMaker using TensorFlow 1.x and TensorFlow 2.0 scripts with SageMaker Python SDK. In addition, this notebook demonstrates how to perform real time inference with the [SageMaker TensorFlow Serving container](https://github.com/aws/sagemaker-tensorflow-serving-container). The TensorFlow Serving container is the default inference method for script mode. For full documentation on the TensorFlow Serving container, please visit [here](https://github.com/aws/sagemaker-python-sdk/blob/master/src/sagemaker/tensorflow/deploying_tensorflow_serving.rst).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up the environment\n",
    "\n",
    "Let's start by setting up the environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "\n",
    "role = get_execution_role()\n",
    "region = sagemaker_session.boto_session.region_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conda 4.8.4\n",
      "2.19.0\n"
     ]
    }
   ],
   "source": [
    "!conda --version\n",
    "\n",
    "print(sagemaker.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Data\n",
    "\n",
    "The MNIST dataset has been loaded to the public S3 buckets ``sagemaker-sample-data-<REGION>`` under the prefix ``tensorflow/mnist``. There are four ``.npy`` file under this prefix:\n",
    "* ``train_data.npy``\n",
    "* ``eval_data.npy``\n",
    "* ``train_labels.npy``\n",
    "* ``eval_labels.npy``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_uri = 's3://sagemaker-sample-data-{}/tensorflow/mnist'.format(region)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construct a script for distributed training\n",
    "\n",
    "This tutorial's training script was adapted from TensorFlow's official [CNN MNIST example](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/tutorials/layers/cnn_mnist.py). We have modified it to handle the ``model_dir`` parameter passed in by SageMaker. This is an S3 path which can be used for data sharing during distributed training and checkpointing and/or model persistence. We have also added an argument-parsing function to handle processing training-related variables.\n",
    "\n",
    "At the end of the training job we have added a step to export the trained model to the path stored in the environment variable ``SM_MODEL_DIR``, which always points to ``/opt/ml/model``. This is critical because SageMaker uploads all the model artifacts in this folder to S3 at end of training.\n",
    "\n",
    "Here is the entire script:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[37m# Copyright 2018-2019 Amazon.com, Inc. or its affiliates. All Rights Reserved.\u001b[39;49;00m\n",
      "\u001b[37m#\u001b[39;49;00m\n",
      "\u001b[37m# Licensed under the Apache License, Version 2.0 (the \"License\"). You\u001b[39;49;00m\n",
      "\u001b[37m# may not use this file except in compliance with the License. A copy of\u001b[39;49;00m\n",
      "\u001b[37m# the License is located at\u001b[39;49;00m\n",
      "\u001b[37m#\u001b[39;49;00m\n",
      "\u001b[37m#     http://aws.amazon.com/apache2.0/\u001b[39;49;00m\n",
      "\u001b[37m#\u001b[39;49;00m\n",
      "\u001b[37m# or in the \"license\" file accompanying this file. This file is\u001b[39;49;00m\n",
      "\u001b[37m# distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\u001b[39;49;00m\n",
      "\u001b[37m# ANY KIND, either express or implied. See the License for the specific\u001b[39;49;00m\n",
      "\u001b[37m# language governing permissions and limitations under the License.\u001b[39;49;00m\n",
      "\u001b[33m\"\"\"Convolutional Neural Network Estimator for MNIST, built with tf.layers.\"\"\"\u001b[39;49;00m\n",
      "\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36m__future__\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m absolute_import\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36m__future__\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m division\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36m__future__\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m print_function\n",
      "\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mnumpy\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mnp\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtensorflow\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mtf\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mos\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mjson\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36margparse\u001b[39;49;00m\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mtensorflow\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mpython\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mplatform\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m tf_logging\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mlogging\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36m_logging\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36msys\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36m_sys\u001b[39;49;00m\n",
      "\n",
      "\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mcnn_model_fn\u001b[39;49;00m(features, labels, mode):\n",
      "    \u001b[33m\"\"\"Model function for CNN.\"\"\"\u001b[39;49;00m\n",
      "    \u001b[37m# Input Layer\u001b[39;49;00m\n",
      "    \u001b[37m# Reshape X to 4-D tensor: [batch_size, width, height, channels]\u001b[39;49;00m\n",
      "    \u001b[37m# MNIST images are 28x28 pixels, and have one color channel\u001b[39;49;00m\n",
      "    input_layer = tf.reshape(features[\u001b[33m\"\u001b[39;49;00m\u001b[33mx\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m], [-\u001b[34m1\u001b[39;49;00m, \u001b[34m28\u001b[39;49;00m, \u001b[34m28\u001b[39;49;00m, \u001b[34m1\u001b[39;49;00m])\n",
      "\n",
      "    \u001b[37m# Convolutional Layer #1\u001b[39;49;00m\n",
      "    \u001b[37m# Computes 32 features using a 5x5 filter with ReLU activation.\u001b[39;49;00m\n",
      "    \u001b[37m# Padding is added to preserve width and height.\u001b[39;49;00m\n",
      "    \u001b[37m# Input Tensor Shape: [batch_size, 28, 28, 1]\u001b[39;49;00m\n",
      "    \u001b[37m# Output Tensor Shape: [batch_size, 28, 28, 32]\u001b[39;49;00m\n",
      "    conv1 = tf.layers.conv2d(\n",
      "        inputs=input_layer,\n",
      "        filters=\u001b[34m32\u001b[39;49;00m,\n",
      "        kernel_size=[\u001b[34m5\u001b[39;49;00m, \u001b[34m5\u001b[39;49;00m],\n",
      "        padding=\u001b[33m\"\u001b[39;49;00m\u001b[33msame\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\n",
      "        activation=tf.nn.relu)\n",
      "\n",
      "    \u001b[37m# Pooling Layer #1\u001b[39;49;00m\n",
      "    \u001b[37m# First max pooling layer with a 2x2 filter and stride of 2\u001b[39;49;00m\n",
      "    \u001b[37m# Input Tensor Shape: [batch_size, 28, 28, 32]\u001b[39;49;00m\n",
      "    \u001b[37m# Output Tensor Shape: [batch_size, 14, 14, 32]\u001b[39;49;00m\n",
      "    pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[\u001b[34m2\u001b[39;49;00m, \u001b[34m2\u001b[39;49;00m], strides=\u001b[34m2\u001b[39;49;00m)\n",
      "\n",
      "    \u001b[37m# Convolutional Layer #2\u001b[39;49;00m\n",
      "    \u001b[37m# Computes 64 features using a 5x5 filter.\u001b[39;49;00m\n",
      "    \u001b[37m# Padding is added to preserve width and height.\u001b[39;49;00m\n",
      "    \u001b[37m# Input Tensor Shape: [batch_size, 14, 14, 32]\u001b[39;49;00m\n",
      "    \u001b[37m# Output Tensor Shape: [batch_size, 14, 14, 64]\u001b[39;49;00m\n",
      "    conv2 = tf.layers.conv2d(\n",
      "        inputs=pool1,\n",
      "        filters=\u001b[34m64\u001b[39;49;00m,\n",
      "        kernel_size=[\u001b[34m5\u001b[39;49;00m, \u001b[34m5\u001b[39;49;00m],\n",
      "        padding=\u001b[33m\"\u001b[39;49;00m\u001b[33msame\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\n",
      "        activation=tf.nn.relu)\n",
      "\n",
      "    \u001b[37m# Pooling Layer #2\u001b[39;49;00m\n",
      "    \u001b[37m# Second max pooling layer with a 2x2 filter and stride of 2\u001b[39;49;00m\n",
      "    \u001b[37m# Input Tensor Shape: [batch_size, 14, 14, 64]\u001b[39;49;00m\n",
      "    \u001b[37m# Output Tensor Shape: [batch_size, 7, 7, 64]\u001b[39;49;00m\n",
      "    pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[\u001b[34m2\u001b[39;49;00m, \u001b[34m2\u001b[39;49;00m], strides=\u001b[34m2\u001b[39;49;00m)\n",
      "\n",
      "    \u001b[37m# Flatten tensor into a batch of vectors\u001b[39;49;00m\n",
      "    \u001b[37m# Input Tensor Shape: [batch_size, 7, 7, 64]\u001b[39;49;00m\n",
      "    \u001b[37m# Output Tensor Shape: [batch_size, 7 * 7 * 64]\u001b[39;49;00m\n",
      "    pool2_flat = tf.reshape(pool2, [-\u001b[34m1\u001b[39;49;00m, \u001b[34m7\u001b[39;49;00m * \u001b[34m7\u001b[39;49;00m * \u001b[34m64\u001b[39;49;00m])\n",
      "\n",
      "    \u001b[37m# Dense Layer\u001b[39;49;00m\n",
      "    \u001b[37m# Densely connected layer with 1024 neurons\u001b[39;49;00m\n",
      "    \u001b[37m# Input Tensor Shape: [batch_size, 7 * 7 * 64]\u001b[39;49;00m\n",
      "    \u001b[37m# Output Tensor Shape: [batch_size, 1024]\u001b[39;49;00m\n",
      "    dense = tf.layers.dense(inputs=pool2_flat, units=\u001b[34m1024\u001b[39;49;00m, activation=tf.nn.relu)\n",
      "\n",
      "    \u001b[37m# Add dropout operation; 0.6 probability that element will be kept\u001b[39;49;00m\n",
      "    dropout = tf.layers.dropout(\n",
      "        inputs=dense, rate=\u001b[34m0.4\u001b[39;49;00m, training=mode == tf.estimator.ModeKeys.TRAIN)\n",
      "\n",
      "    \u001b[37m# Logits layer\u001b[39;49;00m\n",
      "    \u001b[37m# Input Tensor Shape: [batch_size, 1024]\u001b[39;49;00m\n",
      "    \u001b[37m# Output Tensor Shape: [batch_size, 10]\u001b[39;49;00m\n",
      "    logits = tf.layers.dense(inputs=dropout, units=\u001b[34m10\u001b[39;49;00m)\n",
      "\n",
      "    predictions = {\n",
      "        \u001b[37m# Generate predictions (for PREDICT and EVAL mode)\u001b[39;49;00m\n",
      "        \u001b[33m\"\u001b[39;49;00m\u001b[33mclasses\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: tf.argmax(\u001b[36minput\u001b[39;49;00m=logits, axis=\u001b[34m1\u001b[39;49;00m),\n",
      "        \u001b[37m# Add `softmax_tensor` to the graph. It is used for PREDICT and by the\u001b[39;49;00m\n",
      "        \u001b[37m# `logging_hook`.\u001b[39;49;00m\n",
      "        \u001b[33m\"\u001b[39;49;00m\u001b[33mprobabilities\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: tf.nn.softmax(logits, name=\u001b[33m\"\u001b[39;49;00m\u001b[33msoftmax_tensor\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "    }\n",
      "    \u001b[34mif\u001b[39;49;00m mode == tf.estimator.ModeKeys.PREDICT:\n",
      "      \u001b[34mreturn\u001b[39;49;00m tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\n",
      "\n",
      "    \u001b[37m# Calculate Loss (for both TRAIN and EVAL modes)\u001b[39;49;00m\n",
      "    loss = tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits)\n",
      "\n",
      "    \u001b[37m# Configure the Training Op (for TRAIN mode)\u001b[39;49;00m\n",
      "    \u001b[34mif\u001b[39;49;00m mode == tf.estimator.ModeKeys.TRAIN:\n",
      "      optimizer = tf.train.GradientDescentOptimizer(learning_rate=\u001b[34m0.001\u001b[39;49;00m)\n",
      "      train_op = optimizer.minimize(\n",
      "          loss=loss,\n",
      "          global_step=tf.train.get_global_step())\n",
      "      \u001b[34mreturn\u001b[39;49;00m tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)\n",
      "\n",
      "    \u001b[37m# Add evaluation metrics (for EVAL mode)\u001b[39;49;00m\n",
      "    eval_metric_ops = {\n",
      "        \u001b[33m\"\u001b[39;49;00m\u001b[33maccuracy\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: tf.metrics.accuracy(\n",
      "            labels=labels, predictions=predictions[\u001b[33m\"\u001b[39;49;00m\u001b[33mclasses\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])}\n",
      "    \u001b[34mreturn\u001b[39;49;00m tf.estimator.EstimatorSpec(\n",
      "        mode=mode, loss=loss, eval_metric_ops=eval_metric_ops)\n",
      "\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32m_load_training_data\u001b[39;49;00m(base_dir):\n",
      "    x_train = np.load(os.path.join(base_dir, \u001b[33m'\u001b[39;49;00m\u001b[33mtrain_data.npy\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m))\n",
      "    y_train = np.load(os.path.join(base_dir, \u001b[33m'\u001b[39;49;00m\u001b[33mtrain_labels.npy\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m))\n",
      "    \u001b[34mreturn\u001b[39;49;00m x_train, y_train\n",
      "\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32m_load_testing_data\u001b[39;49;00m(base_dir):\n",
      "    x_test = np.load(os.path.join(base_dir, \u001b[33m'\u001b[39;49;00m\u001b[33meval_data.npy\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m))\n",
      "    y_test = np.load(os.path.join(base_dir, \u001b[33m'\u001b[39;49;00m\u001b[33meval_labels.npy\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m))\n",
      "    \u001b[34mreturn\u001b[39;49;00m x_test, y_test\n",
      "\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32m_parse_args\u001b[39;49;00m():\n",
      "\n",
      "    parser = argparse.ArgumentParser()\n",
      "\n",
      "    \u001b[37m# Data, model, and output directories\u001b[39;49;00m\n",
      "    \u001b[37m# model_dir is always passed in from SageMaker. By default this is a S3 path under the default bucket.\u001b[39;49;00m\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--model_dir\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m)\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--sm-model-dir\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=os.environ.get(\u001b[33m'\u001b[39;49;00m\u001b[33mSM_MODEL_DIR\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m))\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--train\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=os.environ.get(\u001b[33m'\u001b[39;49;00m\u001b[33mSM_CHANNEL_TRAINING\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m))\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--hosts\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mlist\u001b[39;49;00m, default=json.loads(os.environ.get(\u001b[33m'\u001b[39;49;00m\u001b[33mSM_HOSTS\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)))\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--current-host\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=os.environ.get(\u001b[33m'\u001b[39;49;00m\u001b[33mSM_CURRENT_HOST\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m))\n",
      "\n",
      "    \u001b[34mreturn\u001b[39;49;00m parser.parse_known_args()\n",
      "\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mserving_input_fn\u001b[39;49;00m():\n",
      "    inputs = {\u001b[33m'\u001b[39;49;00m\u001b[33mx\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: tf.placeholder(tf.float32, [\u001b[34mNone\u001b[39;49;00m, \u001b[34m784\u001b[39;49;00m])}\n",
      "    \u001b[34mreturn\u001b[39;49;00m tf.estimator.export.ServingInputReceiver(inputs, inputs)\n",
      "\n",
      "\u001b[34mif\u001b[39;49;00m \u001b[31m__name__\u001b[39;49;00m == \u001b[33m\"\u001b[39;49;00m\u001b[33m__main__\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\n",
      "    args, unknown = _parse_args()\n",
      "\n",
      "    train_data, train_labels = _load_training_data(args.train)\n",
      "    eval_data, eval_labels = _load_testing_data(args.train)\n",
      "\n",
      "    \u001b[37m# Create the Estimator\u001b[39;49;00m\n",
      "    mnist_classifier = tf.estimator.Estimator(\n",
      "        model_fn=cnn_model_fn, model_dir=args.model_dir)\n",
      "\n",
      "    \u001b[37m# Set up logging for predictions\u001b[39;49;00m\n",
      "    \u001b[37m# Log the values in the \"Softmax\" tensor with label \"probabilities\"\u001b[39;49;00m\n",
      "    tensors_to_log = {\u001b[33m\"\u001b[39;49;00m\u001b[33mprobabilities\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: \u001b[33m\"\u001b[39;49;00m\u001b[33msoftmax_tensor\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m}\n",
      "    logging_hook = tf.train.LoggingTensorHook(\n",
      "        tensors=tensors_to_log, every_n_iter=\u001b[34m50\u001b[39;49;00m)\n",
      "\n",
      "    \u001b[37m# Train the model\u001b[39;49;00m\n",
      "    train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
      "        x={\u001b[33m\"\u001b[39;49;00m\u001b[33mx\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: train_data},\n",
      "        y=train_labels,\n",
      "        batch_size=\u001b[34m100\u001b[39;49;00m,\n",
      "        num_epochs=\u001b[34mNone\u001b[39;49;00m,\n",
      "        shuffle=\u001b[34mTrue\u001b[39;49;00m)\n",
      "\n",
      "    \u001b[37m# Evaluate the model and print results\u001b[39;49;00m\n",
      "    eval_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
      "        x={\u001b[33m\"\u001b[39;49;00m\u001b[33mx\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: eval_data},\n",
      "        y=eval_labels,\n",
      "        num_epochs=\u001b[34m1\u001b[39;49;00m,\n",
      "        shuffle=\u001b[34mFalse\u001b[39;49;00m)\n",
      "\n",
      "    train_spec = tf.estimator.TrainSpec(train_input_fn, max_steps=\u001b[34m20000\u001b[39;49;00m)\n",
      "    eval_spec = tf.estimator.EvalSpec(eval_input_fn)\n",
      "    tf.estimator.train_and_evaluate(mnist_classifier, train_spec, eval_spec)\n",
      "\n",
      "    \u001b[34mif\u001b[39;49;00m args.current_host == args.hosts[\u001b[34m0\u001b[39;49;00m]:\n",
      "        mnist_classifier.export_savedmodel(args.sm_model_dir, serving_input_fn)\n",
      "\u001b[37m# Copyright 2019 Amazon.com, Inc. or its affiliates. All Rights Reserved.\u001b[39;49;00m\n",
      "\u001b[37m#\u001b[39;49;00m\n",
      "\u001b[37m# Licensed under the Apache License, Version 2.0 (the \"License\"). You\u001b[39;49;00m\n",
      "\u001b[37m# may not use this file except in compliance with the License. A copy of\u001b[39;49;00m\n",
      "\u001b[37m# the License is located at\u001b[39;49;00m\n",
      "\u001b[37m#\u001b[39;49;00m\n",
      "\u001b[37m#     http://aws.amazon.com/apache2.0/\u001b[39;49;00m\n",
      "\u001b[37m#\u001b[39;49;00m\n",
      "\u001b[37m# or in the \"license\" file accompanying this file. This file is\u001b[39;49;00m\n",
      "\u001b[37m# distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\u001b[39;49;00m\n",
      "\u001b[37m# ANY KIND, either express or implied. See the License for the specific\u001b[39;49;00m\n",
      "\u001b[37m# language governing permissions and limitations under the License.import tensorflow as tf\u001b[39;49;00m\n",
      "\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtensorflow\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mtf\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36margparse\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mos\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mnumpy\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mnp\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mjson\u001b[39;49;00m\n",
      "\n",
      "\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mmodel\u001b[39;49;00m(x_train, y_train, x_test, y_test):\n",
      "    \u001b[33m\"\"\"Generate a simple model\"\"\"\u001b[39;49;00m\n",
      "    model = tf.keras.models.Sequential([\n",
      "        tf.keras.layers.Flatten(),\n",
      "        tf.keras.layers.Dense(\u001b[34m1024\u001b[39;49;00m, activation=tf.nn.relu),\n",
      "        tf.keras.layers.Dropout(\u001b[34m0.4\u001b[39;49;00m),\n",
      "        tf.keras.layers.Dense(\u001b[34m10\u001b[39;49;00m, activation=tf.nn.softmax)\n",
      "    ])\n",
      "\n",
      "    model.compile(optimizer=\u001b[33m'\u001b[39;49;00m\u001b[33madam\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\n",
      "                  loss=\u001b[33m'\u001b[39;49;00m\u001b[33msparse_categorical_crossentropy\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\n",
      "                  metrics=[\u001b[33m'\u001b[39;49;00m\u001b[33maccuracy\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m])\n",
      "    model.fit(x_train, y_train)\n",
      "    model.evaluate(x_test, y_test)\n",
      "\n",
      "    \u001b[34mreturn\u001b[39;49;00m model\n",
      "\n",
      "\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32m_load_training_data\u001b[39;49;00m(base_dir):\n",
      "    \u001b[33m\"\"\"Load MNIST training data\"\"\"\u001b[39;49;00m\n",
      "    x_train = np.load(os.path.join(base_dir, \u001b[33m'\u001b[39;49;00m\u001b[33mtrain_data.npy\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m))\n",
      "    y_train = np.load(os.path.join(base_dir, \u001b[33m'\u001b[39;49;00m\u001b[33mtrain_labels.npy\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m))\n",
      "    \u001b[34mreturn\u001b[39;49;00m x_train, y_train\n",
      "\n",
      "\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32m_load_testing_data\u001b[39;49;00m(base_dir):\n",
      "    \u001b[33m\"\"\"Load MNIST testing data\"\"\"\u001b[39;49;00m\n",
      "    x_test = np.load(os.path.join(base_dir, \u001b[33m'\u001b[39;49;00m\u001b[33meval_data.npy\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m))\n",
      "    y_test = np.load(os.path.join(base_dir, \u001b[33m'\u001b[39;49;00m\u001b[33meval_labels.npy\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m))\n",
      "    \u001b[34mreturn\u001b[39;49;00m x_test, y_test\n",
      "\n",
      "\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32m_parse_args\u001b[39;49;00m():\n",
      "    parser = argparse.ArgumentParser()\n",
      "\n",
      "    \u001b[37m# Data, model, and output directories\u001b[39;49;00m\n",
      "    \u001b[37m# model_dir is always passed in from SageMaker. By default this is a S3 path under the default bucket.\u001b[39;49;00m\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--model_dir\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m)\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--sm-model-dir\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=os.environ.get(\u001b[33m'\u001b[39;49;00m\u001b[33mSM_MODEL_DIR\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m))\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--train\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=os.environ.get(\u001b[33m'\u001b[39;49;00m\u001b[33mSM_CHANNEL_TRAINING\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m))\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--hosts\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mlist\u001b[39;49;00m, default=json.loads(os.environ.get(\u001b[33m'\u001b[39;49;00m\u001b[33mSM_HOSTS\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)))\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--current-host\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=os.environ.get(\u001b[33m'\u001b[39;49;00m\u001b[33mSM_CURRENT_HOST\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m))\n",
      "\n",
      "    \u001b[34mreturn\u001b[39;49;00m parser.parse_known_args()\n",
      "\n",
      "\n",
      "\u001b[34mif\u001b[39;49;00m \u001b[31m__name__\u001b[39;49;00m == \u001b[33m\"\u001b[39;49;00m\u001b[33m__main__\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\n",
      "    args, unknown = _parse_args()\n",
      "\n",
      "    train_data, train_labels = _load_training_data(args.train)\n",
      "    eval_data, eval_labels = _load_testing_data(args.train)\n",
      "\n",
      "    mnist_classifier = model(train_data, train_labels, eval_data, eval_labels)\n",
      "\n",
      "    \u001b[34mif\u001b[39;49;00m args.current_host == args.hosts[\u001b[34m0\u001b[39;49;00m]:\n",
      "        \u001b[37m# save model to an S3 directory with version number '00000001'\u001b[39;49;00m\n",
      "        mnist_classifier.save(os.path.join(args.sm_model_dir, \u001b[33m'\u001b[39;49;00m\u001b[33m000000001\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m), \u001b[33m'\u001b[39;49;00m\u001b[33mmy_model.h5\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\n"
     ]
    }
   ],
   "source": [
    "!pygmentize 'mnist.py'\n",
    "\n",
    "# TensorFlow 2.1+ script\n",
    "!pygmentize 'mnist-2.py'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a training job using the `TensorFlow` estimator\n",
    "\n",
    "The `sagemaker.tensorflow.TensorFlow` estimator handles locating the script mode container, uploading your script to a S3 location and creating a SageMaker training job. Let's call out a couple important parameters here:\n",
    "\n",
    "* `py_version` is set to `'py3'` to indicate that we are using script mode since legacy mode supports only Python 2. Though Python 2 will be deprecated soon, you can use script mode with Python 2 by setting `py_version` to `'py2'` and `script_mode` to `True`.\n",
    "\n",
    "* `distributions` is used to configure the distributed training setup. It's required only if you are doing distributed training either across a cluster of instances or across multiple GPUs. Here we are using parameter servers as the distributed training schema. SageMaker training jobs run on homogeneous clusters. To make parameter server more performant in the SageMaker setup, we run a parameter server on every instance in the cluster, so there is no need to specify the number of parameter servers to launch. Script mode also supports distributed training with [Horovod](https://github.com/horovod/horovod). You can find the full documentation on how to configure `distributions` [here](https://github.com/aws/sagemaker-python-sdk/tree/master/src/sagemaker/tensorflow#distributed-training). \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.tensorflow import TensorFlow\n",
    "\n",
    "\n",
    "mnist_estimator = TensorFlow(entry_point='mnist.py',\n",
    "                             role=role,\n",
    "                             instance_count=2,\n",
    "                             instance_type='ml.p3.2xlarge',\n",
    "                             framework_version='1.15.2',\n",
    "                             py_version='py3',\n",
    "                             distribution={'parameter_server': {'enabled': True}},\n",
    "                             disable_profiler=True\n",
    "                            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also initiate an estimator to train with TensorFlow 2.3.0 script. The only things that you will need to change are the script name and ``framewotk_version``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_estimator2 = TensorFlow(entry_point='mnist-2.py',\n",
    "                             role=role,\n",
    "                             instance_count=2,\n",
    "                             instance_type='ml.p3.2xlarge',\n",
    "                             framework_version='2.3.0',\n",
    "                             py_version='py36',\n",
    "                             distribution={'parameter_server': {'enabled': True}},\n",
    "                             disable_profiler=True\n",
    "                             )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calling ``fit``\n",
    "\n",
    "To start a training job, we call `estimator.fit(training_data_uri)`.\n",
    "\n",
    "An S3 location is used here as the input. `fit` creates a default channel named `'training'`, which points to this S3 location. In the training script we can then access the training data from the location stored in `SM_CHANNEL_TRAINING`. `fit` accepts a couple other types of input as well. See the API doc [here](https://sagemaker.readthedocs.io/en/stable/estimators.html#sagemaker.estimator.EstimatorBase.fit) for details.\n",
    "\n",
    "When training starts, the TensorFlow container executes mnist.py, passing `hyperparameters` and `model_dir` from the estimator as script arguments. Because we didn't define either in this example, no hyperparameters are passed, and `model_dir` defaults to `s3://<DEFAULT_BUCKET>/<TRAINING_JOB_NAME>`, so the script execution is as follows:\n",
    "```bash\n",
    "python mnist.py --model_dir s3://<DEFAULT_BUCKET>/<TRAINING_JOB_NAME>\n",
    "```\n",
    "When training is complete, the training job will upload the saved model for TensorFlow serving."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-12-30 08:41:56 Starting - Starting the training job...\n",
      "2020-12-30 08:42:01 Starting - Launching requested ML instances......\n",
      "2020-12-30 08:43:11 Starting - Preparing the instances for training............\n",
      "2020-12-30 08:45:01 Downloading - Downloading input data...\n",
      "2020-12-30 08:45:34 Training - Downloading the training image.\u001b[35mWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/__init__.py:1473: The name tf.estimator.inputs is deprecated. Please use tf.compat.v1.estimator.inputs instead.\n",
      "\u001b[0m\n",
      "\u001b[35m2020-12-30 08:46:00,880 sagemaker-containers INFO     Imported framework sagemaker_tensorflow_container.training\u001b[0m\n",
      "\u001b[35m2020-12-30 08:46:01,157 sagemaker_tensorflow_container.training INFO     Running distributed training job with parameter servers\u001b[0m\n",
      "\u001b[35m2020-12-30 08:46:01,158 sagemaker_tensorflow_container.training INFO     Launching parameter server process\u001b[0m\n",
      "\u001b[35m2020-12-30 08:46:01,158 sagemaker_tensorflow_container.training INFO     Running distributed training job with parameter servers\u001b[0m\n",
      "\u001b[35mWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/sagemaker_tensorflow_container/training.py:99: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\u001b[0m\n",
      "\u001b[35m2020-12-30 08:46:01,158 tensorflow   WARNING  From /usr/local/lib/python3.6/dist-packages/sagemaker_tensorflow_container/training.py:99: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\u001b[0m\n",
      "\u001b[35mWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/sagemaker_tensorflow_container/training.py:101: The name tf.train.Server is deprecated. Please use tf.distribute.Server instead.\n",
      "\u001b[0m\n",
      "\u001b[35m2020-12-30 08:46:01,158 tensorflow   WARNING  From /usr/local/lib/python3.6/dist-packages/sagemaker_tensorflow_container/training.py:101: The name tf.train.Server is deprecated. Please use tf.distribute.Server instead.\n",
      "\u001b[0m\n",
      "\u001b[35m2020-12-30 08:46:02,145 sagemaker_tensorflow_container.training INFO     Launching worker process\u001b[0m\n",
      "\u001b[35m2020-12-30 08:46:02,356 sagemaker-containers INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[35mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[35m{\n",
      "    \"additional_framework_parameters\": {\n",
      "        \"sagemaker_parameter_server_enabled\": true\n",
      "    },\n",
      "    \"channel_input_dirs\": {\n",
      "        \"training\": \"/opt/ml/input/data/training\"\n",
      "    },\n",
      "    \"current_host\": \"algo-2\",\n",
      "    \"framework_module\": \"sagemaker_tensorflow_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\",\n",
      "        \"algo-2\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"model_dir\": \"s3://sagemaker-cn-north-1-876820548815/tensorflow-training-2020-12-30-08-41-55-827/model\"\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"training\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": false,\n",
      "    \"job_name\": \"tensorflow-training-2020-12-30-08-41-55-827\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-cn-north-1-876820548815/tensorflow-training-2020-12-30-08-41-55-827/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"mnist\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 8,\n",
      "    \"num_gpus\": 1,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-2\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\",\n",
      "            \"algo-2\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"mnist.py\"\u001b[0m\n",
      "\u001b[35m}\n",
      "\u001b[0m\n",
      "\u001b[35mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[35mSM_HOSTS=[\"algo-1\",\"algo-2\"]\u001b[0m\n",
      "\u001b[35mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[35mSM_HPS={\"model_dir\":\"s3://sagemaker-cn-north-1-876820548815/tensorflow-training-2020-12-30-08-41-55-827/model\"}\u001b[0m\n",
      "\u001b[35mSM_USER_ENTRY_POINT=mnist.py\u001b[0m\n",
      "\u001b[35mSM_FRAMEWORK_PARAMS={\"sagemaker_parameter_server_enabled\":true}\u001b[0m\n",
      "\u001b[35mSM_RESOURCE_CONFIG={\"current_host\":\"algo-2\",\"hosts\":[\"algo-1\",\"algo-2\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[35mSM_INPUT_DATA_CONFIG={\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[35mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[35mSM_CHANNELS=[\"training\"]\u001b[0m\n",
      "\u001b[35mSM_CURRENT_HOST=algo-2\u001b[0m\n",
      "\u001b[35mSM_MODULE_NAME=mnist\u001b[0m\n",
      "\u001b[35mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[35mSM_FRAMEWORK_MODULE=sagemaker_tensorflow_container.training:main\u001b[0m\n",
      "\u001b[35mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[35mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[35mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[35mSM_NUM_CPUS=8\u001b[0m\n",
      "\u001b[35mSM_NUM_GPUS=1\u001b[0m\n",
      "\u001b[35mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[35mSM_MODULE_DIR=s3://sagemaker-cn-north-1-876820548815/tensorflow-training-2020-12-30-08-41-55-827/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[35mSM_TRAINING_ENV={\"additional_framework_parameters\":{\"sagemaker_parameter_server_enabled\":true},\"channel_input_dirs\":{\"training\":\"/opt/ml/input/data/training\"},\"current_host\":\"algo-2\",\"framework_module\":\"sagemaker_tensorflow_container.training:main\",\"hosts\":[\"algo-1\",\"algo-2\"],\"hyperparameters\":{\"model_dir\":\"s3://sagemaker-cn-north-1-876820548815/tensorflow-training-2020-12-30-08-41-55-827/model\"},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":false,\"job_name\":\"tensorflow-training-2020-12-30-08-41-55-827\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-cn-north-1-876820548815/tensorflow-training-2020-12-30-08-41-55-827/source/sourcedir.tar.gz\",\"module_name\":\"mnist\",\"network_interface_name\":\"eth0\",\"num_cpus\":8,\"num_gpus\":1,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-2\",\"hosts\":[\"algo-1\",\"algo-2\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"mnist.py\"}\u001b[0m\n",
      "\u001b[35mSM_USER_ARGS=[\"--model_dir\",\"s3://sagemaker-cn-north-1-876820548815/tensorflow-training-2020-12-30-08-41-55-827/model\"]\u001b[0m\n",
      "\u001b[35mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[35mSM_CHANNEL_TRAINING=/opt/ml/input/data/training\u001b[0m\n",
      "\u001b[35mSM_HP_MODEL_DIR=s3://sagemaker-cn-north-1-876820548815/tensorflow-training-2020-12-30-08-41-55-827/model\u001b[0m\n",
      "\u001b[35mTF_CONFIG={\"cluster\": {\"master\": [\"algo-1:2222\"], \"ps\": [\"algo-1:2223\", \"algo-2:2223\"], \"worker\": [\"algo-2:2222\"]}, \"environment\": \"cloud\", \"task\": {\"index\": 0, \"type\": \"worker\"}}\u001b[0m\n",
      "\u001b[35mPYTHONPATH=/opt/ml/code:/usr/local/bin:/usr/lib/python36.zip:/usr/lib/python3.6:/usr/lib/python3.6/lib-dynload:/usr/local/lib/python3.6/dist-packages:/usr/lib/python3/dist-packages\n",
      "\u001b[0m\n",
      "\u001b[35mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[35m/usr/bin/python3 mnist.py --model_dir s3://sagemaker-cn-north-1-876820548815/tensorflow-training-2020-12-30-08-41-55-827/model\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/__init__.py:1473: The name tf.estimator.inputs is deprecated. Please use tf.compat.v1.estimator.inputs instead.\n",
      "\u001b[0m\n",
      "\u001b[34m2020-12-30 08:46:02,332 sagemaker-containers INFO     Imported framework sagemaker_tensorflow_container.training\u001b[0m\n",
      "\u001b[34m2020-12-30 08:46:02,624 sagemaker_tensorflow_container.training INFO     Running distributed training job with parameter servers\u001b[0m\n",
      "\u001b[34m2020-12-30 08:46:02,625 sagemaker_tensorflow_container.training INFO     Launching parameter server process\u001b[0m\n",
      "\u001b[34m2020-12-30 08:46:02,625 sagemaker_tensorflow_container.training INFO     Running distributed training job with parameter servers\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/sagemaker_tensorflow_container/training.py:99: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\u001b[0m\n",
      "\u001b[34m2020-12-30 08:46:02,625 tensorflow   WARNING  From /usr/local/lib/python3.6/dist-packages/sagemaker_tensorflow_container/training.py:99: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/sagemaker_tensorflow_container/training.py:101: The name tf.train.Server is deprecated. Please use tf.distribute.Server instead.\n",
      "\u001b[0m\n",
      "\u001b[34m2020-12-30 08:46:02,626 tensorflow   WARNING  From /usr/local/lib/python3.6/dist-packages/sagemaker_tensorflow_container/training.py:101: The name tf.train.Server is deprecated. Please use tf.distribute.Server instead.\n",
      "\u001b[0m\n",
      "\u001b[34m2020-12-30 08:46:03,388 sagemaker_tensorflow_container.training INFO     Launching worker process\u001b[0m\n",
      "\u001b[34m2020-12-30 08:46:03,641 sagemaker-containers INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[34mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {\n",
      "        \"sagemaker_parameter_server_enabled\": true\n",
      "    },\n",
      "    \"channel_input_dirs\": {\n",
      "        \"training\": \"/opt/ml/input/data/training\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_tensorflow_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\",\n",
      "        \"algo-2\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"model_dir\": \"s3://sagemaker-cn-north-1-876820548815/tensorflow-training-2020-12-30-08-41-55-827/model\"\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"training\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"tensorflow-training-2020-12-30-08-41-55-827\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-cn-north-1-876820548815/tensorflow-training-2020-12-30-08-41-55-827/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"mnist\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 8,\n",
      "    \"num_gpus\": 1,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\",\n",
      "            \"algo-2\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"mnist.py\"\u001b[0m\n",
      "\u001b[34m}\n",
      "\u001b[0m\n",
      "\u001b[34mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\",\"algo-2\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"model_dir\":\"s3://sagemaker-cn-north-1-876820548815/tensorflow-training-2020-12-30-08-41-55-827/model\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=mnist.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={\"sagemaker_parameter_server_enabled\":true}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\",\"algo-2\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"training\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=mnist\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_tensorflow_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=8\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=1\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-cn-north-1-876820548815/tensorflow-training-2020-12-30-08-41-55-827/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{\"sagemaker_parameter_server_enabled\":true},\"channel_input_dirs\":{\"training\":\"/opt/ml/input/data/training\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_tensorflow_container.training:main\",\"hosts\":[\"algo-1\",\"algo-2\"],\"hyperparameters\":{\"model_dir\":\"s3://sagemaker-cn-north-1-876820548815/tensorflow-training-2020-12-30-08-41-55-827/model\"},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"tensorflow-training-2020-12-30-08-41-55-827\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-cn-north-1-876820548815/tensorflow-training-2020-12-30-08-41-55-827/source/sourcedir.tar.gz\",\"module_name\":\"mnist\",\"network_interface_name\":\"eth0\",\"num_cpus\":8,\"num_gpus\":1,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\",\"algo-2\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"mnist.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--model_dir\",\"s3://sagemaker-cn-north-1-876820548815/tensorflow-training-2020-12-30-08-41-55-827/model\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAINING=/opt/ml/input/data/training\u001b[0m\n",
      "\u001b[34mSM_HP_MODEL_DIR=s3://sagemaker-cn-north-1-876820548815/tensorflow-training-2020-12-30-08-41-55-827/model\u001b[0m\n",
      "\u001b[34mTF_CONFIG={\"cluster\": {\"master\": [\"algo-1:2222\"], \"ps\": [\"algo-1:2223\", \"algo-2:2223\"], \"worker\": [\"algo-2:2222\"]}, \"environment\": \"cloud\", \"task\": {\"index\": 0, \"type\": \"master\"}}\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/usr/local/bin:/usr/lib/python36.zip:/usr/lib/python3.6:/usr/lib/python3.6/lib-dynload:/usr/local/lib/python3.6/dist-packages:/usr/lib/python3/dist-packages\n",
      "\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[34m/usr/bin/python3 mnist.py --model_dir s3://sagemaker-cn-north-1-876820548815/tensorflow-training-2020-12-30-08-41-55-827/model\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[35mWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/__init__.py:1473: The name tf.estimator.inputs is deprecated. Please use tf.compat.v1.estimator.inputs instead.\n",
      "\u001b[0m\n",
      "\u001b[35mWARNING:tensorflow:From mnist.py:161: The name tf.train.LoggingTensorHook is deprecated. Please use tf.estimator.LoggingTensorHook instead.\n",
      "\u001b[0m\n",
      "\u001b[35mWARNING:tensorflow:From mnist.py:165: The name tf.estimator.inputs.numpy_input_fn is deprecated. Please use tf.compat.v1.estimator.inputs.numpy_input_fn instead.\n",
      "\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/__init__.py:1473: The name tf.estimator.inputs is deprecated. Please use tf.compat.v1.estimator.inputs instead.\n",
      "\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From mnist.py:161: The name tf.train.LoggingTensorHook is deprecated. Please use tf.estimator.LoggingTensorHook instead.\n",
      "\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From mnist.py:165: The name tf.estimator.inputs.numpy_input_fn is deprecated. Please use tf.compat.v1.estimator.inputs.numpy_input_fn instead.\n",
      "\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/inputs/queues/feeding_queue_runner.py:62: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mTo construct input pipelines, use the `tf.data` module.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/inputs/queues/feeding_queue_runner.py:62: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mTo construct input pipelines, use the `tf.data` module.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/inputs/queues/feeding_functions.py:500: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mTo construct input pipelines, use the `tf.data` module.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/inputs/queues/feeding_functions.py:500: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mTo construct input pipelines, use the `tf.data` module.\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Calling model_fn.\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Calling model_fn.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From mnist.py:46: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse `tf.keras.layers.Conv2D` instead.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From mnist.py:46: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse `tf.keras.layers.Conv2D` instead.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/layers/convolutional.py:424: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mPlease use `layer.__call__` method instead.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/layers/convolutional.py:424: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mPlease use `layer.__call__` method instead.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From mnist.py:52: max_pooling2d (from tensorflow.python.layers.pooling) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse keras.layers.MaxPooling2D instead.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From mnist.py:52: max_pooling2d (from tensorflow.python.layers.pooling) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse keras.layers.MaxPooling2D instead.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From mnist.py:81: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse keras.layers.Dense instead.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From mnist.py:81: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse keras.layers.Dense instead.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From mnist.py:85: dropout (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse keras.layers.dropout instead.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From mnist.py:85: dropout (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse keras.layers.dropout instead.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From mnist.py:103: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From mnist.py:103: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/losses/losses_impl.py:121: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse tf.where in 2.0, which has the same broadcast rule as np.where\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/losses/losses_impl.py:121: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse tf.where in 2.0, which has the same broadcast rule as np.where\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From mnist.py:107: The name tf.train.GradientDescentOptimizer is deprecated. Please use tf.compat.v1.train.GradientDescentOptimizer instead.\n",
      "\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From mnist.py:107: The name tf.train.GradientDescentOptimizer is deprecated. Please use tf.compat.v1.train.GradientDescentOptimizer instead.\n",
      "\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From mnist.py:110: The name tf.train.get_global_step is deprecated. Please use tf.compat.v1.train.get_global_step instead.\n",
      "\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From mnist.py:110: The name tf.train.get_global_step is deprecated. Please use tf.compat.v1.train.get_global_step instead.\n",
      "\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Done calling model_fn.\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Done calling model_fn.\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Create CheckpointSaverHook.\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Create CheckpointSaverHook.\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Graph was finalized.\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Graph was finalized.\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Running local_init_op.\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Running local_init_op.\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Done running local_init_op.\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Done running local_init_op.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py:888: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mTo construct input pipelines, use the `tf.data` module.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py:888: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mTo construct input pipelines, use the `tf.data` module.\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Saving checkpoints for 0 into s3://sagemaker-cn-north-1-876820548815/tensorflow-training-2020-12-30-08-41-55-827/model/model.ckpt.\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Saving checkpoints for 0 into s3://sagemaker-cn-north-1-876820548815/tensorflow-training-2020-12-30-08-41-55-827/model/model.ckpt.\u001b[0m\n",
      "\u001b[35mWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[35mInstructions for updating:\u001b[0m\n",
      "\u001b[35mUse Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\u001b[0m\n",
      "\u001b[35mWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[35mInstructions for updating:\u001b[0m\n",
      "\u001b[35mUse Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\u001b[0m\n",
      "\u001b[35mWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/inputs/queues/feeding_queue_runner.py:62: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[35mInstructions for updating:\u001b[0m\n",
      "\u001b[35mTo construct input pipelines, use the `tf.data` module.\u001b[0m\n",
      "\u001b[35mWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/inputs/queues/feeding_queue_runner.py:62: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[35mInstructions for updating:\u001b[0m\n",
      "\u001b[35mTo construct input pipelines, use the `tf.data` module.\u001b[0m\n",
      "\u001b[35mWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/inputs/queues/feeding_functions.py:500: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[35mInstructions for updating:\u001b[0m\n",
      "\u001b[35mTo construct input pipelines, use the `tf.data` module.\u001b[0m\n",
      "\u001b[35mWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/inputs/queues/feeding_functions.py:500: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[35mInstructions for updating:\u001b[0m\n",
      "\u001b[35mTo construct input pipelines, use the `tf.data` module.\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:Calling model_fn.\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:Calling model_fn.\u001b[0m\n",
      "\u001b[35mWARNING:tensorflow:From mnist.py:46: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[35mInstructions for updating:\u001b[0m\n",
      "\u001b[35mUse `tf.keras.layers.Conv2D` instead.\u001b[0m\n",
      "\u001b[35mWARNING:tensorflow:From mnist.py:46: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[35mInstructions for updating:\u001b[0m\n",
      "\u001b[35mUse `tf.keras.layers.Conv2D` instead.\u001b[0m\n",
      "\u001b[35mWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/layers/convolutional.py:424: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[35mInstructions for updating:\u001b[0m\n",
      "\u001b[35mPlease use `layer.__call__` method instead.\u001b[0m\n",
      "\u001b[35mWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/layers/convolutional.py:424: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[35mInstructions for updating:\u001b[0m\n",
      "\u001b[35mPlease use `layer.__call__` method instead.\u001b[0m\n",
      "\u001b[35mWARNING:tensorflow:From mnist.py:52: max_pooling2d (from tensorflow.python.layers.pooling) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[35mInstructions for updating:\u001b[0m\n",
      "\u001b[35mUse keras.layers.MaxPooling2D instead.\u001b[0m\n",
      "\u001b[35mWARNING:tensorflow:From mnist.py:52: max_pooling2d (from tensorflow.python.layers.pooling) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[35mInstructions for updating:\u001b[0m\n",
      "\u001b[35mUse keras.layers.MaxPooling2D instead.\u001b[0m\n",
      "\u001b[35mWARNING:tensorflow:From mnist.py:81: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[35mInstructions for updating:\u001b[0m\n",
      "\u001b[35mUse keras.layers.Dense instead.\u001b[0m\n",
      "\u001b[35mWARNING:tensorflow:From mnist.py:81: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[35mInstructions for updating:\u001b[0m\n",
      "\u001b[35mUse keras.layers.Dense instead.\u001b[0m\n",
      "\u001b[35mWARNING:tensorflow:From mnist.py:85: dropout (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[35mInstructions for updating:\u001b[0m\n",
      "\u001b[35mUse keras.layers.dropout instead.\u001b[0m\n",
      "\u001b[35mWARNING:tensorflow:From mnist.py:85: dropout (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[35mInstructions for updating:\u001b[0m\n",
      "\u001b[35mUse keras.layers.dropout instead.\u001b[0m\n",
      "\u001b[35mWARNING:tensorflow:From mnist.py:103: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\u001b[0m\n",
      "\u001b[35mWARNING:tensorflow:From mnist.py:103: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\u001b[0m\n",
      "\u001b[35mWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/losses/losses_impl.py:121: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[35mInstructions for updating:\u001b[0m\n",
      "\u001b[35mUse tf.where in 2.0, which has the same broadcast rule as np.where\u001b[0m\n",
      "\u001b[35mWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/losses/losses_impl.py:121: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[35mInstructions for updating:\u001b[0m\n",
      "\u001b[35mUse tf.where in 2.0, which has the same broadcast rule as np.where\u001b[0m\n",
      "\u001b[35mWARNING:tensorflow:From mnist.py:107: The name tf.train.GradientDescentOptimizer is deprecated. Please use tf.compat.v1.train.GradientDescentOptimizer instead.\n",
      "\u001b[0m\n",
      "\u001b[35mWARNING:tensorflow:From mnist.py:107: The name tf.train.GradientDescentOptimizer is deprecated. Please use tf.compat.v1.train.GradientDescentOptimizer instead.\n",
      "\u001b[0m\n",
      "\u001b[35mWARNING:tensorflow:From mnist.py:110: The name tf.train.get_global_step is deprecated. Please use tf.compat.v1.train.get_global_step instead.\n",
      "\u001b[0m\n",
      "\u001b[35mWARNING:tensorflow:From mnist.py:110: The name tf.train.get_global_step is deprecated. Please use tf.compat.v1.train.get_global_step instead.\n",
      "\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:Done calling model_fn.\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:Done calling model_fn.\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:Create CheckpointSaverHook.\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:Create CheckpointSaverHook.\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:Graph was finalized.\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:Graph was finalized.\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:Running local_init_op.\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:Running local_init_op.\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:Done running local_init_op.\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:Done running local_init_op.\u001b[0m\n",
      "\u001b[35mWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py:888: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[35mInstructions for updating:\u001b[0m\n",
      "\u001b[35mTo construct input pipelines, use the `tf.data` module.\u001b[0m\n",
      "\u001b[35mWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py:888: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[35mInstructions for updating:\u001b[0m\n",
      "\u001b[35mTo construct input pipelines, use the `tf.data` module.\u001b[0m\n",
      "\n",
      "2020-12-30 08:45:57 Training - Training image download completed. Training in progress.\u001b[34mINFO:tensorflow:loss = 2.3087025, step = 0\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 2.3087025, step = 0\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 2.299679, step = 0\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 2.299679, step = 0\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 53.9196\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 53.9196\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 2.2803843, step = 161 (2.835 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 2.2803843, step = 161 (2.835 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 57.3377\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 57.3377\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 2.2626095, step = 275 (5.253 sec)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 2.2626095, step = 275 (5.253 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 57.8822\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 57.8822\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 2.2525337, step = 312 (2.617 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 2.2525337, step = 312 (2.617 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 58.0709\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 58.0709\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 2.2218258, step = 462 (2.569 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 2.2218258, step = 462 (2.569 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 58.342\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 58.342\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 2.2225153, step = 575 (5.174 sec)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 2.2225153, step = 575 (5.174 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 2.19203, step = 612 (2.597 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 2.19203, step = 612 (2.597 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 57.5601\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 57.5601\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 58.982\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 58.982\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 2.1158483, step = 761 (2.523 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 2.1158483, step = 761 (2.523 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 58.5469\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 58.5469\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 2.0957656, step = 877 (5.155 sec)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 2.0957656, step = 877 (5.155 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 2.0660894, step = 911 (2.577 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 2.0660894, step = 911 (2.577 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 58.0188\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 58.0188\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 58.1108\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 58.1108\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 1.9339844, step = 1062 (2.623 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 1.9339844, step = 1062 (2.623 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 57.8869\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 57.8869\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 1.7947714, step = 1176 (5.158 sec)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 1.7947714, step = 1176 (5.158 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 1.8133796, step = 1211 (2.559 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 1.8133796, step = 1211 (2.559 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 58.2379\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 58.2379\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 58.8121\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 58.8121\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 1.576467, step = 1361 (2.537 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 1.576467, step = 1361 (2.537 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 58.5477\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 58.5477\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 1.4198899, step = 1478 (5.149 sec)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 1.4198899, step = 1478 (5.149 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 1.1886325, step = 1510 (2.528 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 1.1886325, step = 1510 (2.528 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 59.1092\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 59.1092\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 58.6032\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 58.6032\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 1.060317, step = 1659 (2.552 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 1.060317, step = 1659 (2.552 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 58.5656\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 58.5656\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.9777327, step = 1778 (5.129 sec)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.9777327, step = 1778 (5.129 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.84999865, step = 1810 (2.603 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.84999865, step = 1810 (2.603 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 58.1018\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 58.1018\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 59.2059\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 59.2059\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.8471418, step = 1960 (2.525 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.8471418, step = 1960 (2.525 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 58.7212\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 58.7212\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.76113164, step = 2109 (2.532 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.76113164, step = 2109 (2.532 sec)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.7503244, step = 2080 (5.114 sec)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.7503244, step = 2080 (5.114 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 59.2234\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 59.2234\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 59.2155\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 59.2155\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.5977818, step = 2259 (2.533 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.5977818, step = 2259 (2.533 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 59.5935\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 59.5935\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.7212769, step = 2407 (2.493 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.7212769, step = 2407 (2.493 sec)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.5414308, step = 2383 (5.114 sec)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.5414308, step = 2383 (5.114 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 59.5174\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 59.5174\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 59.5166\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 59.5166\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.6533339, step = 2557 (2.508 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.6533339, step = 2557 (2.508 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 58.9971\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 58.9971\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.4685924, step = 2706 (2.525 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.4685924, step = 2706 (2.525 sec)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.4529828, step = 2686 (5.113 sec)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.4529828, step = 2686 (5.113 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 58.9623\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 58.9623\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 58.8818\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 58.8818\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.42200676, step = 2855 (2.543 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.42200676, step = 2855 (2.543 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 59.2192\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 59.2192\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.38639832, step = 2990 (5.149 sec)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.38639832, step = 2990 (5.149 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.44990918, step = 3004 (2.523 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.44990918, step = 3004 (2.523 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 59.0357\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 59.0357\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 59.5433\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 59.5433\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.4987328, step = 3153 (2.496 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.4987328, step = 3153 (2.496 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 59.3811\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 59.3811\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.46006927, step = 3295 (5.157 sec)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.46006927, step = 3295 (5.157 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.44217587, step = 3302 (2.525 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.44217587, step = 3302 (2.525 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 58.3571\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 58.3571\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 60.0323\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 60.0323\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.29634076, step = 3449 (2.477 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.29634076, step = 3449 (2.477 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 60.1975\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 60.1975\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.4040099, step = 3603 (5.165 sec)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.4040099, step = 3603 (5.165 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.35025933, step = 3598 (2.494 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.35025933, step = 3598 (2.494 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 58.8892\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 58.8892\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 59.597\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 59.597\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.46044075, step = 3746 (2.484 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.46044075, step = 3746 (2.484 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 59.0138\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 59.0138\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.31081033, step = 3907 (5.132 sec)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.31081033, step = 3907 (5.132 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.3375252, step = 3896 (2.558 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.3375252, step = 3896 (2.558 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 58.6633\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 58.6633\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 59.5844\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 59.5844\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.39163458, step = 4044 (2.486 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.39163458, step = 4044 (2.486 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 59.8232\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 59.8232\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.55265063, step = 4214 (5.161 sec)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.55265063, step = 4214 (5.161 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.35859975, step = 4193 (2.498 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.35859975, step = 4193 (2.498 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 59.5116\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 59.5116\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 59.1944\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 59.1944\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.47209167, step = 4341 (2.497 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.47209167, step = 4341 (2.497 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 59.413\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 59.413\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.37968093, step = 4491 (2.560 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.37968093, step = 4491 (2.560 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 58.6782\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 58.6782\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.32748592, step = 4517 (5.124 sec)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.32748592, step = 4517 (5.124 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 59.3625\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 59.3625\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.2890825, step = 4640 (2.493 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.2890825, step = 4640 (2.493 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 58.7939\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 58.7939\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.5069011, step = 4788 (2.507 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.5069011, step = 4788 (2.507 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 59.5808\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 59.5808\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.3491012, step = 4825 (5.179 sec)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.3491012, step = 4825 (5.179 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.29766327, step = 4936 (2.456 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.29766327, step = 4936 (2.456 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 60.5569\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 60.5569\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 59.4132\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 59.4132\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.24282113, step = 5084 (2.497 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.24282113, step = 5084 (2.497 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 59.6723\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 59.6723\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.30716336, step = 5132 (5.150 sec)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.30716336, step = 5132 (5.150 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.3284561, step = 5232 (2.467 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.3284561, step = 5232 (2.467 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 60.0081\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 60.0081\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 59.5066\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 59.5066\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.40493858, step = 5381 (2.522 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.40493858, step = 5381 (2.522 sec)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.42462066, step = 5437 (5.140 sec)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.42462066, step = 5437 (5.140 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 58.0492\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 58.0492\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.41071415, step = 5530 (2.515 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.41071415, step = 5530 (2.515 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 59.8135\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 59.8135\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 58.982\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 58.982\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.5019284, step = 5679 (2.523 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.5019284, step = 5679 (2.523 sec)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.18036692, step = 5741 (5.138 sec)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.18036692, step = 5741 (5.138 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 58.9888\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 58.9888\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.40450788, step = 5828 (2.515 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.40450788, step = 5828 (2.515 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 59.0598\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 59.0598\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 59.1559\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 59.1559\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.22713071, step = 5978 (2.549 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.22713071, step = 5978 (2.549 sec)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.44800732, step = 6044 (5.128 sec)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.44800732, step = 6044 (5.128 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 59.3023\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 59.3023\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.24967553, step = 6127 (2.494 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.24967553, step = 6127 (2.494 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 59.8606\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 59.8606\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 60.0179\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 60.0179\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.20985448, step = 6275 (2.484 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.20985448, step = 6275 (2.484 sec)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.25355193, step = 6348 (5.133 sec)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.25355193, step = 6348 (5.133 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 57.6461\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 57.6461\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.1556879, step = 6425 (2.554 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.1556879, step = 6425 (2.554 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 59.2998\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 59.2998\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 59.2039\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 59.2039\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.13800187, step = 6573 (2.505 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.13800187, step = 6573 (2.505 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 59.2212\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 59.2212\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.3492813, step = 6653 (5.139 sec)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.3492813, step = 6653 (5.139 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.17923854, step = 6723 (2.552 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.17923854, step = 6723 (2.552 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 58.4803\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 58.4803\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 60.1453\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 60.1453\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.2227068, step = 6876 (2.708 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.2227068, step = 6876 (2.708 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 54.5482\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 54.5482\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.18624067, step = 6949 (5.147 sec)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.18624067, step = 6949 (5.147 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.27634382, step = 7024 (2.501 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.27634382, step = 7024 (2.501 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 59.7041\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 59.7041\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 59.7226\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 59.7226\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.08066957, step = 7172 (2.467 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.08066957, step = 7172 (2.467 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 59.2048\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 59.2048\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.085621506, step = 7256 (5.160 sec)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.085621506, step = 7256 (5.160 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.32373998, step = 7321 (2.512 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.32373998, step = 7321 (2.512 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 59.4982\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 59.4982\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 58.8123\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 58.8123\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.1782553, step = 7469 (2.506 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.1782553, step = 7469 (2.506 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 58.7989\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 58.7989\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.19512694, step = 7563 (5.195 sec)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.19512694, step = 7563 (5.195 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.32236233, step = 7617 (2.516 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.32236233, step = 7617 (2.516 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 59.6873\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 59.6873\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 60.0121\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 60.0121\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.2703149, step = 7766 (2.485 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.2703149, step = 7766 (2.485 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 57.719\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 57.719\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.27468848, step = 7868 (5.166 sec)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.27468848, step = 7868 (5.166 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.3067871, step = 7915 (2.564 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.3067871, step = 7915 (2.564 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 59.4309\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 59.4309\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 59.4907\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 59.4907\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.27096787, step = 8064 (2.489 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.27096787, step = 8064 (2.489 sec)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.3089193, step = 8174 (5.140 sec)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.3089193, step = 8174 (5.140 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 59.3765\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 59.3765\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.13225272, step = 8212 (2.492 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.13225272, step = 8212 (2.492 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 59.9397\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 59.9397\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.2873603, step = 8359 (2.446 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.2873603, step = 8359 (2.446 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 60.1809\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 60.1809\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 58.6067\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 58.6067\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.29175508, step = 8509 (2.552 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.29175508, step = 8509 (2.552 sec)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.20704949, step = 8481 (5.153 sec)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.20704949, step = 8481 (5.153 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 59.0159\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 59.0159\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.22261564, step = 8658 (2.521 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.22261564, step = 8658 (2.521 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 59.2029\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 59.2029\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 58.9452\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 58.9452\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.20503289, step = 8807 (2.516 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.20503289, step = 8807 (2.516 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 59.8984\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 59.8984\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.14089027, step = 8784 (5.139 sec)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.14089027, step = 8784 (5.139 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.23650046, step = 8955 (2.488 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.23650046, step = 8955 (2.488 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 59.5391\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 59.5391\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 59.0025\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 59.0025\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.22806755, step = 9103 (2.496 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.22806755, step = 9103 (2.496 sec)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.16837823, step = 9091 (5.167 sec)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.16837823, step = 9091 (5.167 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 60.1897\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 60.1897\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.2243777, step = 9252 (2.529 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.2243777, step = 9252 (2.529 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 57.7815\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 57.7815\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 58.6503\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 58.6503\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.23831393, step = 9401 (2.528 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.23831393, step = 9401 (2.528 sec)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.15943642, step = 9396 (5.178 sec)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.15943642, step = 9396 (5.178 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 59.0078\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 59.0078\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.14359052, step = 9549 (2.501 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.14359052, step = 9549 (2.501 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 59.8746\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 59.8746\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 58.8058\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 58.8058\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.1915459, step = 9702 (5.197 sec)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.1915459, step = 9702 (5.197 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.23217632, step = 9698 (2.556 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.23217632, step = 9698 (2.556 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 56.9297\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 56.9297\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.20996147, step = 9848 (2.640 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.20996147, step = 9848 (2.640 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 55.7079\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 55.7079\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 57.3696\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 57.3696\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.21996847, step = 9997 (2.598 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.21996847, step = 9997 (2.598 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 59.8977\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 59.8977\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.23273599, step = 10005 (5.320 sec)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.23273599, step = 10005 (5.320 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.10230138, step = 10145 (2.473 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.10230138, step = 10145 (2.473 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 59.5928\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 59.5928\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 57.8623\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 57.8623\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.21049999, step = 10293 (2.531 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.21049999, step = 10293 (2.531 sec)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.17526676, step = 10314 (5.209 sec)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.17526676, step = 10314 (5.209 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 59.0623\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 59.0623\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.16159478, step = 10442 (2.517 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.16159478, step = 10442 (2.517 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 59.6495\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 59.6495\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 58.7837\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 58.7837\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.18786503, step = 10591 (2.520 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.18786503, step = 10591 (2.520 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 58.9506\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 58.9506\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.033385426, step = 10618 (5.151 sec)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.033385426, step = 10618 (5.151 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.14199619, step = 10739 (2.502 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.14199619, step = 10739 (2.502 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 59.631\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 59.631\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 58.2548\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 58.2548\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.1766258, step = 10888 (2.540 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.1766258, step = 10888 (2.540 sec)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.16736779, step = 10924 (5.188 sec)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.16736779, step = 10924 (5.188 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 58.6375\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 58.6375\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.14174984, step = 11037 (2.518 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.14174984, step = 11037 (2.518 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 60.5155\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 60.5155\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 58.3374\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 58.3374\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.16303456, step = 11186 (2.523 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.16303456, step = 11186 (2.523 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 59.3061\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 59.3061\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.09384437, step = 11228 (5.138 sec)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.09384437, step = 11228 (5.138 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.18179494, step = 11334 (2.504 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.18179494, step = 11334 (2.504 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 59.5133\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 59.5133\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.13359018, step = 11483 (2.513 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.13359018, step = 11483 (2.513 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 59.1841\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 59.1841\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.2696329, step = 11533 (5.162 sec)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.2696329, step = 11533 (5.162 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 59.3962\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 59.3962\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.23920754, step = 11631 (2.491 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.23920754, step = 11631 (2.491 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 59.3927\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 59.3927\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.14085397, step = 11781 (2.551 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.14085397, step = 11781 (2.551 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 58.011\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 58.011\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.1641614, step = 11838 (5.161 sec)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.1641614, step = 11838 (5.161 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 58.2218\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 58.2218\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.16091727, step = 11931 (2.587 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.16091727, step = 11931 (2.587 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 58.0267\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 58.0267\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.11008643, step = 12080 (2.556 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.11008643, step = 12080 (2.556 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 58.702\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 58.702\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.17791748, step = 12137 (5.152 sec)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.17791748, step = 12137 (5.152 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 58.1036\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 58.1036\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.2157688, step = 12231 (2.577 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.2157688, step = 12231 (2.577 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 58.7907\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 58.7907\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.11508012, step = 12380 (2.540 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.11508012, step = 12380 (2.540 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 58.5662\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 58.5662\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.4504145, step = 12438 (5.150 sec)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.4504145, step = 12438 (5.150 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 57.438\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 57.438\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.18819058, step = 12530 (2.628 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.18819058, step = 12530 (2.628 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 57.231\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 57.231\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.27364817, step = 12680 (2.541 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.27364817, step = 12680 (2.541 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 59.3805\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 59.3805\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.14722352, step = 12742 (5.186 sec)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.14722352, step = 12742 (5.186 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 60.3817\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 60.3817\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.09994051, step = 12827 (2.455 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.09994051, step = 12827 (2.455 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 58.5288\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 58.5288\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.20948513, step = 12974 (2.487 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.20948513, step = 12974 (2.487 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 60.1732\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 60.1732\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.17366968, step = 13048 (5.143 sec)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.17366968, step = 13048 (5.143 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 59.7684\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 59.7684\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.14109902, step = 13122 (2.469 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.14109902, step = 13122 (2.469 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 59.8406\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 59.8406\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.06739804, step = 13271 (2.507 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.06739804, step = 13271 (2.507 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 58.7603\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 58.7603\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.1467832, step = 13355 (5.170 sec)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.1467832, step = 13355 (5.170 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 57.993\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 57.993\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.19828562, step = 13420 (2.590 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.19828562, step = 13420 (2.590 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 58.423\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 58.423\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.12432197, step = 13569 (2.543 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.12432197, step = 13569 (2.543 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 58.4253\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 58.4253\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.26657, step = 13661 (5.216 sec)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.26657, step = 13661 (5.216 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 60.111\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 60.111\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.06520164, step = 13718 (2.488 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.06520164, step = 13718 (2.488 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 58.7318\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 58.7318\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.14424495, step = 13866 (2.509 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.14424495, step = 13866 (2.509 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 59.5042\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 59.5042\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.12555031, step = 13966 (5.166 sec)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.12555031, step = 13966 (5.166 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 50.6108\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 50.6108\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.09999793, step = 14025 (2.985 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.09999793, step = 14025 (2.985 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 58.6052\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 58.6052\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.128889, step = 14174 (2.524 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.128889, step = 14174 (2.524 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 59.0801\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 59.0801\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.20320804, step = 14249 (5.103 sec)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.20320804, step = 14249 (5.103 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 59.5544\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 59.5544\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.14698517, step = 14322 (2.503 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.14698517, step = 14322 (2.503 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 59.597\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 59.597\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.04435922, step = 14470 (2.498 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.04435922, step = 14470 (2.498 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 58.2556\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 58.2556\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.1101651, step = 14556 (5.188 sec)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.1101651, step = 14556 (5.188 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 59.4208\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 59.4208\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.1427831, step = 14619 (2.525 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.1427831, step = 14619 (2.525 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 60.0359\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 60.0359\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.11954729, step = 14767 (2.469 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.11954729, step = 14767 (2.469 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 59.0879\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 59.0879\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.17838806, step = 14862 (5.154 sec)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.17838806, step = 14862 (5.154 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 59.0773\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 59.0773\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.16243422, step = 14916 (2.532 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.16243422, step = 14916 (2.532 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 58.9564\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 58.9564\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.17792697, step = 15066 (2.537 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.17792697, step = 15066 (2.537 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 58.9833\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 58.9833\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.14605038, step = 15166 (5.140 sec)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.14605038, step = 15166 (5.140 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 59.5132\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 59.5132\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.16286297, step = 15215 (2.511 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.16286297, step = 15215 (2.511 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 59.3875\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 59.3875\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.17930949, step = 15364 (2.496 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.17930949, step = 15364 (2.496 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 59.8598\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 59.8598\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.09530473, step = 15472 (5.115 sec)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.09530473, step = 15472 (5.115 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 60.5425\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 60.5425\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.20306967, step = 15512 (2.462 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.20306967, step = 15512 (2.462 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 59.7127\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 59.7127\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.095793396, step = 15659 (2.487 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.095793396, step = 15659 (2.487 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 58.0018\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 58.0018\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.20448397, step = 15808 (2.504 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.20448397, step = 15808 (2.504 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 60.1948\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 60.1948\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.18347585, step = 15779 (5.178 sec)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.18347585, step = 15779 (5.178 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 59.9578\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 59.9578\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.18271285, step = 15955 (2.464 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.18271285, step = 15955 (2.464 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 59.2516\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 59.2516\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.046394013, step = 16104 (2.526 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.046394013, step = 16104 (2.526 sec)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.09322796, step = 16086 (5.163 sec)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.09322796, step = 16086 (5.163 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 58.7942\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 58.7942\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 59.2397\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 59.2397\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.12768966, step = 16254 (2.554 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.12768966, step = 16254 (2.554 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 58.9423\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 58.9423\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.18008882, step = 16402 (2.486 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.18008882, step = 16402 (2.486 sec)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.1529478, step = 16391 (5.164 sec)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.1529478, step = 16391 (5.164 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 59.3114\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 59.3114\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 59.1702\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 59.1702\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.12384551, step = 16550 (2.508 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.12384551, step = 16550 (2.508 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 59.0405\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 59.0405\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.1370158, step = 16698 (2.507 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.1370158, step = 16698 (2.507 sec)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.15566465, step = 16699 (5.194 sec)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.15566465, step = 16699 (5.194 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 59.3958\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 59.3958\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 58.3564\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 58.3564\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.23592243, step = 16848 (2.538 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.23592243, step = 16848 (2.538 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 58.3922\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 58.3922\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.19486283, step = 17003 (5.192 sec)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.19486283, step = 17003 (5.192 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.12880339, step = 16996 (2.539 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.12880339, step = 16996 (2.539 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 59.0195\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 59.0195\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 58.0702\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 58.0702\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.19050685, step = 17146 (2.555 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.19050685, step = 17146 (2.555 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 59.3975\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 59.3975\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.11316416, step = 17307 (5.175 sec)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.11316416, step = 17307 (5.175 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.11487677, step = 17295 (2.525 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.11487677, step = 17295 (2.525 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 58.7522\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 58.7522\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 58.3623\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 58.3623\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.14731126, step = 17443 (2.531 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.14731126, step = 17443 (2.531 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 59.4135\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 59.4135\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.16557287, step = 17592 (2.513 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.16557287, step = 17592 (2.513 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 59.5777\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 59.5777\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.17176966, step = 17612 (5.173 sec)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.17176966, step = 17612 (5.173 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 58.2709\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 58.2709\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.16203529, step = 17741 (2.524 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.16203529, step = 17741 (2.524 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 58.4199\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 58.4199\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.17924288, step = 17890 (2.578 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.17924288, step = 17890 (2.578 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 57.863\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 57.863\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.07005576, step = 17916 (5.191 sec)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.07005576, step = 17916 (5.191 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 57.5257\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 57.5257\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.22922447, step = 18039 (2.572 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.22922447, step = 18039 (2.572 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 57.5272\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 57.5272\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.07488626, step = 18189 (2.632 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.07488626, step = 18189 (2.632 sec)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.12721527, step = 18219 (5.292 sec)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.12721527, step = 18219 (5.292 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 57.4269\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 57.4269\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 57.2675\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 57.2675\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.11446385, step = 18337 (2.575 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.11446385, step = 18337 (2.575 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 57.486\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 57.486\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.24511924, step = 18487 (2.610 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.24511924, step = 18487 (2.610 sec)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.08753975, step = 18521 (5.261 sec)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.08753975, step = 18521 (5.261 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 56.8463\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 56.8463\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 57.2232\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 57.2232\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.15079367, step = 18637 (2.628 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.15079367, step = 18637 (2.628 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 57.5675\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 57.5675\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.23291752, step = 18787 (2.619 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.23291752, step = 18787 (2.619 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 56.6729\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 56.6729\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.0946051, step = 18821 (5.244 sec)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.0946051, step = 18821 (5.244 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 57.5669\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 57.5669\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.11192142, step = 18938 (2.635 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.11192142, step = 18938 (2.635 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 57.479\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 57.479\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.09727281, step = 19087 (2.595 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.09727281, step = 19087 (2.595 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 57.8037\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 57.8037\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.18434143, step = 19121 (5.214 sec)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.18434143, step = 19121 (5.214 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 56.997\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 56.997\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.09071417, step = 19238 (2.618 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.09071417, step = 19238 (2.618 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 57.8093\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 57.8093\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.06018211, step = 19387 (2.588 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.06018211, step = 19387 (2.588 sec)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.16508766, step = 19422 (5.257 sec)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.16508766, step = 19422 (5.257 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 57.3931\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 57.3931\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 57.4407\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 57.4407\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.06788386, step = 19537 (2.616 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.06788386, step = 19537 (2.616 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 57.8889\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 57.8889\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.13446179, step = 19686 (2.567 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.13446179, step = 19686 (2.567 sec)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.16537102, step = 19724 (5.240 sec)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:loss = 0.16537102, step = 19724 (5.240 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 57.5274\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 57.5274\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.14219391, step = 19836 (2.654 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.14219391, step = 19836 (2.654 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 56.27\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 56.27\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 56.8464\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 56.8464\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.109087475, step = 19986 (2.634 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.109087475, step = 19986 (2.634 sec)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Saving checkpoints for 20002 into s3://sagemaker-cn-north-1-876820548815/tensorflow-training-2020-12-30-08-41-55-827/model/model.ckpt.\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Saving checkpoints for 20002 into s3://sagemaker-cn-north-1-876820548815/tensorflow-training-2020-12-30-08-41-55-827/model/model.ckpt.\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:Loss for final step: 0.079036705.\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:Loss for final step: 0.079036705.\u001b[0m\n",
      "\u001b[35m2020-12-30 08:51:56,345 sagemaker_tensorflow_container.training INFO     master algo-1 is still up, waiting for it to exit\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Calling model_fn.\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Calling model_fn.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From mnist.py:115: The name tf.metrics.accuracy is deprecated. Please use tf.compat.v1.metrics.accuracy instead.\n",
      "\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From mnist.py:115: The name tf.metrics.accuracy is deprecated. Please use tf.compat.v1.metrics.accuracy instead.\n",
      "\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Done calling model_fn.\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Done calling model_fn.\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Starting evaluation at 2020-12-30T08:51:57Z\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Starting evaluation at 2020-12-30T08:51:57Z\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Graph was finalized.\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Graph was finalized.\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Restoring parameters from s3://sagemaker-cn-north-1-876820548815/tensorflow-training-2020-12-30-08-41-55-827/model/model.ckpt-20002\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Restoring parameters from s3://sagemaker-cn-north-1-876820548815/tensorflow-training-2020-12-30-08-41-55-827/model/model.ckpt-20002\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Running local_init_op.\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Running local_init_op.\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Done running local_init_op.\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Done running local_init_op.\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Evaluation [10/100]\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Evaluation [10/100]\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Evaluation [20/100]\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Evaluation [20/100]\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Evaluation [30/100]\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Evaluation [30/100]\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Evaluation [40/100]\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Evaluation [40/100]\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Evaluation [50/100]\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Evaluation [50/100]\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Evaluation [60/100]\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Evaluation [60/100]\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Evaluation [70/100]\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Evaluation [70/100]\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Finished evaluation at 2020-12-30-08:51:57\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Finished evaluation at 2020-12-30-08:51:57\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Saving dict for global step 20002: accuracy = 0.9699, global_step = 20002, loss = 0.10069607\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Saving dict for global step 20002: accuracy = 0.9699, global_step = 20002, loss = 0.10069607\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Saving 'checkpoint_path' summary for global step 20002: s3://sagemaker-cn-north-1-876820548815/tensorflow-training-2020-12-30-08-41-55-827/model/model.ckpt-20002\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Saving 'checkpoint_path' summary for global step 20002: s3://sagemaker-cn-north-1-876820548815/tensorflow-training-2020-12-30-08-41-55-827/model/model.ckpt-20002\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Loss for final step: 0.17996663.\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Loss for final step: 0.17996663.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From mnist.py:184: Estimator.export_savedmodel (from tensorflow_estimator.python.estimator.estimator) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mThis function has been renamed, use `export_saved_model` instead.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From mnist.py:184: Estimator.export_savedmodel (from tensorflow_estimator.python.estimator.estimator) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mThis function has been renamed, use `export_saved_model` instead.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From mnist.py:145: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From mnist.py:145: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Calling model_fn.\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Calling model_fn.\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Done calling model_fn.\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Done calling model_fn.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/saved_model/signature_def_utils_impl.py:201: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mThis function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/saved_model/signature_def_utils_impl.py:201: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mThis function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Signatures INCLUDED in export for Classify: None\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Signatures INCLUDED in export for Classify: None\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Signatures INCLUDED in export for Regress: None\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Signatures INCLUDED in export for Regress: None\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Signatures INCLUDED in export for Predict: ['serving_default']\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Signatures INCLUDED in export for Predict: ['serving_default']\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Signatures INCLUDED in export for Train: None\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Signatures INCLUDED in export for Train: None\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Signatures INCLUDED in export for Eval: None\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Signatures INCLUDED in export for Eval: None\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Restoring parameters from s3://sagemaker-cn-north-1-876820548815/tensorflow-training-2020-12-30-08-41-55-827/model/model.ckpt-20002\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Restoring parameters from s3://sagemaker-cn-north-1-876820548815/tensorflow-training-2020-12-30-08-41-55-827/model/model.ckpt-20002\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Assets added to graph.\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Assets added to graph.\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:No assets to write.\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:No assets to write.\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:SavedModel written to: /opt/ml/model/temp-1609318318/saved_model.pb\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:SavedModel written to: /opt/ml/model/temp-1609318318/saved_model.pb\u001b[0m\n",
      "\u001b[34m2020-12-30 08:52:00,458 sagemaker-containers INFO     Reporting training SUCCESS\u001b[0m\n",
      "\u001b[35m2020-12-30 08:52:40,933 sagemaker_tensorflow_container.training INFO     master algo-1 is down, stopping parameter server\u001b[0m\n",
      "\u001b[35m2020-12-30 08:52:40,934 sagemaker_tensorflow_container.training WARNING  No model artifact is saved under path /opt/ml/model. Your training job will not save any model files to S3.\u001b[0m\n",
      "\u001b[35mFor details of how to construct your training script see:\u001b[0m\n",
      "\u001b[35mhttps://sagemaker.readthedocs.io/en/stable/using_tf.html#adapting-your-local-tensorflow-script\u001b[0m\n",
      "\u001b[35m2020-12-30 08:52:40,934 sagemaker-containers INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2020-12-30 08:52:53 Uploading - Uploading generated training model\n",
      "2020-12-30 08:52:53 Completed - Training job completed\n",
      "Training seconds: 944\n",
      "Billable seconds: 944\n"
     ]
    }
   ],
   "source": [
    "mnist_estimator.fit(training_data_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calling fit to train a model with TensorFlow 2.3.0 scroipt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-12-30 09:02:40 Starting - Starting the training job...\n",
      "2020-12-30 09:02:51 Starting - Launching requested ML instances............\n",
      "2020-12-30 09:04:50 Starting - Preparing the instances for training.........\n",
      "2020-12-30 09:06:20 Downloading - Downloading input data...\n",
      "2020-12-30 09:06:46 Training - Downloading the training image.....\u001b[34m2020-12-30 09:07:50.595708: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.2\u001b[0m\n",
      "\u001b[34m2020-12-30 09:07:53,636 sagemaker-training-toolkit INFO     Imported framework sagemaker_tensorflow_container.training\u001b[0m\n",
      "\u001b[34m2020-12-30 09:07:53,918 sagemaker_tensorflow_container.training INFO     Running distributed training job with parameter servers\u001b[0m\n",
      "\u001b[34m2020-12-30 09:07:53,918 sagemaker_tensorflow_container.training INFO     Launching parameter server process\u001b[0m\n",
      "\u001b[34m2020-12-30 09:07:53,918 sagemaker_tensorflow_container.training INFO     Running distributed training job with parameter servers\u001b[0m\n",
      "\u001b[34m2020-12-30 09:07:53.960919: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2300050000 Hz\u001b[0m\n",
      "\u001b[34m2020-12-30 09:07:53.961605: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5615aef9fa30 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\u001b[0m\n",
      "\u001b[34m2020-12-30 09:07:53.961636: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\u001b[0m\n",
      "\u001b[34m2020-12-30 09:07:53.965816: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1\u001b[0m\n",
      "\u001b[34m2020-12-30 09:07:54.281831: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:\u001b[0m\n",
      "\u001b[34m2020-12-30 09:07:54.281863: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      \u001b[0m\n",
      "\u001b[34m2020-12-30 09:07:54.299118: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:301] Initialize GrpcChannelCache for job master -> {0 -> algo-1:2222}\u001b[0m\n",
      "\u001b[34m2020-12-30 09:07:54.299146: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:301] Initialize GrpcChannelCache for job ps -> {0 -> algo-1:2223, 1 -> algo-2:2223}\u001b[0m\n",
      "\u001b[34m2020-12-30 09:07:54.299159: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:301] Initialize GrpcChannelCache for job worker -> {0 -> algo-2:2222}\u001b[0m\n",
      "\u001b[34m2020-12-30 09:07:54.299855: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:405] Started server with target: grpc://algo-2:2223\u001b[0m\n",
      "\u001b[34m2020-12-30 09:07:54,461 sagemaker_tensorflow_container.training INFO     Launching worker process\u001b[0m\n",
      "\n",
      "2020-12-30 09:07:59 Training - Training image download completed. Training in progress.\u001b[35m2020-12-30 09:08:00,973 sagemaker-training-toolkit INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[35mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[35m{\n",
      "    \"additional_framework_parameters\": {\n",
      "        \"sagemaker_parameter_server_enabled\": true\n",
      "    },\n",
      "    \"channel_input_dirs\": {\n",
      "        \"training\": \"/opt/ml/input/data/training\"\n",
      "    },\n",
      "    \"current_host\": \"algo-2\",\n",
      "    \"framework_module\": \"sagemaker_tensorflow_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\",\n",
      "        \"algo-2\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"model_dir\": \"s3://sagemaker-cn-north-1-876820548815/tensorflow-training-2020-12-30-09-02-39-680/model\"\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"training\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": false,\n",
      "    \"job_name\": \"tensorflow-training-2020-12-30-09-02-39-680\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-cn-north-1-876820548815/tensorflow-training-2020-12-30-09-02-39-680/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"mnist-2\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 8,\n",
      "    \"num_gpus\": 1,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-2\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\",\n",
      "            \"algo-2\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"mnist-2.py\"\u001b[0m\n",
      "\u001b[35m}\n",
      "\u001b[0m\n",
      "\u001b[35mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[35mSM_HOSTS=[\"algo-1\",\"algo-2\"]\u001b[0m\n",
      "\u001b[35mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[35mSM_HPS={\"model_dir\":\"s3://sagemaker-cn-north-1-876820548815/tensorflow-training-2020-12-30-09-02-39-680/model\"}\u001b[0m\n",
      "\u001b[35mSM_USER_ENTRY_POINT=mnist-2.py\u001b[0m\n",
      "\u001b[35mSM_FRAMEWORK_PARAMS={\"sagemaker_parameter_server_enabled\":true}\u001b[0m\n",
      "\u001b[35mSM_RESOURCE_CONFIG={\"current_host\":\"algo-2\",\"hosts\":[\"algo-1\",\"algo-2\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[35mSM_INPUT_DATA_CONFIG={\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[35mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[35mSM_CHANNELS=[\"training\"]\u001b[0m\n",
      "\u001b[35mSM_CURRENT_HOST=algo-2\u001b[0m\n",
      "\u001b[35mSM_MODULE_NAME=mnist-2\u001b[0m\n",
      "\u001b[35mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[35mSM_FRAMEWORK_MODULE=sagemaker_tensorflow_container.training:main\u001b[0m\n",
      "\u001b[35mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[35mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[35mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[35mSM_NUM_CPUS=8\u001b[0m\n",
      "\u001b[35mSM_NUM_GPUS=1\u001b[0m\n",
      "\u001b[35mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[35mSM_MODULE_DIR=s3://sagemaker-cn-north-1-876820548815/tensorflow-training-2020-12-30-09-02-39-680/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[35mSM_TRAINING_ENV={\"additional_framework_parameters\":{\"sagemaker_parameter_server_enabled\":true},\"channel_input_dirs\":{\"training\":\"/opt/ml/input/data/training\"},\"current_host\":\"algo-2\",\"framework_module\":\"sagemaker_tensorflow_container.training:main\",\"hosts\":[\"algo-1\",\"algo-2\"],\"hyperparameters\":{\"model_dir\":\"s3://sagemaker-cn-north-1-876820548815/tensorflow-training-2020-12-30-09-02-39-680/model\"},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":false,\"job_name\":\"tensorflow-training-2020-12-30-09-02-39-680\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-cn-north-1-876820548815/tensorflow-training-2020-12-30-09-02-39-680/source/sourcedir.tar.gz\",\"module_name\":\"mnist-2\",\"network_interface_name\":\"eth0\",\"num_cpus\":8,\"num_gpus\":1,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-2\",\"hosts\":[\"algo-1\",\"algo-2\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"mnist-2.py\"}\u001b[0m\n",
      "\u001b[35mSM_USER_ARGS=[\"--model_dir\",\"s3://sagemaker-cn-north-1-876820548815/tensorflow-training-2020-12-30-09-02-39-680/model\"]\u001b[0m\n",
      "\u001b[35mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[35mSM_CHANNEL_TRAINING=/opt/ml/input/data/training\u001b[0m\n",
      "\u001b[35mSM_HP_MODEL_DIR=s3://sagemaker-cn-north-1-876820548815/tensorflow-training-2020-12-30-09-02-39-680/model\u001b[0m\n",
      "\u001b[35mTF_CONFIG={\"cluster\": {\"master\": [\"algo-1:2222\"], \"ps\": [\"algo-1:2223\", \"algo-2:2223\"], \"worker\": [\"algo-2:2222\"]}, \"environment\": \"cloud\", \"task\": {\"index\": 0, \"type\": \"worker\"}}\u001b[0m\n",
      "\u001b[35mPYTHONPATH=/opt/ml/code:/usr/local/bin:/usr/local/lib/python37.zip:/usr/local/lib/python3.7:/usr/local/lib/python3.7/lib-dynload:/usr/local/lib/python3.7/site-packages\n",
      "\u001b[0m\n",
      "\u001b[35mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[35m/usr/local/bin/python3.7 mnist-2.py --model_dir s3://sagemaker-cn-north-1-876820548815/tensorflow-training-2020-12-30-09-02-39-680/model\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34m2020-12-30 09:08:00.210039: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.2\u001b[0m\n",
      "\u001b[34m2020-12-30 09:08:03,341 sagemaker-training-toolkit INFO     Imported framework sagemaker_tensorflow_container.training\u001b[0m\n",
      "\u001b[34m2020-12-30 09:08:03,630 sagemaker_tensorflow_container.training INFO     Running distributed training job with parameter servers\u001b[0m\n",
      "\u001b[34m2020-12-30 09:08:03,630 sagemaker_tensorflow_container.training INFO     Launching parameter server process\u001b[0m\n",
      "\u001b[34m2020-12-30 09:08:03,630 sagemaker_tensorflow_container.training INFO     Running distributed training job with parameter servers\u001b[0m\n",
      "\u001b[34m2020-12-30 09:08:03.669485: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2300050000 Hz\u001b[0m\n",
      "\u001b[34m2020-12-30 09:08:03.670083: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55eae1e19a90 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\u001b[0m\n",
      "\u001b[34m2020-12-30 09:08:03.670124: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\u001b[0m\n",
      "\u001b[34m2020-12-30 09:08:03.674253: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1\u001b[0m\n",
      "\u001b[34m2020-12-30 09:08:03.856819: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:\u001b[0m\n",
      "\u001b[34m2020-12-30 09:08:03.856858: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      \u001b[0m\n",
      "\u001b[34m2020-12-30 09:08:03.873626: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:301] Initialize GrpcChannelCache for job master -> {0 -> algo-1:2222}\u001b[0m\n",
      "\u001b[34m2020-12-30 09:08:03.873659: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:301] Initialize GrpcChannelCache for job ps -> {0 -> algo-1:2223, 1 -> algo-2:2223}\u001b[0m\n",
      "\u001b[34m2020-12-30 09:08:03.873669: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:301] Initialize GrpcChannelCache for job worker -> {0 -> algo-2:2222}\u001b[0m\n",
      "\u001b[34m2020-12-30 09:08:03.874301: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:405] Started server with target: grpc://algo-1:2223\u001b[0m\n",
      "\u001b[34m2020-12-30 09:08:03,993 sagemaker_tensorflow_container.training INFO     Launching worker process\u001b[0m\n",
      "\u001b[34m2020-12-30 09:08:04,280 sagemaker-training-toolkit INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[34mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {\n",
      "        \"sagemaker_parameter_server_enabled\": true\n",
      "    },\n",
      "    \"channel_input_dirs\": {\n",
      "        \"training\": \"/opt/ml/input/data/training\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_tensorflow_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\",\n",
      "        \"algo-2\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"model_dir\": \"s3://sagemaker-cn-north-1-876820548815/tensorflow-training-2020-12-30-09-02-39-680/model\"\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"training\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"tensorflow-training-2020-12-30-09-02-39-680\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-cn-north-1-876820548815/tensorflow-training-2020-12-30-09-02-39-680/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"mnist-2\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 8,\n",
      "    \"num_gpus\": 1,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\",\n",
      "            \"algo-2\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"mnist-2.py\"\u001b[0m\n",
      "\u001b[34m}\n",
      "\u001b[0m\n",
      "\u001b[34mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\",\"algo-2\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"model_dir\":\"s3://sagemaker-cn-north-1-876820548815/tensorflow-training-2020-12-30-09-02-39-680/model\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=mnist-2.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={\"sagemaker_parameter_server_enabled\":true}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\",\"algo-2\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"training\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=mnist-2\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_tensorflow_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=8\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=1\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-cn-north-1-876820548815/tensorflow-training-2020-12-30-09-02-39-680/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{\"sagemaker_parameter_server_enabled\":true},\"channel_input_dirs\":{\"training\":\"/opt/ml/input/data/training\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_tensorflow_container.training:main\",\"hosts\":[\"algo-1\",\"algo-2\"],\"hyperparameters\":{\"model_dir\":\"s3://sagemaker-cn-north-1-876820548815/tensorflow-training-2020-12-30-09-02-39-680/model\"},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"tensorflow-training-2020-12-30-09-02-39-680\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-cn-north-1-876820548815/tensorflow-training-2020-12-30-09-02-39-680/source/sourcedir.tar.gz\",\"module_name\":\"mnist-2\",\"network_interface_name\":\"eth0\",\"num_cpus\":8,\"num_gpus\":1,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\",\"algo-2\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"mnist-2.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--model_dir\",\"s3://sagemaker-cn-north-1-876820548815/tensorflow-training-2020-12-30-09-02-39-680/model\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAINING=/opt/ml/input/data/training\u001b[0m\n",
      "\u001b[34mSM_HP_MODEL_DIR=s3://sagemaker-cn-north-1-876820548815/tensorflow-training-2020-12-30-09-02-39-680/model\u001b[0m\n",
      "\u001b[34mTF_CONFIG={\"cluster\": {\"master\": [\"algo-1:2222\"], \"ps\": [\"algo-1:2223\", \"algo-2:2223\"], \"worker\": [\"algo-2:2222\"]}, \"environment\": \"cloud\", \"task\": {\"index\": 0, \"type\": \"master\"}}\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/usr/local/bin:/usr/local/lib/python37.zip:/usr/local/lib/python3.7:/usr/local/lib/python3.7/lib-dynload:/usr/local/lib/python3.7/site-packages\n",
      "\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[34m/usr/local/bin/python3.7 mnist-2.py --model_dir s3://sagemaker-cn-north-1-876820548815/tensorflow-training-2020-12-30-09-02-39-680/model\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[35m#015   1/1719 [..............................] - ETA: 0s - loss: 2.3438 - accuracy: 0.1562#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015  28/1719 [..............................] - ETA: 3s - loss: 1.1172 - accuracy: 0.6875#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015  55/1719 [..............................] - ETA: 3s - loss: 0.8035 - accuracy: 0.7733#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015  83/1719 [>.............................] - ETA: 3s - loss: 0.6966 - accuracy: 0.7986#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015 111/1719 [>.............................] - ETA: 2s - loss: 0.6289 - accuracy: 0.8204#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015 139/1719 [=>............................] - ETA: 2s - loss: 0.5918 - accuracy: 0.8307#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015 167/1719 [=>............................] - ETA: 2s - loss: 0.5443 - accuracy: 0.8432#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015 195/1719 [==>...........................] - ETA: 2s - loss: 0.5138 - accuracy: 0.8526#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015 223/1719 [==>...........................] - ETA: 2s - loss: 0.4852 - accuracy: 0.8593#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015 251/1719 [===>..........................] - ETA: 2s - loss: 0.4674 - accuracy: 0.8639#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015 279/1719 [===>..........................] - ETA: 2s - loss: 0.4584 - accuracy: 0.8656#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015 307/1719 [====>.........................] - ETA: 2s - loss: 0.4428 - accuracy: 0.8696#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015 331/1719 [====>.........................] - ETA: 2s - loss: 0.4313 - accuracy: 0.8732#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015 359/1719 [=====>........................] - ETA: 2s - loss: 0.4156 - accuracy: 0.8781#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015 387/1719 [=====>........................] - ETA: 2s - loss: 0.4025 - accuracy: 0.8819#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015 415/1719 [======>.......................] - ETA: 2s - loss: 0.3930 - accuracy: 0.8843#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015 443/1719 [======>.......................] - ETA: 2s - loss: 0.3844 - accuracy: 0.8872#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015 471/1719 [=======>......................] - ETA: 2s - loss: 0.3740 - accuracy: 0.8897#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015 499/1719 [=======>......................] - ETA: 2s - loss: 0.3677 - accuracy: 0.8912#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015 527/1719 [========>.....................] - ETA: 2s - loss: 0.3618 - accuracy: 0.8931#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015 555/1719 [========>.....................] - ETA: 2s - loss: 0.3560 - accuracy: 0.8942#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015 583/1719 [=========>....................] - ETA: 2s - loss: 0.3519 - accuracy: 0.8954#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015 611/1719 [=========>....................] - ETA: 2s - loss: 0.3472 - accuracy: 0.8971#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015 639/1719 [==========>...................] - ETA: 1s - loss: 0.3399 - accuracy: 0.8992#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015 667/1719 [==========>...................] - ETA: 1s - loss: 0.3336 - accuracy: 0.9010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015 695/1719 [===========>..................] - ETA: 1s - loss: 0.3285 - accuracy: 0.9024#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015 723/1719 [===========>..................] - ETA: 1s - loss: 0.3233 - accuracy: 0.9038#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015 751/1719 [============>.................] - ETA: 1s - loss: 0.3193 - accuracy: 0.9053#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015 778/1719 [============>.................] - ETA: 1s - loss: 0.3145 - accuracy: 0.9064#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015 806/1719 [=============>................] - ETA: 1s - loss: 0.3104 - accuracy: 0.9075#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015 834/1719 [=============>................] - ETA: 1s - loss: 0.3063 - accuracy: 0.9088#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015 862/1719 [==============>...............] - ETA: 1s - loss: 0.3028 - accuracy: 0.9098#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015 889/1719 [==============>...............] - ETA: 1s - loss: 0.2995 - accuracy: 0.9108#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015 917/1719 [===============>..............] - ETA: 1s - loss: 0.2960 - accuracy: 0.9119#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015 945/1719 [===============>..............] - ETA: 1s - loss: 0.2933 - accuracy: 0.9128#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015 973/1719 [===============>..............] - ETA: 1s - loss: 0.2902 - accuracy: 0.9135#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0151001/1719 [================>.............] - ETA: 1s - loss: 0.2865 - accuracy: 0.9146#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0151029/1719 [================>.............] - ETA: 1s - loss: 0.2835 - accuracy: 0.9158#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0151057/1719 [=================>............] - ETA: 1s - loss: 0.2806 - accuracy: 0.9166#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0151085/1719 [=================>............] - ETA: 1s - loss: 0.2775 - accuracy: 0.9175#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0151112/1719 [==================>...........] - ETA: 1s - loss: 0.2747 - accuracy: 0.9183#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0151140/1719 [==================>...........] - ETA: 1s - loss: 0.2722 - accuracy: 0.9192#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0151168/1719 [===================>..........] - ETA: 1s - loss: 0.2697 - accuracy: 0.9201#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0151196/1719 [===================>..........] - ETA: 0s - loss: 0.2669 - accuracy: 0.9209#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0151224/1719 [====================>.........] - ETA: 0s - loss: 0.2643 - accuracy: 0.9216#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0151252/1719 [====================>.........] - ETA: 0s - loss: 0.2620 - accuracy: 0.9224#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0151280/1719 [=====================>........] - ETA: 0s - loss: 0.2596 - accuracy: 0.9230#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0151308/1719 [=====================>........] - ETA: 0s - loss: 0.2571 - accuracy: 0.9235#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0151336/1719 [======================>.......] - ETA: 0s - loss: 0.2549 - accuracy: 0.9242#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0151363/1719 [======================>.......] - ETA: 0s - loss: 0.2534 - accuracy: 0.9246#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0151388/1719 [=======================>......] - ETA: 0s - loss: 0.2525 - accuracy: 0.9247#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0151415/1719 [=======================>......] - ETA: 0s - loss: 0.2508 - accuracy: 0.9253#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0151441/1719 [========================>.....] - ETA: 0s - loss: 0.2492 - accuracy: 0.9257#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0151469/1719 [========================>.....] - ETA: 0s - loss: 0.2478 - accuracy: 0.9261#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0151497/1719 [=========================>....] - ETA: 0s - loss: 0.2458 - accuracy: 0.9267#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0151525/1719 [=========================>....] - ETA: 0s - loss: 0.2439 - accuracy: 0.9272#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0151553/1719 [==========================>...] - ETA: 0s - loss: 0.2422 - accuracy: 0.9275#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0151579/1719 [==========================>...] - ETA: 0s - loss: 0.2409 - accuracy: 0.9280#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0151607/1719 [===========================>..] - ETA: 0s - loss: 0.2390 - accuracy: 0.9286#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0151635/1719 [===========================>..] - ETA: 0s - loss: 0.2368 - accuracy: 0.9292#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0151663/1719 [============================>.] - ETA: 0s - loss: 0.2349 - accuracy: 0.9298#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0151690/1719 [============================>.] - ETA: 0s - loss: 0.2337 - accuracy: 0.9303#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0151718/1719 [============================>.] - ETA: 0s - loss: 0.2324 - accuracy: 0.9307#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0151719/1719 [==============================] - 3s 2ms/step - loss: 0.2323 - accuracy: 0.9307\u001b[0m\n",
      "\u001b[35m#015  1/313 [..............................] - ETA: 0s - loss: 0.0200 - accuracy: 1.0000#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015 33/313 [==>...........................] - ETA: 0s - loss: 0.1214 - accuracy: 0.9602#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015 65/313 [=====>........................] - ETA: 0s - loss: 0.1540 - accuracy: 0.9553#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015 97/313 [========>.....................] - ETA: 0s - loss: 0.1544 - accuracy: 0.9530#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015129/313 [===========>..................] - ETA: 0s - loss: 0.1589 - accuracy: 0.9506#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015162/313 [==============>...............] - ETA: 0s - loss: 0.1544 - accuracy: 0.9514#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015192/313 [=================>............] - ETA: 0s - loss: 0.1453 - accuracy: 0.9546#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015225/313 [====================>.........] - ETA: 0s - loss: 0.1351 - accuracy: 0.9579#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015257/313 [=======================>......] - ETA: 0s - loss: 0.1281 - accuracy: 0.9599#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015289/313 [==========================>...] - ETA: 0s - loss: 0.1180 - accuracy: 0.9629#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015313/313 [==============================] - 0s 2ms/step - loss: 0.1207 - accuracy: 0.9620\u001b[0m\n",
      "\u001b[35m2020-12-30 09:08:11,780 sagemaker_tensorflow_container.training INFO     master algo-1 is down, stopping parameter server\u001b[0m\n",
      "\u001b[35m2020-12-30 09:08:11,781 sagemaker_tensorflow_container.training WARNING  No model artifact is saved under path /opt/ml/model. Your training job will not save any model files to S3.\u001b[0m\n",
      "\u001b[35mFor details of how to construct your training script see:\u001b[0m\n",
      "\u001b[35mhttps://sagemaker.readthedocs.io/en/stable/using_tf.html#adapting-your-local-tensorflow-script\u001b[0m\n",
      "\u001b[35m2020-12-30 09:08:11,781 sagemaker-training-toolkit INFO     Reporting training SUCCESS\u001b[0m\n",
      "\u001b[34m#015   1/1719 [..............................] - ETA: 0s - loss: 2.4173 - accuracy: 0.0312#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015  29/1719 [..............................] - ETA: 3s - loss: 1.1504 - accuracy: 0.6509#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015  57/1719 [..............................] - ETA: 2s - loss: 0.8565 - accuracy: 0.7484#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015  85/1719 [>.............................] - ETA: 2s - loss: 0.7171 - accuracy: 0.7893#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015 114/1719 [>.............................] - ETA: 2s - loss: 0.6212 - accuracy: 0.8177#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015 142/1719 [=>............................] - ETA: 2s - loss: 0.5705 - accuracy: 0.8314#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015 170/1719 [=>............................] - ETA: 2s - loss: 0.5436 - accuracy: 0.8388#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015 198/1719 [==>...........................] - ETA: 2s - loss: 0.5234 - accuracy: 0.8458#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015 226/1719 [==>...........................] - ETA: 2s - loss: 0.4954 - accuracy: 0.8534#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015 254/1719 [===>..........................] - ETA: 2s - loss: 0.4740 - accuracy: 0.8604#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015 283/1719 [===>..........................] - ETA: 2s - loss: 0.4629 - accuracy: 0.8650#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015 312/1719 [====>.........................] - ETA: 2s - loss: 0.4437 - accuracy: 0.8706#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015 339/1719 [====>.........................] - ETA: 2s - loss: 0.4316 - accuracy: 0.8740#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015 367/1719 [=====>........................] - ETA: 2s - loss: 0.4188 - accuracy: 0.8781#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015 396/1719 [=====>........................] - ETA: 2s - loss: 0.4049 - accuracy: 0.8819#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015 424/1719 [======>.......................] - ETA: 2s - loss: 0.3937 - accuracy: 0.8847#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015 452/1719 [======>.......................] - ETA: 2s - loss: 0.3853 - accuracy: 0.8866#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015 480/1719 [=======>......................] - ETA: 2s - loss: 0.3789 - accuracy: 0.8878#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015 509/1719 [=======>......................] - ETA: 2s - loss: 0.3719 - accuracy: 0.8897#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015 537/1719 [========>.....................] - ETA: 2s - loss: 0.3682 - accuracy: 0.8910#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015 566/1719 [========>.....................] - ETA: 2s - loss: 0.3611 - accuracy: 0.8928#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015 594/1719 [=========>....................] - ETA: 2s - loss: 0.3532 - accuracy: 0.8950#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015 622/1719 [=========>....................] - ETA: 1s - loss: 0.3497 - accuracy: 0.8964#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015 651/1719 [==========>...................] - ETA: 1s - loss: 0.3428 - accuracy: 0.8984#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015 679/1719 [==========>...................] - ETA: 1s - loss: 0.3372 - accuracy: 0.8999#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015 707/1719 [===========>..................] - ETA: 1s - loss: 0.3308 - accuracy: 0.9018#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015 735/1719 [===========>..................] - ETA: 1s - loss: 0.3237 - accuracy: 0.9037#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015 763/1719 [============>.................] - ETA: 1s - loss: 0.3193 - accuracy: 0.9051#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015 791/1719 [============>.................] - ETA: 1s - loss: 0.3158 - accuracy: 0.9061#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015 819/1719 [=============>................] - ETA: 1s - loss: 0.3140 - accuracy: 0.9067#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015 847/1719 [=============>................] - ETA: 1s - loss: 0.3093 - accuracy: 0.9080#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015 875/1719 [==============>...............] - ETA: 1s - loss: 0.3048 - accuracy: 0.9094#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015 902/1719 [==============>...............] - ETA: 1s - loss: 0.3002 - accuracy: 0.9108#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015 930/1719 [===============>..............] - ETA: 1s - loss: 0.2963 - accuracy: 0.9117#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015 958/1719 [===============>..............] - ETA: 1s - loss: 0.2935 - accuracy: 0.9125#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015 986/1719 [================>.............] - ETA: 1s - loss: 0.2906 - accuracy: 0.9135#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0151014/1719 [================>.............] - ETA: 1s - loss: 0.2876 - accuracy: 0.9144#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0151042/1719 [=================>............] - ETA: 1s - loss: 0.2853 - accuracy: 0.9151#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0151070/1719 [=================>............] - ETA: 1s - loss: 0.2827 - accuracy: 0.9156#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0151098/1719 [==================>...........] - ETA: 1s - loss: 0.2794 - accuracy: 0.9164#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0151126/1719 [==================>...........] - ETA: 1s - loss: 0.2772 - accuracy: 0.9169#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0151155/1719 [===================>..........] - ETA: 1s - loss: 0.2750 - accuracy: 0.9174#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0151183/1719 [===================>..........] - ETA: 0s - loss: 0.2721 - accuracy: 0.9182#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0151211/1719 [====================>.........] - ETA: 0s - loss: 0.2691 - accuracy: 0.9192#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0151239/1719 [====================>.........] - ETA: 0s - loss: 0.2670 - accuracy: 0.9198#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0151267/1719 [=====================>........] - ETA: 0s - loss: 0.2644 - accuracy: 0.9206#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0151295/1719 [=====================>........] - ETA: 0s - loss: 0.2620 - accuracy: 0.9212#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0151323/1719 [======================>.......] - ETA: 0s - loss: 0.2596 - accuracy: 0.9220#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0151351/1719 [======================>.......] - ETA: 0s - loss: 0.2573 - accuracy: 0.9226#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0151379/1719 [=======================>......] - ETA: 0s - loss: 0.2550 - accuracy: 0.9232#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0151407/1719 [=======================>......] - ETA: 0s - loss: 0.2529 - accuracy: 0.9240#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0151435/1719 [========================>.....] - ETA: 0s - loss: 0.2506 - accuracy: 0.9246#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0151462/1719 [========================>.....] - ETA: 0s - loss: 0.2482 - accuracy: 0.9255#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0151490/1719 [=========================>....] - ETA: 0s - loss: 0.2463 - accuracy: 0.9260#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0151518/1719 [=========================>....] - ETA: 0s - loss: 0.2448 - accuracy: 0.9264#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0151547/1719 [=========================>....] - ETA: 0s - loss: 0.2427 - accuracy: 0.9269#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0151576/1719 [==========================>...] - ETA: 0s - loss: 0.2413 - accuracy: 0.9274#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0151605/1719 [===========================>..] - ETA: 0s - loss: 0.2391 - accuracy: 0.9280#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0151633/1719 [===========================>..] - ETA: 0s - loss: 0.2382 - accuracy: 0.9284#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0151662/1719 [============================>.] - ETA: 0s - loss: 0.2367 - accuracy: 0.9289#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0151691/1719 [============================>.] - ETA: 0s - loss: 0.2350 - accuracy: 0.9294#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0151719/1719 [==============================] - ETA: 0s - loss: 0.2337 - accuracy: 0.9298#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0151719/1719 [==============================] - 3s 2ms/step - loss: 0.2337 - accuracy: 0.9298\u001b[0m\n",
      "\u001b[34m#015  1/313 [..............................] - ETA: 0s - loss: 0.0478 - accuracy: 0.9688#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015 33/313 [==>...........................] - ETA: 0s - loss: 0.1198 - accuracy: 0.9659#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015 66/313 [=====>........................] - ETA: 0s - loss: 0.1562 - accuracy: 0.9541#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015 99/313 [========>.....................] - ETA: 0s - loss: 0.1520 - accuracy: 0.9549#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015132/313 [===========>..................] - ETA: 0s - loss: 0.1543 - accuracy: 0.9534#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015165/313 [==============>...............] - ETA: 0s - loss: 0.1466 - accuracy: 0.9551#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015198/313 [=================>............] - ETA: 0s - loss: 0.1415 - accuracy: 0.9564#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015231/313 [=====================>........] - ETA: 0s - loss: 0.1283 - accuracy: 0.9609#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015262/313 [========================>.....] - ETA: 0s - loss: 0.1182 - accuracy: 0.9640#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015295/313 [===========================>..] - ETA: 0s - loss: 0.1088 - accuracy: 0.9667#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015313/313 [==============================] - 0s 2ms/step - loss: 0.1115 - accuracy: 0.9659\u001b[0m\n",
      "\u001b[34m2020-12-30 09:08:15,564 sagemaker-training-toolkit INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2020-12-30 09:08:27 Uploading - Uploading generated training model\n",
      "2020-12-30 09:08:27 Completed - Training job completed\n",
      "Training seconds: 254\n",
      "Billable seconds: 254\n"
     ]
    }
   ],
   "source": [
    "mnist_estimator2.fit(training_data_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploy the trained model to an endpoint\n",
    "\n",
    "The `deploy()` method creates a SageMaker model, which is then deployed to an endpoint to serve prediction requests in real time. We will use the TensorFlow Serving container for the endpoint, because we trained with script mode. This serving container runs an implementation of a web server that is compatible with SageMaker hosting protocol. The [Using your own inference code]() document explains how SageMaker runs inference containers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "update_endpoint is a no-op in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------!"
     ]
    }
   ],
   "source": [
    "predictor = mnist_estimator.deploy(initial_instance_count=1, instance_type='ml.p3.8xlarge')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deployed the trained TensorFlow 2.3.0 model to an endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "update_endpoint is a no-op in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------!"
     ]
    }
   ],
   "source": [
    "predictor2 = mnist_estimator2.deploy(initial_instance_count=1, instance_type='ml.p3.8xlarge')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Invoke the endpoint\n",
    "\n",
    "Let's download the training data and use that as input for inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://sagemaker-sample-data-cn-north-1/tensorflow/mnist/train_data.npy to ./train_data.npy\n",
      "download: s3://sagemaker-sample-data-cn-north-1/tensorflow/mnist/train_labels.npy to ./train_labels.npy\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "!aws --region {region} s3 cp s3://sagemaker-sample-data-{region}/tensorflow/mnist/train_data.npy train_data.npy\n",
    "!aws --region {region} s3 cp s3://sagemaker-sample-data-{region}/tensorflow/mnist/train_labels.npy train_labels.npy\n",
    "\n",
    "train_data = np.load('train_data.npy')\n",
    "train_labels = np.load('train_labels.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The formats of the input and the output data correspond directly to the request and response formats of the `Predict` method in the [TensorFlow Serving REST API](https://www.tensorflow.org/serving/api_rest). SageMaker's TensforFlow Serving endpoints can also accept additional input formats that are not part of the TensorFlow REST API, including the simplified JSON format, line-delimited JSON objects (\"jsons\" or \"jsonlines\"), and CSV data.\n",
    "\n",
    "In this example we are using a `numpy` array as input, which will be serialized into the simplified JSON format. In addtion, TensorFlow serving can also process multiple items at once as you can see in the following code. You can find the complete documentation on how to make predictions against a TensorFlow serving SageMaker endpoint [here](https://github.com/aws/sagemaker-python-sdk/blob/master/src/sagemaker/tensorflow/deploying_tensorflow_serving.rst#making-predictions-against-a-sagemaker-endpoint)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction is 7, label is 7, matched: True\n",
      "prediction is 3, label is 3, matched: True\n",
      "prediction is 4, label is 4, matched: True\n",
      "prediction is 6, label is 6, matched: True\n",
      "prediction is 1, label is 1, matched: True\n",
      "prediction is 8, label is 8, matched: True\n",
      "prediction is 1, label is 1, matched: True\n",
      "prediction is 0, label is 0, matched: True\n",
      "prediction is 9, label is 9, matched: True\n",
      "prediction is 8, label is 8, matched: True\n",
      "prediction is 0, label is 0, matched: True\n",
      "prediction is 3, label is 3, matched: True\n",
      "prediction is 1, label is 1, matched: True\n",
      "prediction is 5, label is 2, matched: False\n",
      "prediction is 7, label is 7, matched: True\n",
      "prediction is 0, label is 0, matched: True\n",
      "prediction is 2, label is 2, matched: True\n",
      "prediction is 9, label is 9, matched: True\n",
      "prediction is 6, label is 6, matched: True\n",
      "prediction is 0, label is 0, matched: True\n",
      "prediction is 1, label is 1, matched: True\n",
      "prediction is 6, label is 6, matched: True\n",
      "prediction is 7, label is 7, matched: True\n",
      "prediction is 1, label is 1, matched: True\n",
      "prediction is 9, label is 9, matched: True\n",
      "prediction is 7, label is 7, matched: True\n",
      "prediction is 6, label is 6, matched: True\n",
      "prediction is 5, label is 5, matched: True\n",
      "prediction is 5, label is 5, matched: True\n",
      "prediction is 8, label is 8, matched: True\n",
      "prediction is 8, label is 8, matched: True\n",
      "prediction is 3, label is 3, matched: True\n",
      "prediction is 4, label is 4, matched: True\n",
      "prediction is 4, label is 4, matched: True\n",
      "prediction is 8, label is 8, matched: True\n",
      "prediction is 7, label is 7, matched: True\n",
      "prediction is 3, label is 3, matched: True\n",
      "prediction is 6, label is 6, matched: True\n",
      "prediction is 4, label is 4, matched: True\n",
      "prediction is 6, label is 6, matched: True\n",
      "prediction is 6, label is 6, matched: True\n",
      "prediction is 3, label is 3, matched: True\n",
      "prediction is 1, label is 8, matched: False\n",
      "prediction is 8, label is 8, matched: True\n",
      "prediction is 9, label is 9, matched: True\n",
      "prediction is 9, label is 9, matched: True\n",
      "prediction is 4, label is 4, matched: True\n",
      "prediction is 4, label is 4, matched: True\n",
      "prediction is 0, label is 0, matched: True\n",
      "prediction is 7, label is 7, matched: True\n"
     ]
    }
   ],
   "source": [
    "predictions = predictor.predict(train_data[:50])\n",
    "for i in range(0, 50):\n",
    "    prediction = predictions['predictions'][i]['classes']\n",
    "    label = train_labels[i]\n",
    "    print('prediction is {}, label is {}, matched: {}'.format(prediction, label, prediction == label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examine the prediction result from the TensorFlow 2.3.0 model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction is 7, label is 7, matched: True\n",
      "prediction is 3, label is 3, matched: True\n",
      "prediction is 4, label is 4, matched: True\n",
      "prediction is 6, label is 6, matched: True\n",
      "prediction is 1, label is 1, matched: True\n",
      "prediction is 8, label is 8, matched: True\n",
      "prediction is 1, label is 1, matched: True\n",
      "prediction is 0, label is 0, matched: True\n",
      "prediction is 9, label is 9, matched: True\n",
      "prediction is 8, label is 8, matched: True\n",
      "prediction is 0, label is 0, matched: True\n",
      "prediction is 3, label is 3, matched: True\n",
      "prediction is 1, label is 1, matched: True\n",
      "prediction is 3, label is 2, matched: False\n",
      "prediction is 7, label is 7, matched: True\n",
      "prediction is 0, label is 0, matched: True\n",
      "prediction is 2, label is 2, matched: True\n",
      "prediction is 9, label is 9, matched: True\n",
      "prediction is 6, label is 6, matched: True\n",
      "prediction is 0, label is 0, matched: True\n",
      "prediction is 1, label is 1, matched: True\n",
      "prediction is 6, label is 6, matched: True\n",
      "prediction is 7, label is 7, matched: True\n",
      "prediction is 1, label is 1, matched: True\n",
      "prediction is 9, label is 9, matched: True\n",
      "prediction is 7, label is 7, matched: True\n",
      "prediction is 6, label is 6, matched: True\n",
      "prediction is 5, label is 5, matched: True\n",
      "prediction is 5, label is 5, matched: True\n",
      "prediction is 8, label is 8, matched: True\n",
      "prediction is 8, label is 8, matched: True\n",
      "prediction is 3, label is 3, matched: True\n",
      "prediction is 4, label is 4, matched: True\n",
      "prediction is 4, label is 4, matched: True\n",
      "prediction is 8, label is 8, matched: True\n",
      "prediction is 7, label is 7, matched: True\n",
      "prediction is 3, label is 3, matched: True\n",
      "prediction is 6, label is 6, matched: True\n",
      "prediction is 4, label is 4, matched: True\n",
      "prediction is 6, label is 6, matched: True\n",
      "prediction is 6, label is 6, matched: True\n",
      "prediction is 3, label is 3, matched: True\n",
      "prediction is 6, label is 8, matched: False\n",
      "prediction is 8, label is 8, matched: True\n",
      "prediction is 9, label is 9, matched: True\n",
      "prediction is 9, label is 9, matched: True\n",
      "prediction is 4, label is 4, matched: True\n",
      "prediction is 4, label is 4, matched: True\n",
      "prediction is 0, label is 0, matched: True\n",
      "prediction is 7, label is 7, matched: True\n"
     ]
    }
   ],
   "source": [
    "predictions2 = predictor2.predict(train_data[:50])\n",
    "for i in range(0, 50):\n",
    "    prediction = np.argmax(predictions2['predictions'][i])\n",
    "    label = train_labels[i]\n",
    "    print('prediction is {}, label is {}, matched: {}'.format(prediction, label, prediction == label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Delete the endpoint\n",
    "\n",
    "Let's delete the endpoint we just created to prevent incurring any extra costs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The endpoint attribute has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n"
     ]
    }
   ],
   "source": [
    "sagemaker.Session().delete_endpoint(predictor.endpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Delete the TensorFlow 2.3.0 endpoint as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The endpoint attribute has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n"
     ]
    }
   ],
   "source": [
    "sagemaker.Session().delete_endpoint(predictor2.endpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow2_p36",
   "language": "python",
   "name": "conda_tensorflow2_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "notice": "Copyright 2017 Amazon.com, Inc. or its affiliates. All Rights Reserved.  Licensed under the Apache License, Version 2.0 (the \"License\"). You may not use this file except in compliance with the License. A copy of the License is located at http://aws.amazon.com/apache2.0/ or in the \"license\" file accompanying this file. This file is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
