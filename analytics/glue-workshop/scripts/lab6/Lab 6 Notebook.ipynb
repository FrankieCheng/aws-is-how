{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08b5add0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Spark application\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>User</th><th>Current session?</th></tr><tr><td>8</td><td>application_1623861101193_0009</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-172-32-26-31.us-east-2.compute.internal:20888/proxy/application_1623861101193_0009/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-172-32-8-64.us-east-2.compute.internal:8042/node/containerlogs/container_1623861101193_0009_01_000001/livy\">Link</a></td><td>None</td><td>✔</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession available as 'spark'.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sys\n",
    "from awsglue.transforms import *\n",
    "from awsglue.utils import getResolvedOptions\n",
    "from pyspark.context import SparkContext\n",
    "from awsglue.context import GlueContext\n",
    "from awsglue.job import Job\n",
    "from awsglue.dynamicframe import DynamicFrameCollection\n",
    "from awsglue.dynamicframe import DynamicFrame\n",
    "\n",
    "glueContext = GlueContext(SparkContext.getOrCreate())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "24fa1996",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- date: string (nullable = true)\n",
      " |-- state: string (nullable = true)\n",
      " |-- positiveIncrease: double (nullable = true)\n",
      " |-- totalTestResultsIncrease: double (nullable = true)\n",
      "\n",
      "+--------+-----+----------------+------------------------+\n",
      "|    date|state|positiveIncrease|totalTestResultsIncrease|\n",
      "+--------+-----+----------------+------------------------+\n",
      "|20210307|   AK|             0.0|                     0.0|\n",
      "|20210307|   AL|           408.0|                  2347.0|\n",
      "|20210307|   AR|           165.0|                  3380.0|\n",
      "|20210307|   AS|             0.0|                     0.0|\n",
      "|20210307|   AZ|          1335.0|                 45110.0|\n",
      "|20210307|   CA|          3816.0|                133186.0|\n",
      "|20210307|   CO|           840.0|                 38163.0|\n",
      "|20210307|   CT|             0.0|                     0.0|\n",
      "|20210307|   DC|           146.0|                  5726.0|\n",
      "|20210307|   DE|           215.0|                  5867.0|\n",
      "+--------+-----+----------------+------------------------+\n",
      "only showing top 10 rows"
     ]
    }
   ],
   "source": [
    "DataSource0 = glueContext.create_dynamic_frame.from_options(\n",
    "    format_options = {\"jsonPath\":\"\",\"multiline\":False}, \n",
    "    connection_type = \"s3\", \n",
    "    format = \"json\", \n",
    "    connection_options = {\"paths\": [\"s3://glueworkshop-ray-us-east-2/output/lab6/custom/temp1/\"], \"recurse\":True}, \n",
    "    transformation_ctx = \"DataSource0\")\n",
    "\n",
    "sparkDF = DataSource0.toDF()\n",
    "sparkDF.createOrReplaceTempView(\"inputTable\")\n",
    "sparkDF.printSchema()\n",
    "sparkDF.show(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ae1eb78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- date: date (nullable = true)\n",
      " |-- state: string (nullable = true)\n",
      " |-- positiveIncrease: double (nullable = true)\n",
      " |-- totalTestResultsIncrease: double (nullable = true)\n",
      "\n",
      "+----------+-----+----------------+------------------------+\n",
      "|      date|state|positiveIncrease|totalTestResultsIncrease|\n",
      "+----------+-----+----------------+------------------------+\n",
      "|2021-03-07|   AK|             0.0|                     0.0|\n",
      "|2021-03-07|   AL|           408.0|                  2347.0|\n",
      "|2021-03-07|   AR|           165.0|                  3380.0|\n",
      "|2021-03-07|   AS|             0.0|                     0.0|\n",
      "|2021-03-07|   AZ|          1335.0|                 45110.0|\n",
      "|2021-03-07|   CA|          3816.0|                133186.0|\n",
      "|2021-03-07|   CO|           840.0|                 38163.0|\n",
      "|2021-03-07|   CT|             0.0|                     0.0|\n",
      "|2021-03-07|   DC|           146.0|                  5726.0|\n",
      "|2021-03-07|   DE|           215.0|                  5867.0|\n",
      "+----------+-----+----------------+------------------------+\n",
      "only showing top 10 rows"
     ]
    }
   ],
   "source": [
    "df = spark.sql(\"select TO_DATE(CAST(UNIX_TIMESTAMP(date, 'yyyyMMdd') AS TIMESTAMP)) as date, \\\n",
    "                       state , \\\n",
    "                       positiveIncrease ,  \\\n",
    "                       totalTestResultsIncrease \\\n",
    "                from   inputTable\")\n",
    "df.printSchema()\n",
    "df.show(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "76a6e494",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- date: date (nullable = true)\n",
      " |-- state: string (nullable = true)\n",
      " |-- positiveIncrease: double (nullable = true)\n",
      " |-- totalTestResultsIncrease: double (nullable = true)\n",
      "\n",
      "+----------+-----+----------------+------------------------+\n",
      "|      date|state|positiveIncrease|totalTestResultsIncrease|\n",
      "+----------+-----+----------------+------------------------+\n",
      "|2021-03-07|   AK|             0.0|                     0.0|\n",
      "|2021-03-07|   AL|           408.0|                  2347.0|\n",
      "|2021-03-07|   AR|           165.0|                  3380.0|\n",
      "|2021-03-07|   AS|             0.0|                     0.0|\n",
      "|2021-03-07|   AZ|          1335.0|                 45110.0|\n",
      "|2021-03-07|   CA|          3816.0|                133186.0|\n",
      "|2021-03-07|   CO|           840.0|                 38163.0|\n",
      "|2021-03-07|   CT|             0.0|                     0.0|\n",
      "|2021-03-07|   DC|           146.0|                  5726.0|\n",
      "|2021-03-07|   DE|           215.0|                  5867.0|\n",
      "+----------+-----+----------------+------------------------+\n",
      "only showing top 10 rows"
     ]
    }
   ],
   "source": [
    "def ConvertDateStringToDate (glueContext, dfc) -> DynamicFrameCollection:\n",
    "    sparkDF = dfc.select(list(dfc.keys())[0]).toDF()\n",
    "    sparkDF.createOrReplaceTempView(\"inputTable\")\n",
    "\n",
    "    df = spark.sql(\"select TO_DATE(CAST(UNIX_TIMESTAMP(date, 'yyyyMMdd') AS TIMESTAMP)) as date, \\\n",
    "                           state , \\\n",
    "                           positiveIncrease ,  \\\n",
    "                           totalTestResultsIncrease \\\n",
    "                    from   inputTable\")\n",
    "\n",
    "    dyf = DynamicFrame.fromDF(df, glueContext, \"results\")\n",
    "    return DynamicFrameCollection({\"CustomTransform0\": dyf}, glueContext)\n",
    "\n",
    "Transform = ConvertDateStringToDate(glueContext, DynamicFrameCollection({\"DataSource0\": DataSource0}, glueContext))\n",
    "resultDF = Transform.select(list(Transform.keys())[0]).toDF()\n",
    "resultDF.printSchema()\n",
    "resultDF.show(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d11d9106",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- date: date (nullable = true)\n",
      " |-- state: string (nullable = true)\n",
      " |-- positivePercentage: double (nullable = true)\n",
      "\n",
      "+----------+-----+------------------+\n",
      "|      date|state|positivePercentage|\n",
      "+----------+-----+------------------+\n",
      "|2021-03-07|   CA|2.8651660084393256|\n",
      "|2021-03-07|   NY|  2.98066453584349|\n",
      "|2021-03-06|   CA| 2.039161800068705|\n",
      "|2021-03-06|   NY| 2.799745178155617|\n",
      "|2021-03-05|   CA|  3.17331662330232|\n",
      "|2021-03-05|   NY|3.0161483152878574|\n",
      "|2021-03-04|   CA| 2.928859800897716|\n",
      "|2021-03-04|   NY|2.8112955359159386|\n",
      "|2021-03-03|   CA| 2.561555273655413|\n",
      "|2021-03-03|   NY|  3.53282676584017|\n",
      "+----------+-----+------------------+\n",
      "only showing top 10 rows"
     ]
    }
   ],
   "source": [
    "def FilterAndCalculatePercentage (glueContext, dfc) -> DynamicFrameCollection:\n",
    "    sparkDF = dfc.select(list(dfc.keys())[0]).toDF()\n",
    "    sparkDF.createOrReplaceTempView(\"inputTable\")\n",
    "\n",
    "    df = spark.sql(\"select  date , \\\n",
    "                            state , \\\n",
    "                            (positiveIncrease * 100 / totalTestResultsIncrease) as positivePercentage \\\n",
    "                    from inputTable \\\n",
    "                    where state in ('NY', 'CA')\")\n",
    "\n",
    "    dyf = DynamicFrame.fromDF(df, glueContext, \"results\")\n",
    "    return DynamicFrameCollection({\"CustomTransform0\": dyf}, glueContext)\n",
    "\n",
    "TransformFilter = FilterAndCalculatePercentage(glueContext, Transform)\n",
    "resultDF = TransformFilter.select(list(TransformFilter.keys())[0]).toDF()\n",
    "resultDF.printSchema()\n",
    "resultDF.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4129a92b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- date: date (nullable = true)\n",
      " |-- positivePercentageNY: double (nullable = true)\n",
      " |-- positivePercentageCA: double (nullable = true)\n",
      "\n",
      "+----------+--------------------+--------------------+\n",
      "|      date|positivePercentageNY|positivePercentageCA|\n",
      "+----------+--------------------+--------------------+\n",
      "|2020-08-24|  0.6577356483048798|    4.43762561010623|\n",
      "|2021-01-27|   5.441599518407587|  6.9206328192228765|\n",
      "|2020-08-05|  0.8752132988385534|    5.10671540308814|\n",
      "|2020-07-24|  0.9842236658083574|    7.06393742912802|\n",
      "|2020-11-29|   4.273455377574371|   6.663565481245652|\n",
      "|2020-08-28|  0.6501339112301433|  5.7784476589100215|\n",
      "|2020-08-29|  0.6764458363959818|   5.031668905882234|\n",
      "|2020-04-30|  16.625821346119693|  10.888368321470402|\n",
      "|2020-10-04|  1.1075963708544445|   2.659867781089102|\n",
      "|2020-12-18|   5.091324658660304|  14.406907671716976|\n",
      "+----------+--------------------+--------------------+\n",
      "only showing top 10 rows"
     ]
    }
   ],
   "source": [
    "def PivotValue (glueContext, dfc) -> DynamicFrameCollection:\n",
    "    sparkDF = dfc.select(list(dfc.keys())[0]).toDF()\n",
    "    sparkDF.createOrReplaceTempView(\"inputTable\")\n",
    "\n",
    "    df = spark.sql(\"select * from inputTable \\\n",
    "                    pivot (avg(positivePercentage) as positivePercentage \\\n",
    "                    for state in ('NY' as positivePercentageNY, 'CA' as positivePercentageCA))\")\n",
    "\n",
    "    dyf = DynamicFrame.fromDF(df, glueContext, \"results\")\n",
    "    return DynamicFrameCollection({\"CustomTransform0\": dyf}, glueContext)\n",
    "\n",
    "PivotValueTransform = PivotValue(glueContext, TransformFilter)\n",
    "resultDF = PivotValueTransform.select(list(PivotValueTransform.keys())[0]).toDF()\n",
    "resultDF.printSchema()\n",
    "resultDF.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e6d7151",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Sparkmagic (PySpark)",
   "language": "python",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
