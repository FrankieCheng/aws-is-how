{"paragraphs":[{"text":"In Lake Formation enabled clusters, Spark SQL can only read from data managed by AWS Glue Data Catalog and cannot access data managed outside of AWS Glue or Lake Formation.\nData from other sources can be accessed using non-Spark SQL operations if the IAM role for other AWS Services chosen during cluster deployment has policies in place allowing the cluster to access those data sources\n\nSpark SQL can only read from Lake Formation tables\n\nSo let's see how may databases you have access to, one of them should be tpc as SAML authenticatd user has SELECT permission for two of the tables in tpc database.","user":"emr-developer","dateUpdated":"2020-03-16T22:57:32+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"results":{},"enabled":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1584399452553_-1309282629","id":"20200212-213816_325620074","dateCreated":"2020-03-16T22:57:32+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:81"},{"title":"","text":"spark.sql(\"show databases\").show()","user":"emr-developer","dateUpdated":"2021-01-07T15:35:36+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"title":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1584399452557_2141691468","id":"20200210-201358_1488794384","dateCreated":"2020-03-16T22:57:32+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:82","dateFinished":"2021-01-07T15:36:29+0000","dateStarted":"2021-01-07T15:35:36+0000","results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+------------+\n|databaseName|\n+------------+\n|     default|\n|   glue-demo|\n|         tpc|\n+------------+"},{"type":"HTML","data":"<hr/>Spark Application Id: application_1610030784103_0001<br/>Spark WebUI: <a href=\"http://ip-10-0-0-111.us-west-1.compute.internal:20888/proxy/application_1610030784103_0001/\">http://ip-10-0-0-111.us-west-1.compute.internal:20888/proxy/application_1610030784103_0001/</a>"}]}},{"text":"As we gave SELECT permission to dl_tpc_web_page table under tpc database , let's get the count(*) of rows from the table ","user":"emr-developer","dateUpdated":"2020-03-16T22:57:32+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"results":{},"enabled":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1584399452558_-2085340618","id":"20200212-213947_706265815","dateCreated":"2020-03-16T22:57:32+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:83"},{"text":"spark.sql( \"select count(*) from tpc.dl_tpc_web_page \").show()","user":"emr-developer","dateUpdated":"2021-01-07T15:36:52+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"results":{"0":{"graph":{"mode":"table","height":300,"optionOpen":false,"setting":{"table":{"tableGridState":{},"tableColumnTypeState":{"names":{"count(1)":"string"},"updated":false},"tableOptionSpecHash":"[{\"name\":\"useFilter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable filter for columns\"},{\"name\":\"showPagination\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable pagination for better navigation\"},{\"name\":\"showAggregationFooter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable a footer for displaying aggregated values\"}]","tableOptionValue":{"useFilter":false,"showPagination":false,"showAggregationFooter":false},"updated":false,"initialized":false}},"commonSetting":{}},"helium":{}}},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1584399452558_-1651731267","id":"20200210-202617_1512789887","dateCreated":"2020-03-16T22:57:32+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:84","dateFinished":"2021-01-07T15:37:03+0000","dateStarted":"2021-01-07T15:36:52+0000","results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+--------+\n|count(1)|\n+--------+\n|    3600|\n+--------+"},{"type":"HTML","data":"<hr/>Spark Application Id: application_1610030784103_0001<br/>Spark WebUI: <a href=\"http://ip-10-0-0-111.us-west-1.compute.internal:20888/proxy/application_1610030784103_0001/\">http://ip-10-0-0-111.us-west-1.compute.internal:20888/proxy/application_1610030784103_0001/</a>"}]}},{"text":"spark.sql( \" SELECT sum(ws_net_paid_inc_tax) NetPaid, ws_web_site_sk WebSiteID FROM tpc.dl_tpc_web_sales ws, tpc.dl_tpc_web_page wp WHERE ws.ws_web_site_sk =wp.wp_web_page_sk GROUP BY  ws_web_site_sk \").show()","user":"emr-developer","dateUpdated":"2021-01-07T15:37:42+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"results":{"0":{"graph":{"mode":"table","height":300,"optionOpen":false,"setting":{"table":{"tableGridState":{},"tableColumnTypeState":{"names":{"NetPaid":"string","WebSiteID":"string"},"updated":false},"tableOptionSpecHash":"[{\"name\":\"useFilter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable filter for columns\"},{\"name\":\"showPagination\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable pagination for better navigation\"},{\"name\":\"showAggregationFooter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable a footer for displaying aggregated values\"}]","tableOptionValue":{"useFilter":false,"showPagination":false,"showAggregationFooter":false},"updated":false,"initialized":false}},"commonSetting":{}}}},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1584399452559_-1943858117","id":"20200210-210710_1556991954","dateCreated":"2020-03-16T22:57:32+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:85","dateFinished":"2021-01-07T15:37:49+0000","dateStarted":"2021-01-07T15:37:42+0000","results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+-----------+---------+\n|    NetPaid|WebSiteID|\n+-----------+---------+\n|25270749.33|        1|\n|24409352.92|        2|\n|24823169.90|        4|\n|25445390.34|        7|\n|25811585.40|        8|\n|25024877.60|       10|\n|25046976.36|       13|\n|24986231.12|       14|\n|24518423.73|       16|\n|24924972.15|       19|\n|25781409.47|       20|\n|25448611.17|       22|\n|25611532.61|       25|\n|25421459.92|       26|\n|25727733.44|       28|\n|25516118.29|       31|\n|25978611.48|       32|\n|24996325.31|       34|\n|24764737.96|       37|\n|25709251.40|       38|\n+-----------+---------+\nonly showing top 20 rows"},{"type":"HTML","data":"<hr/>Spark Application Id: application_1610030784103_0001<br/>Spark WebUI: <a href=\"http://ip-10-0-0-111.us-west-1.compute.internal:20888/proxy/application_1610030784103_0001/\">http://ip-10-0-0-111.us-west-1.compute.internal:20888/proxy/application_1610030784103_0001/</a>"}]}},{"text":"Let's select a table for which user does not have SELECT permission and see what happens? You should receive Service: AWSGlue; Status Code: 400; Error Code: AccessDeniedException for the following","user":"emr-developer","dateUpdated":"2020-03-16T22:57:32+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"results":{},"enabled":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1584399452559_-728101276","id":"20200212-214120_529407211","dateCreated":"2020-03-16T22:57:32+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:86"},{"text":"%sql\nSELECT * FROM tpc.dl_tpc_item limit 10","user":"emr-developer","dateUpdated":"2021-01-07T15:37:59+0000","config":{"editorSetting":{"language":"sql","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/sql","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1584399452560_1661709583","id":"20200210-210939_888909168","dateCreated":"2020-03-16T22:57:32+0000","status":"ERROR","progressUpdateIntervalMs":500,"$$hashKey":"object:87","dateFinished":"2021-01-07T15:38:01+0000","dateStarted":"2021-01-07T15:37:59+0000","results":{"code":"ERROR","msg":[{"type":"TEXT","data":"org.apache.spark.sql.catalyst.analysis.AccessControlException: Insufficient Lake Formation permission(s) on dl_tpc_item (Service: AWSGlue; Status Code: 400; Error Code: AccessDeniedException; Request ID: efe2eb2d-16fb-4562-a728-8abf58c7bf63; Proxy: null);\n  at org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:126)\n  at org.apache.spark.sql.hive.HiveExternalCatalog.tableExists(HiveExternalCatalog.scala:848)\n  at org.apache.spark.sql.catalyst.catalog.ExternalCatalogWithListener.tableExists(ExternalCatalogWithListener.scala:142)\n  at org.apache.spark.sql.catalyst.catalog.SessionCatalog.tableExists(SessionCatalog.scala:420)\n  at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.isRunningDirectlyOnFiles(Analyzer.scala:852)\n  at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveRelation(Analyzer.scala:785)\n  at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$8.applyOrElse(Analyzer.scala:817)\n  at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$8.applyOrElse(Analyzer.scala:810)\n  at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveOperatorsUp$1$$anonfun$apply$1.apply(AnalysisHelper.scala:90)\n  at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveOperatorsUp$1$$anonfun$apply$1.apply(AnalysisHelper.scala:90)\n  at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:71)\n  at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveOperatorsUp$1.apply(AnalysisHelper.scala:89)\n  at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveOperatorsUp$1.apply(AnalysisHelper.scala:86)\n  at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:194)\n  at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$class.resolveOperatorsUp(AnalysisHelper.scala:86)\n  at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUp(LogicalPlan.scala:29)\n  at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveOperatorsUp$1$$anonfun$1.apply(AnalysisHelper.scala:87)\n  at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveOperatorsUp$1$$anonfun$1.apply(AnalysisHelper.scala:87)\n  at org.apache.spark.sql.catalyst.trees.TreeNode.org$apache$spark$sql$catalyst$trees$TreeNode$$applyFunctionIfChanged$1(TreeNode.scala:345)\n  at org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$6.apply(TreeNode.scala:381)\n  at org.apache.spark.sql.catalyst.trees.TreeNode.mapProductIterator(TreeNode.scala:213)\n  at org.apache.spark.sql.catalyst.trees.TreeNode.mapChildren(TreeNode.scala:379)\n  at org.apache.spark.sql.catalyst.trees.TreeNode.mapChildren(TreeNode.scala:327)\n  at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveOperatorsUp$1.apply(AnalysisHelper.scala:87)\n  at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveOperatorsUp$1.apply(AnalysisHelper.scala:86)\n  at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:194)\n  at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$class.resolveOperatorsUp(AnalysisHelper.scala:86)\n  at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUp(LogicalPlan.scala:29)\n  at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveOperatorsUp$1$$anonfun$1.apply(AnalysisHelper.scala:87)\n  at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveOperatorsUp$1$$anonfun$1.apply(AnalysisHelper.scala:87)\n  at org.apache.spark.sql.catalyst.trees.TreeNode.org$apache$spark$sql$catalyst$trees$TreeNode$$applyFunctionIfChanged$1(TreeNode.scala:345)\n  at org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$6.apply(TreeNode.scala:381)\n  at org.apache.spark.sql.catalyst.trees.TreeNode.mapProductIterator(TreeNode.scala:213)\n  at org.apache.spark.sql.catalyst.trees.TreeNode.mapChildren(TreeNode.scala:379)\n  at org.apache.spark.sql.catalyst.trees.TreeNode.mapChildren(TreeNode.scala:327)\n  at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveOperatorsUp$1.apply(AnalysisHelper.scala:87)\n  at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveOperatorsUp$1.apply(AnalysisHelper.scala:86)\n  at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:194)\n  at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$class.resolveOperatorsUp(AnalysisHelper.scala:86)\n  at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUp(LogicalPlan.scala:29)\n  at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveOperatorsUp$1$$anonfun$1.apply(AnalysisHelper.scala:87)\n  at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveOperatorsUp$1$$anonfun$1.apply(AnalysisHelper.scala:87)\n  at org.apache.spark.sql.catalyst.trees.TreeNode.org$apache$spark$sql$catalyst$trees$TreeNode$$applyFunctionIfChanged$1(TreeNode.scala:345)\n  at org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$6.apply(TreeNode.scala:381)\n  at org.apache.spark.sql.catalyst.trees.TreeNode.mapProductIterator(TreeNode.scala:213)\n  at org.apache.spark.sql.catalyst.trees.TreeNode.mapChildren(TreeNode.scala:379)\n  at org.apache.spark.sql.catalyst.trees.TreeNode.mapChildren(TreeNode.scala:327)\n  at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveOperatorsUp$1.apply(AnalysisHelper.scala:87)\n  at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveOperatorsUp$1.apply(AnalysisHelper.scala:86)\n  at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:194)\n  at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$class.resolveOperatorsUp(AnalysisHelper.scala:86)\n  at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUp(LogicalPlan.scala:29)\n  at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:810)\n  at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:756)\n  at org.apache.spark.sql.catalyst.rules.RuleExecutor$$anonfun$execute$1$$anonfun$apply$1$$anonfun$2.apply(RuleExecutor.scala:92)\n  at org.apache.spark.sql.catalyst.rules.RuleExecutor$$anonfun$execute$1$$anonfun$apply$1$$anonfun$2.apply(RuleExecutor.scala:92)\n  at org.apache.spark.sql.execution.QueryExecutionMetrics$.withMetrics(QueryExecutionMetrics.scala:141)\n  at org.apache.spark.sql.catalyst.rules.RuleExecutor$$anonfun$execute$1$$anonfun$apply$1.apply(RuleExecutor.scala:91)\n  at org.apache.spark.sql.catalyst.rules.RuleExecutor$$anonfun$execute$1$$anonfun$apply$1.apply(RuleExecutor.scala:88)\n  at scala.collection.LinearSeqOptimized$class.foldLeft(LinearSeqOptimized.scala:124)\n  at scala.collection.immutable.List.foldLeft(List.scala:84)\n  at org.apache.spark.sql.catalyst.rules.RuleExecutor$$anonfun$execute$1.apply(RuleExecutor.scala:88)\n  at org.apache.spark.sql.catalyst.rules.RuleExecutor$$anonfun$execute$1.apply(RuleExecutor.scala:80)\n  at scala.collection.immutable.List.foreach(List.scala:392)\n  at org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:80)\n  at org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:164)\n  at org.apache.spark.sql.catalyst.analysis.Analyzer$$anonfun$execute$1.apply(Analyzer.scala:156)\n  at org.apache.spark.sql.catalyst.analysis.Analyzer$$anonfun$execute$1.apply(Analyzer.scala:156)\n  at org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withLocalMetrics(Analyzer.scala:104)\n  at org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:155)\n  at org.apache.spark.sql.catalyst.analysis.Analyzer$$anonfun$executeAndCheck$1.apply(Analyzer.scala:126)\n  at org.apache.spark.sql.catalyst.analysis.Analyzer$$anonfun$executeAndCheck$1.apply(Analyzer.scala:125)\n  at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:201)\n  at org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:125)\n  at org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:76)\n  at org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)\n  at org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)\n  at org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:79)\n  at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:644)\n  ... 50 elided\nCaused by: org.apache.hadoop.hive.ql.metadata.HiveException: Unable to fetch table dl_tpc_item. Insufficient Lake Formation permission(s) on dl_tpc_item (Service: AWSGlue; Status Code: 400; Error Code: AccessDeniedException; Request ID: efe2eb2d-16fb-4562-a728-8abf58c7bf63; Proxy: null)\n  at org.apache.hadoop.hive.ql.metadata.Hive.getTable(Hive.java:1124)\n  at org.apache.spark.sql.hive.client.HiveClientImpl.org$apache$spark$sql$hive$client$HiveClientImpl$$getRawTableOption(HiveClientImpl.scala:359)\n  at org.apache.spark.sql.hive.client.HiveClientImpl$$anonfun$tableExists$1.apply$mcZ$sp(HiveClientImpl.scala:363)\n  at org.apache.spark.sql.hive.client.HiveClientImpl$$anonfun$tableExists$1.apply(HiveClientImpl.scala:363)\n  at org.apache.spark.sql.hive.client.HiveClientImpl$$anonfun$tableExists$1.apply(HiveClientImpl.scala:363)\n  at org.apache.spark.sql.hive.client.HiveClientImpl$$anonfun$withHiveState$1.apply(HiveClientImpl.scala:277)\n  at org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:215)\n  at org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:214)\n  at org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:260)\n  at org.apache.spark.sql.hive.client.HiveClientImpl.tableExists(HiveClientImpl.scala:362)\n  at org.apache.spark.sql.hive.HiveExternalCatalog$$anonfun$tableExists$1.apply$mcZ$sp(HiveExternalCatalog.scala:849)\n  at org.apache.spark.sql.hive.HiveExternalCatalog$$anonfun$tableExists$1.apply(HiveExternalCatalog.scala:849)\n  at org.apache.spark.sql.hive.HiveExternalCatalog$$anonfun$tableExists$1.apply(HiveExternalCatalog.scala:849)\n  at org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:99)\n  ... 128 more\nCaused by: org.apache.hadoop.hive.metastore.api.MetaException: Insufficient Lake Formation permission(s) on dl_tpc_item (Service: AWSGlue; Status Code: 400; Error Code: AccessDeniedException; Request ID: efe2eb2d-16fb-4562-a728-8abf58c7bf63; Proxy: null)\n  at com.amazonaws.glue.catalog.converters.CatalogToHiveConverter.getHiveException(CatalogToHiveConverter.java:120)\n  at com.amazonaws.glue.catalog.converters.CatalogToHiveConverter.wrapInHiveException(CatalogToHiveConverter.java:108)\n  at com.amazonaws.glue.catalog.metastore.GlueMetastoreClientDelegate.getTable(GlueMetastoreClientDelegate.java:443)\n  at com.amazonaws.glue.catalog.metastore.AWSCatalogMetastoreClient.getTable(AWSCatalogMetastoreClient.java:968)\n  at org.apache.hadoop.hive.ql.metadata.Hive.getTable(Hive.java:1116)\n  ... 141 more\n"}]}},{"text":"For dl_tpc_customer table we only give SELECT permission at four columns COLUMN which includes ( c_first_sales_date_sk, c_first_name,c_last_name,c_first_shipto_date_sk ) \nfollowing query should only show those columns for which user has access.\n","user":"emr-developer","dateUpdated":"2020-03-16T22:57:32+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"results":{},"enabled":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1584399452560_1712955033","id":"20200212-214145_449414646","dateCreated":"2020-03-16T22:57:32+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:88"},{"text":"spark.sql(\"select * from tpc.dl_tpc_customer limit 10\").show()\n","user":"emr-developer","dateUpdated":"2021-01-07T15:40:43+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1584399452560_1056382196","id":"20200210-211122_557582954","dateCreated":"2020-03-16T22:57:32+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:89","dateFinished":"2021-01-07T15:40:54+0000","dateStarted":"2021-01-07T15:40:43+0000","results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+---------------------+------------+-----------+----------------------+\n|c_first_sales_date_sk|c_first_name|c_last_name|c_first_shipto_date_sk|\n+---------------------+------------+-----------+----------------------+\n|                 null|        null|       null|               2449597|\n|              2452077|       Joyce|     Deaton|                  null|\n|              2450637|       Ellis|        Dow|               2450667|\n|              2452342|        null|       Cass|               2452372|\n|                 null|        null|      Lange|                  null|\n|                 null|        Rene| Mclaughlin|                  null|\n|                 null|       Megan|      Sisco|                  null|\n|                 null|        null|       Soto|                  null|\n|                 null|      Stella|       null|               2449664|\n|              2449021|      Wesley|     Harris|                  null|\n+---------------------+------------+-----------+----------------------+"},{"type":"HTML","data":"<hr/>Spark Application Id: application_1610030784103_0001<br/>Spark WebUI: <a href=\"http://ip-10-0-0-111.us-west-1.compute.internal:20888/proxy/application_1610030784103_0001/\">http://ip-10-0-0-111.us-west-1.compute.internal:20888/proxy/application_1610030784103_0001/</a>"}]}},{"user":"emr-developer","dateUpdated":"2020-03-16T22:57:32+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1584399452561_-88254079","id":"20200211-135446_1452608321","dateCreated":"2020-03-16T22:57:32+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:90"}],"name":"LakeFormation-EMR-Notebook","id":"2F599NGVP","noteParams":{},"noteForms":{},"angularObjects":{},"config":{"isZeppelinNotebookCronEnable":false,"looknfeel":"default","personalizedMode":"false"},"info":{}}